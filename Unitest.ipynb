{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "n_train_items = 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import syft as sy  # <-- NEW: import the Pysyft library\n",
    "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
    "# simulation functions\n",
    "def connect_to_workers(n_workers):\n",
    "    return [\n",
    "        sy.VirtualWorker(hook, id=f\"worker{i+1}\")\n",
    "        for i in range(n_workers)\n",
    "    ]\n",
    "\n",
    "\n",
    "workers = connect_to_workers(n_workers=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.test_batch_size = 64\n",
    "        self.epochs = epochs\n",
    "        self.lr = 0.01\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 3\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The following options are not supported: num_workers: 1, pin_memory: True\n"
     ]
    }
   ],
   "source": [
    "# federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
    "#     datasets.MNIST('../data', train=True, download=True,\n",
    "#                    transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),\n",
    "#                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                    ]))\n",
    "#     .federate(workers), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "#     batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),\n",
    "#                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                    ])),\n",
    "#     batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size\n",
    ")\n",
    "\n",
    "    \n",
    "#---\n",
    "\n",
    "less_train_dataloader = [\n",
    "        ((data), (target))\n",
    "        for i, (data, target) in enumerate(train_loader)\n",
    "        if i < n_train_items / args.batch_size\n",
    "    ]\n",
    "less_test_dataloader = [\n",
    "        ((data), (target))\n",
    "        for i, (data, target) in enumerate(test_loader)\n",
    "        if i < n_train_items / args.batch_size\n",
    "    ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy \n",
    "# #mnist_dataset.__getitem__(2)[1]\n",
    "# a = (mnist_dataset.__getitem__(0)[0]).numpy()\n",
    "# a.dtype = 'uint8'\n",
    "# print(a)\n",
    "# Image.fromarray(a[0], mode= 'P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, less_train_dataloader, optimizer, epoch, workers):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(less_train_dataloader): # <-- now it is a distributed dataset\n",
    "        model.send(workers[batch_idx%len(workers)]) # <-- NEW: send the model to the right location\n",
    "        \n",
    "        data_on_worker = data.send(workers[batch_idx%len(workers)])\n",
    "        target_on_worker = target.send(workers[batch_idx%len(workers)])\n",
    "        \n",
    "        data_on_worker, target_on_worker = data_on_worker.to(device), target_on_worker.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_on_worker)\n",
    "        loss = F.nll_loss(output, target_on_worker)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.get() # <-- NEW: get the model back\n",
    "        \n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            loss = loss.get() # <-- NEW: get the loss back\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * args.batch_size, len(less_train_dataloader) * args.batch_size,\n",
    "                100. * batch_idx / len(less_train_dataloader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader*args.batch_size)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader* args.batch_size),\n",
    "        100. * correct / (len(test_loader)*args.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1280 (0%)]\tLoss: 2.324638\n",
      "Train Epoch: 1 [192/1280 (15%)]\tLoss: 2.314684\n",
      "Train Epoch: 1 [384/1280 (30%)]\tLoss: 2.291706\n",
      "Train Epoch: 1 [576/1280 (45%)]\tLoss: 2.310091\n",
      "Train Epoch: 1 [768/1280 (60%)]\tLoss: 2.275877\n",
      "Train Epoch: 1 [960/1280 (75%)]\tLoss: 2.281027\n",
      "Train Epoch: 1 [1152/1280 (90%)]\tLoss: 2.268555\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 2.2690, Accuracy: 252/1280 (20%)\n",
      "\n",
      "Train Epoch: 2 [0/1280 (0%)]\tLoss: 2.277216\n",
      "Train Epoch: 2 [192/1280 (15%)]\tLoss: 2.262702\n",
      "Train Epoch: 2 [384/1280 (30%)]\tLoss: 2.245050\n",
      "Train Epoch: 2 [576/1280 (45%)]\tLoss: 2.264976\n",
      "Train Epoch: 2 [768/1280 (60%)]\tLoss: 2.227021\n",
      "Train Epoch: 2 [960/1280 (75%)]\tLoss: 2.228276\n",
      "Train Epoch: 2 [1152/1280 (90%)]\tLoss: 2.211541\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 2.2258, Accuracy: 538/1280 (42%)\n",
      "\n",
      "Train Epoch: 3 [0/1280 (0%)]\tLoss: 2.226589\n",
      "Train Epoch: 3 [192/1280 (15%)]\tLoss: 2.203862\n",
      "Train Epoch: 3 [384/1280 (30%)]\tLoss: 2.188233\n",
      "Train Epoch: 3 [576/1280 (45%)]\tLoss: 2.211404\n",
      "Train Epoch: 3 [768/1280 (60%)]\tLoss: 2.163832\n",
      "Train Epoch: 3 [960/1280 (75%)]\tLoss: 2.158487\n",
      "Train Epoch: 3 [1152/1280 (90%)]\tLoss: 2.132762\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 2.1616, Accuracy: 558/1280 (44%)\n",
      "\n",
      "Train Epoch: 4 [0/1280 (0%)]\tLoss: 2.153714\n",
      "Train Epoch: 4 [192/1280 (15%)]\tLoss: 2.114891\n",
      "Train Epoch: 4 [384/1280 (30%)]\tLoss: 2.100732\n",
      "Train Epoch: 4 [576/1280 (45%)]\tLoss: 2.128700\n",
      "Train Epoch: 4 [768/1280 (60%)]\tLoss: 2.060370\n",
      "Train Epoch: 4 [960/1280 (75%)]\tLoss: 2.044523\n",
      "Train Epoch: 4 [1152/1280 (90%)]\tLoss: 2.003530\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 2.0504, Accuracy: 607/1280 (47%)\n",
      "\n",
      "Train Epoch: 5 [0/1280 (0%)]\tLoss: 2.029537\n",
      "Train Epoch: 5 [192/1280 (15%)]\tLoss: 1.957552\n",
      "Train Epoch: 5 [384/1280 (30%)]\tLoss: 1.948145\n",
      "Train Epoch: 5 [576/1280 (45%)]\tLoss: 1.981956\n",
      "Train Epoch: 5 [768/1280 (60%)]\tLoss: 1.874076\n",
      "Train Epoch: 5 [960/1280 (75%)]\tLoss: 1.841531\n",
      "Train Epoch: 5 [1152/1280 (90%)]\tLoss: 1.778745\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 1.8518, Accuracy: 678/1280 (53%)\n",
      "\n",
      "Train Epoch: 6 [0/1280 (0%)]\tLoss: 1.809550\n",
      "Train Epoch: 6 [192/1280 (15%)]\tLoss: 1.679309\n",
      "Train Epoch: 6 [384/1280 (30%)]\tLoss: 1.684945\n",
      "Train Epoch: 6 [576/1280 (45%)]\tLoss: 1.735237\n",
      "Train Epoch: 6 [768/1280 (60%)]\tLoss: 1.555564\n",
      "Train Epoch: 6 [960/1280 (75%)]\tLoss: 1.514473\n",
      "Train Epoch: 6 [1152/1280 (90%)]\tLoss: 1.436680\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 1.5526, Accuracy: 765/1280 (60%)\n",
      "\n",
      "Train Epoch: 7 [0/1280 (0%)]\tLoss: 1.478951\n",
      "Train Epoch: 7 [192/1280 (15%)]\tLoss: 1.296345\n",
      "Train Epoch: 7 [384/1280 (30%)]\tLoss: 1.331200\n",
      "Train Epoch: 7 [576/1280 (45%)]\tLoss: 1.418389\n",
      "Train Epoch: 7 [768/1280 (60%)]\tLoss: 1.157233\n",
      "Train Epoch: 7 [960/1280 (75%)]\tLoss: 1.135285\n",
      "Train Epoch: 7 [1152/1280 (90%)]\tLoss: 1.062929\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 1.2383, Accuracy: 855/1280 (67%)\n",
      "\n",
      "Train Epoch: 8 [0/1280 (0%)]\tLoss: 1.132568\n",
      "Train Epoch: 8 [192/1280 (15%)]\tLoss: 0.939146\n",
      "Train Epoch: 8 [384/1280 (30%)]\tLoss: 1.005010\n",
      "Train Epoch: 8 [576/1280 (45%)]\tLoss: 1.134784\n",
      "Train Epoch: 8 [768/1280 (60%)]\tLoss: 0.833044\n",
      "Train Epoch: 8 [960/1280 (75%)]\tLoss: 0.849073\n",
      "Train Epoch: 8 [1152/1280 (90%)]\tLoss: 0.771674\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 1.0080, Accuracy: 909/1280 (71%)\n",
      "\n",
      "Train Epoch: 9 [0/1280 (0%)]\tLoss: 0.885917\n",
      "Train Epoch: 9 [192/1280 (15%)]\tLoss: 0.703052\n",
      "Train Epoch: 9 [384/1280 (30%)]\tLoss: 0.785647\n",
      "Train Epoch: 9 [576/1280 (45%)]\tLoss: 0.929986\n",
      "Train Epoch: 9 [768/1280 (60%)]\tLoss: 0.640221\n",
      "Train Epoch: 9 [960/1280 (75%)]\tLoss: 0.687586\n",
      "Train Epoch: 9 [1152/1280 (90%)]\tLoss: 0.581957\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 0.8679, Accuracy: 928/1280 (72%)\n",
      "\n",
      "Train Epoch: 10 [0/1280 (0%)]\tLoss: 0.733676\n",
      "Train Epoch: 10 [192/1280 (15%)]\tLoss: 0.568930\n",
      "Train Epoch: 10 [384/1280 (30%)]\tLoss: 0.647158\n",
      "Train Epoch: 10 [576/1280 (45%)]\tLoss: 0.786850\n",
      "Train Epoch: 10 [768/1280 (60%)]\tLoss: 0.531604\n",
      "Train Epoch: 10 [960/1280 (75%)]\tLoss: 0.599982\n",
      "Train Epoch: 10 [1152/1280 (90%)]\tLoss: 0.463047\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 0.7895, Accuracy: 944/1280 (74%)\n",
      "\n",
      "CPU times: user 8.86 s, sys: 0 ns, total: 8.86 s\n",
      "Wall time: 8.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, device, less_train_dataloader, optimizer, epoch, workers)\n",
    "    test(args, model, device, less_test_dataloader)\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VirtualWorker id:worker1 #objects:35>\n"
     ]
    }
   ],
   "source": [
    "print(workers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VirtualWorker id:worker1 #objects:180>\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-293ccfed3689>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel_ondevice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggregater\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Net' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model_list = []\n",
    "model_ondevice = []\n",
    "aggregater = sy.VirtualWorker(hook, id=\"aggregater\")\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(less_train_dataloader):\n",
    "    data_on_device = data.send(workers[batch_idx])\n",
    "    if batch_idx<3:\n",
    "        model_ondevice.append(model.copy().send(workers[batch_idx]))\n",
    "        print(model_ondevice[batch_idx].location)\n",
    "        \n",
    "        pre = model_ondevice[batch_idx](data_on_device)\n",
    "        model_ondevice[batch_idx].move(aggregater)\n",
    "        print(model.location)\n",
    "        print(model.weight.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-215-fa2944c89d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(model_list[0].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fb2982e6e08>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01297603,  0.02842132,  0.01014335, ..., -0.00745563,\n",
       "        -0.02407177, -0.00225234],\n",
       "       [ 0.03080916,  0.01323886,  0.03059926, ..., -0.01799139,\n",
       "        -0.0265331 ,  0.01559756],\n",
       "       [ 0.01701068,  0.00417169,  0.0316051 , ...,  0.03077709,\n",
       "        -0.02863705,  0.01833366],\n",
       "       ...,\n",
       "       [-0.00771326, -0.01363829,  0.03800831, ..., -0.04430421,\n",
       "        -0.03094019, -0.01628821],\n",
       "       [-0.0320928 ,  0.03452658,  0.01318498, ..., -0.0185255 ,\n",
       "         0.04329454,  0.01331757],\n",
       "       [ 0.02591962, -0.00609975,  0.00413742, ...,  0.02711744,\n",
       "        -0.00503955, -0.03584282]], dtype=float32)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc2.weight.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
