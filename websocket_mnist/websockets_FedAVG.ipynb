{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Please ignore these variable, they only provide options for our CI system.\n",
    "args = []\n",
    "abort_after_one = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Federated learning with websockets and federated averaging with possible solutions for problem you might face\n",
    "\n",
    "This notebook will discuss detailed steps and problems you might face when going through these steps\n",
    "\n",
    "Make sure you have correct websocket-client library because if you have another websocket library installed on top of websocket-client when you run this command ``` import websocket ``` it try will access that additional websocket library first because websocket-client is also called imported into your python script by ``` import websocket ``` and when you try to create connection with this command ``` websocket.create_connection() ``` this causes websocket don't have any module named create_connection\n",
    "Solution: in terminal activate that environment where syft is installed run ```pip uninstall websocket``` to remove any additional websocket libraries then run ```pip install --upgrade websocket_client```\n",
    "\n",
    "Authors:\n",
    "- midokura-silvia\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: start the websocket server workers\n",
    "\n",
    "Each worker is represented by two parts, a local handle (websocket client worker) and the remote instance that holds the data and performs the computations. The remote part is called a websocket server worker.\n",
    "\n",
    "So first, you need to ```cd``` to the folder where this notebook and other additional files for running server and client are \n",
    "\n",
    "for example\n",
    "in windows 10  \n",
    ">cd (path till projects directory) \\python_projects\\websockets-example-MNIST\n",
    "\n",
    "Note: Don't copy paste the path above because this is purely for the sake example your path may differ depending on your OS and project folder\n",
    " \n",
    "\n",
    "\n",
    "because if you don't when you try to run ```python start_websocket_servers.py``` command in terminal this script open sub processes with python which runs other scripts that starts websocket server workers and only the name of the file with its extension is mentioned because the file's path may vary.\n",
    "we need to create the remote workers. For this, you need to run in a terminal (not possible from the notebook):\n",
    "\n",
    "```bash\n",
    "python start_websocket_servers.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the websocket client workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to perform the imports and setup some arguments and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/opt/conda/lib/python3.7/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.3.so'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import syft as sy\n",
    "from syft.workers.websocket_client import WebsocketClientWorker\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from syft.frameworks.torch.fl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_websocket_client as rwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, cuda=False, epochs=2, federate_after_n_batches=50, lr=0.01, save_model=False, seed=1, test_batch_size=1000, use_virtual=False, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "args = rwc.define_and_get_arguments(args=args)\n",
    "use_cuda = args.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's instantiate the websocket client workers, our local access point to the remote workers.\n",
    "Note that **this step will fail, if the websocket server workers are not running**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "#fill your ip in the host\n",
    "kwargs_websocket = {\"host\": '', \"hook\": hook, \"verbose\": args.verbose}\n",
    "alice = WebsocketClientWorker(id='0', port=8666, **kwargs_websocket)\n",
    "bob = WebsocketClientWorker(id='1', port=8667, **kwargs_websocket), host = '140.113.164.36', hook = hook, verbose = args.verbose)#\n",
    "charlie = WebsocketClientWorker(id='2', port=8668, **kwargs_websocket)\n",
    "\n",
    "workers = [alice, bob, charlie]\n",
    "print(workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and distribute the training data\n",
    "\n",
    "We will use the MNIST dataset and distribute the data randomly onto the workers. \n",
    "This is not realistic for a federated training setup, where the data would normally already be available at the remote workers.\n",
    "\n",
    "We instantiate two FederatedDataLoaders, one for the train and one for the test set of the MNIST dataset.\n",
    "\n",
    "*If you run into BrokenPipe errors go to the parrent directory of the directory where your project is and delete data folder then restart notebook and try again if the error comes again delete that data folder again run the following command*\n",
    "\n",
    "for example directory for data \n",
    "\n",
    ">(path till projects directory) \\python_projects\\\n",
    "\n",
    "directory for project notebook and scripts\n",
    "\n",
    ">(path till projects directory) \\python_projects\\websockets-example-MNIST\n",
    "\n",
    "Note: Don't copy paste the path above because this is purely for the sake example your path may differ depending on your OS and project folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a728f10cf25c417281353e4a84183388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f559514d6444a9b82a4aed9d2fd9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2eaa1fbee064635a6db8c7c744d52f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3936b693e574f969d08a3be4bf93e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f2ca2582d50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run this box only if the the next box gives pipeline error\n",
    "torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data\",\n",
    "        train=True,download=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "federated_train_loader = sy.FederatedDataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        ),\n",
    "    ).federate(tuple(workers)),\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True,\n",
    "    iter_per_worker=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data\",\n",
    "        train=False,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=args.test_batch_size,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to instantiate the machine learning model. It is a small neural network with 2 convolutional and two fully connected layers. \n",
    "It uses ReLU activations and max pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = rwc.Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "formatter = logging.Formatter(\"%(asctime)s %(levelname)s %(filename)s(l:%(lineno)d) - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start the training\n",
    "\n",
    "\n",
    "Now we are ready to start the federated training. We will perform training over a given number of batches separately on each worker and then calculate the federated average of the resulting model and calculate test accuracy over that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-23 12:40:46,231 DEBUG run_websocket_client.py(l:130) - Starting training round, batches [0, 50]\n",
      "2020-06-23 12:40:47,079 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [0/50 (0%)]\tLoss: 2.310694\n",
      "2020-06-23 12:40:49,666 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [25/50 (50%)]\tLoss: 2.204401\n",
      "2020-06-23 12:40:54,088 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [0/50 (0%)]\tLoss: 2.298535\n",
      "2020-06-23 12:40:55,580 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [25/50 (50%)]\tLoss: 2.222379\n",
      "2020-06-23 12:41:00,132 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [0/50 (0%)]\tLoss: 2.314187\n",
      "2020-06-23 12:41:01,586 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [25/50 (50%)]\tLoss: 2.209582\n",
      "2020-06-23 12:41:36,839 DEBUG run_websocket_client.py(l:130) - Starting training round, batches [50, 100]\n",
      "2020-06-23 12:41:36,997 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [0/50 (0%)]\tLoss: 2.071491\n",
      "2020-06-23 12:41:39,619 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [25/50 (50%)]\tLoss: 1.756440\n",
      "2020-06-23 12:41:44,755 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [0/50 (0%)]\tLoss: 2.031761\n",
      "2020-06-23 12:41:46,685 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [25/50 (50%)]\tLoss: 1.829457\n",
      "2020-06-23 12:41:51,993 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [0/50 (0%)]\tLoss: 2.106293\n",
      "2020-06-23 12:41:53,580 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [25/50 (50%)]\tLoss: 1.713701\n",
      "2020-06-23 12:42:28,042 DEBUG run_websocket_client.py(l:130) - Starting training round, batches [100, 150]\n",
      "2020-06-23 12:42:28,356 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [0/50 (0%)]\tLoss: 1.196854\n",
      "2020-06-23 12:42:30,684 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [25/50 (50%)]\tLoss: 0.914083\n",
      "2020-06-23 12:42:35,740 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [0/50 (0%)]\tLoss: 1.225595\n",
      "2020-06-23 12:42:37,382 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [25/50 (50%)]\tLoss: 0.987866\n",
      "2020-06-23 12:42:41,732 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [0/50 (0%)]\tLoss: 1.251327\n",
      "2020-06-23 12:42:43,978 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [25/50 (50%)]\tLoss: 0.804695\n",
      "2020-06-23 12:43:18,368 DEBUG run_websocket_client.py(l:130) - Starting training round, batches [150, 200]\n",
      "2020-06-23 12:43:18,519 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [0/50 (0%)]\tLoss: 0.593546\n",
      "2020-06-23 12:43:20,170 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [25/50 (50%)]\tLoss: 0.623730\n",
      "2020-06-23 12:43:24,532 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [0/50 (0%)]\tLoss: 0.602626\n",
      "2020-06-23 12:43:26,002 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [25/50 (50%)]\tLoss: 0.504773\n",
      "2020-06-23 12:43:30,301 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [0/50 (0%)]\tLoss: 0.615767\n",
      "2020-06-23 12:43:31,938 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [25/50 (50%)]\tLoss: 0.596590\n",
      "2020-06-23 12:44:03,259 DEBUG run_websocket_client.py(l:130) - Starting training round, batches [200, 250]\n",
      "2020-06-23 12:44:03,409 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [0/50 (0%)]\tLoss: 0.370446\n",
      "2020-06-23 12:44:04,875 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [25/50 (50%)]\tLoss: 0.519897\n",
      "2020-06-23 12:44:08,603 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [0/50 (0%)]\tLoss: 0.387365\n",
      "2020-06-23 12:44:10,862 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [25/50 (50%)]\tLoss: 0.424589\n",
      "2020-06-23 12:44:14,896 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [0/50 (0%)]\tLoss: 0.468219\n",
      "2020-06-23 12:44:16,424 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [25/50 (50%)]\tLoss: 0.270010\n",
      "2020-06-23 12:44:51,450 DEBUG run_websocket_client.py(l:130) - Starting training round, batches [250, 300]\n",
      "2020-06-23 12:44:51,676 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [0/50 (0%)]\tLoss: 0.275260\n",
      "2020-06-23 12:44:54,049 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [25/50 (50%)]\tLoss: 0.284376\n",
      "2020-06-23 12:44:58,642 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [0/50 (0%)]\tLoss: 0.286853\n",
      "2020-06-23 12:45:00,971 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [25/50 (50%)]\tLoss: 0.333453\n",
      "2020-06-23 12:45:05,577 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [0/50 (0%)]\tLoss: 0.309181\n",
      "2020-06-23 12:45:07,873 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [25/50 (50%)]\tLoss: 0.366478\n",
      "2020-06-23 12:45:22,837 DEBUG run_websocket_client.py(l:130) - Starting training round, batches [300, 350]\n",
      "2020-06-23 12:45:23,040 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [0/13 (0%)]\tLoss: 0.288872\n",
      "2020-06-23 12:45:26,150 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [0/13 (0%)]\tLoss: 0.314986\n",
      "2020-06-23 12:45:29,419 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [0/13 (0%)]\tLoss: 0.173418\n",
      "2020-06-23 12:45:32,941 DEBUG run_websocket_client.py(l:130) - Starting training round, batches [350, 400]\n",
      "2020-06-23 12:45:32,953 DEBUG run_websocket_client.py(l:142) - At least one worker ran out of data, stopping.\n",
      "2020-06-23 12:45:34,662 DEBUG run_websocket_client.py(l:166) - \n",
      "\n",
      "2020-06-23 12:45:34,662 INFO run_websocket_client.py(l:170) - Test set: Average loss: 0.3282, Accuracy: 9021/10000 (90%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-23 12:46:07,648 DEBUG run_websocket_client.py(l:130) - Starting training round, batches [0, 50]\n",
      "2020-06-23 12:46:07,857 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [0/50 (0%)]\tLoss: 0.270864\n",
      "2020-06-23 12:46:09,881 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [25/50 (50%)]\tLoss: 0.449094\n",
      "2020-06-23 12:46:13,939 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [0/50 (0%)]\tLoss: 0.380058\n",
      "2020-06-23 12:46:15,603 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [25/50 (50%)]\tLoss: 0.445399\n",
      "2020-06-23 12:46:19,669 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [0/50 (0%)]\tLoss: 0.381359\n",
      "2020-06-23 12:46:21,677 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [25/50 (50%)]\tLoss: 0.318005\n",
      "2020-06-23 12:46:53,939 DEBUG run_websocket_client.py(l:130) - Starting training round, batches [50, 100]\n",
      "2020-06-23 12:46:54,177 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [0/50 (0%)]\tLoss: 0.275477\n",
      "2020-06-23 12:46:56,333 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [25/50 (50%)]\tLoss: 0.230129\n",
      "2020-06-23 12:47:00,896 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [0/50 (0%)]\tLoss: 0.331849\n",
      "2020-06-23 12:47:03,419 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [25/50 (50%)]\tLoss: 0.348638\n",
      "2020-06-23 12:47:07,752 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [0/50 (0%)]\tLoss: 0.204973\n",
      "2020-06-23 12:47:10,357 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [25/50 (50%)]\tLoss: 0.295844\n",
      "2020-06-23 12:47:37,749 DEBUG run_websocket_client.py(l:130) - Starting training round, batches [100, 150]\n",
      "2020-06-23 12:47:37,938 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [0/50 (0%)]\tLoss: 0.410400\n",
      "2020-06-23 12:47:40,001 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [25/50 (50%)]\tLoss: 0.126727\n",
      "2020-06-23 12:47:44,480 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [0/50 (0%)]\tLoss: 0.191933\n",
      "2020-06-23 12:47:46,675 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [25/50 (50%)]\tLoss: 0.179263\n",
      "2020-06-23 12:47:50,969 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [0/50 (0%)]\tLoss: 0.309312\n",
      "2020-06-23 12:47:52,470 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [25/50 (50%)]\tLoss: 0.509985\n",
      "2020-06-23 12:48:24,350 DEBUG run_websocket_client.py(l:130) - Starting training round, batches [150, 200]\n",
      "2020-06-23 12:48:24,594 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [0/50 (0%)]\tLoss: 0.121421\n",
      "2020-06-23 12:48:26,648 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [25/50 (50%)]\tLoss: 0.334510\n",
      "2020-06-23 12:48:30,461 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [0/50 (0%)]\tLoss: 0.240585\n",
      "2020-06-23 12:48:32,396 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [25/50 (50%)]\tLoss: 0.252131\n",
      "2020-06-23 12:48:36,460 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [0/50 (0%)]\tLoss: 0.243285\n",
      "2020-06-23 12:48:39,190 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [25/50 (50%)]\tLoss: 0.151868\n",
      "2020-06-23 12:49:06,351 DEBUG run_websocket_client.py(l:130) - Starting training round, batches [200, 250]\n",
      "2020-06-23 12:49:06,493 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [0/50 (0%)]\tLoss: 0.176949\n",
      "2020-06-23 12:49:08,335 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [25/50 (50%)]\tLoss: 0.169856\n",
      "2020-06-23 12:49:12,456 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [0/50 (0%)]\tLoss: 0.294133\n",
      "2020-06-23 12:49:14,131 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [25/50 (50%)]\tLoss: 0.263375\n",
      "2020-06-23 12:49:18,007 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [0/50 (0%)]\tLoss: 0.191750\n",
      "2020-06-23 12:49:20,333 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [25/50 (50%)]\tLoss: 0.232282\n",
      "2020-06-23 12:49:47,808 DEBUG run_websocket_client.py(l:130) - Starting training round, batches [250, 300]\n",
      "2020-06-23 12:49:47,981 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [0/50 (0%)]\tLoss: 0.224753\n",
      "2020-06-23 12:49:50,018 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [25/50 (50%)]\tLoss: 0.322472\n",
      "2020-06-23 12:49:53,850 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [0/50 (0%)]\tLoss: 0.207744\n",
      "2020-06-23 12:49:55,712 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [25/50 (50%)]\tLoss: 0.579848\n",
      "2020-06-23 12:50:00,118 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [0/50 (0%)]\tLoss: 0.093462\n",
      "2020-06-23 12:50:01,854 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [25/50 (50%)]\tLoss: 0.251709\n",
      "2020-06-23 12:50:11,313 DEBUG run_websocket_client.py(l:130) - Starting training round, batches [300, 350]\n",
      "2020-06-23 12:50:11,489 DEBUG run_websocket_client.py(l:78) - Train Worker 0: [0/13 (0%)]\tLoss: 0.232532\n",
      "2020-06-23 12:50:14,494 DEBUG run_websocket_client.py(l:78) - Train Worker 1: [0/13 (0%)]\tLoss: 0.103470\n",
      "2020-06-23 12:50:17,530 DEBUG run_websocket_client.py(l:78) - Train Worker 2: [0/13 (0%)]\tLoss: 0.353311\n",
      "2020-06-23 12:50:20,717 DEBUG run_websocket_client.py(l:130) - Starting training round, batches [350, 400]\n",
      "2020-06-23 12:50:20,727 DEBUG run_websocket_client.py(l:142) - At least one worker ran out of data, stopping.\n",
      "2020-06-23 12:50:22,305 DEBUG run_websocket_client.py(l:166) - \n",
      "\n",
      "2020-06-23 12:50:22,306 INFO run_websocket_client.py(l:170) - Test set: Average loss: 0.2076, Accuracy: 9378/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    print(\"Starting epoch {}/{}\".format(epoch, args.epochs))\n",
    "    model = rwc.train(model, device, federated_train_loader, args.lr, args.federate_after_n_batches, \n",
    "                      abort_after_one=abort_after_one)\n",
    "    rwc.test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!!! - Time to Join the Community!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways!\n",
    "\n",
    "### Star PySyft on GitHub\n",
    "\n",
    "The easiest way to help our community is just by starring the GitHub repos! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Join our Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at [http://slack.openmined.org](http://slack.openmined.org)\n",
    "\n",
    "### Join a Code Project!\n",
    "\n",
    "The best way to contribute to our community is to become a code contributor! At any time you can go to PySyft GitHub Issues page and filter for \"Projects\". This will show you all the top level Tickets giving an overview of what projects you can join! If you don't want to join a project, but you would like to do a bit of coding, you can also look for more \"one off\" mini-projects by searching for GitHub issues marked \"good first issue\".\n",
    "\n",
    "- [PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "[OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
