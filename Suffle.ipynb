{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "n_train_items = 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import syft as sy  # <-- NEW: import the Pysyft library\n",
    "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
    "# simulation functions\n",
    "def connect_to_workers(n_workers):\n",
    "    return [\n",
    "        sy.VirtualWorker(hook, id=f\"worker{i+1}\")\n",
    "        for i in range(n_workers)\n",
    "    ]\n",
    "\n",
    "\n",
    "workers = connect_to_workers(n_workers=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.test_batch_size = 64\n",
    "        self.epochs = epochs\n",
    "        self.lr = 0.01\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 3\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
    "#     datasets.MNIST('../data', train=True, download=True,\n",
    "#                    transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),\n",
    "#                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                    ]))\n",
    "#     .federate(workers), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "#     batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),\n",
    "#                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                    ])),\n",
    "#     batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size\n",
    ")\n",
    "\n",
    "    \n",
    "#---\n",
    "\n",
    "less_train_dataloader = [\n",
    "        ((data), (target))\n",
    "        for i, (data, target) in enumerate(train_loader)\n",
    "        if i < n_train_items / args.batch_size\n",
    "    ]\n",
    "less_test_dataloader = [\n",
    "        ((data), (target))\n",
    "        for i, (data, target) in enumerate(test_loader)\n",
    "        if i < n_train_items / args.batch_size\n",
    "    ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy \n",
    "# #mnist_dataset.__getitem__(2)[1]\n",
    "# a = (mnist_dataset.__getitem__(0)[0]).numpy()\n",
    "# a.dtype = 'uint8'\n",
    "# print(a)\n",
    "# Image.fromarray(a[0], mode= 'P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(workers, Net):\n",
    "    model_list = list()\n",
    "    for worker in workers:\n",
    "        model_list.append(Net)\n",
    "    return model_list\n",
    "def opt_init(model_list):\n",
    "    opt_list = list()\n",
    "    for model  in model_list:\n",
    "        opt_list.append(optim.SGD(model.parameters(), lr=args.lr))\n",
    "    return opt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model_list, device, less_train_dataloader, opt_list, epoch, workers):\n",
    "    \n",
    "    ## start training and record the model into model_list\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(less_train_dataloader): # <-- now it is a distributed dataset\n",
    "        model_on_worker = model_list[batch_idx%len(workers)].copy()\n",
    "        model_on_worker.train()\n",
    "        model_on_worker.send(workers[batch_idx%len(workers)]) # <-- NEW: send the model to the right location\n",
    "        \n",
    "        data_on_worker = data.send(workers[batch_idx%len(workers)])\n",
    "        target_on_worker = target.send(workers[batch_idx%len(workers)])\n",
    "        \n",
    "        data_on_worker, target_on_worker = data_on_worker.to(device), target_on_worker.to(device)\n",
    "        \n",
    "        opt_list[batch_idx%len(workers)].zero_grad()\n",
    "        \n",
    "        output = model_on_worker(data_on_worker)\n",
    "        loss = F.nll_loss(output, target_on_worker)\n",
    "        loss.backward()\n",
    "        opt_list[batch_idx%len(workers)].step()\n",
    "        model_on_worker.get() # <-- NEW: get the model back\n",
    "        \n",
    "        model_list[batch_idx%len(workers)] = model_on_worker #When len(dataloader) is longer than the len(worker) send and get must be modified\n",
    "        #model_list here is full of the model which has trained on the workers, there are all different now.\n",
    "        \n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            loss = loss.get() # <-- NEW: get the loss back\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * args.batch_size, len(less_train_dataloader) * args.batch_size,\n",
    "                100. * batch_idx / len(less_train_dataloader), loss.item()))\n",
    "\n",
    "\n",
    "    ##Aggregation time\n",
    "    new_model = []\n",
    "    tmp_model = Net().to(device)\n",
    "    with torch.no_grad():\n",
    "        for p in model_list[0].parameters():\n",
    "            new_model.append(0)\n",
    "            \n",
    "        for m in model_list:\n",
    "            for par_idx, par in enumerate(m.parameters()):\n",
    "                #average the model_list\n",
    "                new_model[par_idx] = new_model[par_idx]+par.data\n",
    "                # we get new model in list format and need to set_ to model\n",
    "        \n",
    "        for i, model in enumerate(model_list):\n",
    "            for i, par in enumerate(tmp_model.parameters()):\n",
    "            par.set_(new_model[i]/len(workers))\n",
    "        # Get new model in tmp_model\n",
    "                  \n",
    "            \n",
    "        #init model with new_model\n",
    "        for workers in range(len(workers):\n",
    "            for par in range(len(new_model)):\n",
    "                model_list[workers][par].set_(tmp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(model.parameters()):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader*args.batch_size)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader* args.batch_size),\n",
    "        100. * correct / (len(test_loader)*args.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1280 (0%)]\tLoss: 2.315260\n",
      "Train Epoch: 1 [192/1280 (15%)]\tLoss: 2.314102\n",
      "Train Epoch: 1 [384/1280 (30%)]\tLoss: 2.307504\n",
      "Train Epoch: 1 [576/1280 (45%)]\tLoss: 2.313025\n",
      "Train Epoch: 1 [768/1280 (60%)]\tLoss: 2.298383\n",
      "Train Epoch: 1 [960/1280 (75%)]\tLoss: 2.304842\n",
      "Train Epoch: 1 [1152/1280 (90%)]\tLoss: 2.324359\n",
      "After training\n",
      "\n",
      "Test set: Average loss: 2.3144, Accuracy: 116/1280 (9%)\n",
      "\n",
      "Train Epoch: 2 [0/1280 (0%)]\tLoss: 2.315260\n",
      "Train Epoch: 2 [192/1280 (15%)]\tLoss: 2.314102\n",
      "Train Epoch: 2 [384/1280 (30%)]\tLoss: 2.307504\n",
      "Train Epoch: 2 [576/1280 (45%)]\tLoss: 2.313025\n",
      "Train Epoch: 2 [768/1280 (60%)]\tLoss: 2.298383\n",
      "Train Epoch: 2 [960/1280 (75%)]\tLoss: 2.304842\n",
      "Train Epoch: 2 [1152/1280 (90%)]\tLoss: 2.324359\n",
      "After training\n",
      "\n",
      "Test set: Average loss: 2.3144, Accuracy: 116/1280 (9%)\n",
      "\n",
      "Train Epoch: 3 [0/1280 (0%)]\tLoss: 2.315260\n",
      "Train Epoch: 3 [192/1280 (15%)]\tLoss: 2.314102\n",
      "Train Epoch: 3 [384/1280 (30%)]\tLoss: 2.307504\n",
      "Train Epoch: 3 [576/1280 (45%)]\tLoss: 2.313025\n",
      "Train Epoch: 3 [768/1280 (60%)]\tLoss: 2.298383\n",
      "Train Epoch: 3 [960/1280 (75%)]\tLoss: 2.304842\n",
      "Train Epoch: 3 [1152/1280 (90%)]\tLoss: 2.324359\n",
      "After training\n",
      "\n",
      "Test set: Average loss: 2.3144, Accuracy: 116/1280 (9%)\n",
      "\n",
      "Train Epoch: 4 [0/1280 (0%)]\tLoss: 2.315260\n",
      "Train Epoch: 4 [192/1280 (15%)]\tLoss: 2.314102\n",
      "Train Epoch: 4 [384/1280 (30%)]\tLoss: 2.307504\n",
      "Train Epoch: 4 [576/1280 (45%)]\tLoss: 2.313025\n",
      "Train Epoch: 4 [768/1280 (60%)]\tLoss: 2.298383\n",
      "Train Epoch: 4 [960/1280 (75%)]\tLoss: 2.304842\n",
      "Train Epoch: 4 [1152/1280 (90%)]\tLoss: 2.324359\n",
      "After training\n",
      "\n",
      "Test set: Average loss: 2.3144, Accuracy: 116/1280 (9%)\n",
      "\n",
      "Train Epoch: 5 [0/1280 (0%)]\tLoss: 2.315260\n",
      "Train Epoch: 5 [192/1280 (15%)]\tLoss: 2.314102\n",
      "Train Epoch: 5 [384/1280 (30%)]\tLoss: 2.307504\n",
      "Train Epoch: 5 [576/1280 (45%)]\tLoss: 2.313025\n",
      "Train Epoch: 5 [768/1280 (60%)]\tLoss: 2.298383\n",
      "Train Epoch: 5 [960/1280 (75%)]\tLoss: 2.304842\n",
      "Train Epoch: 5 [1152/1280 (90%)]\tLoss: 2.324359\n",
      "After training\n",
      "\n",
      "Test set: Average loss: 2.3144, Accuracy: 116/1280 (9%)\n",
      "\n",
      "Train Epoch: 6 [0/1280 (0%)]\tLoss: 2.315260\n",
      "Train Epoch: 6 [192/1280 (15%)]\tLoss: 2.314102\n",
      "Train Epoch: 6 [384/1280 (30%)]\tLoss: 2.307504\n",
      "Train Epoch: 6 [576/1280 (45%)]\tLoss: 2.313025\n",
      "Train Epoch: 6 [768/1280 (60%)]\tLoss: 2.298383\n",
      "Train Epoch: 6 [960/1280 (75%)]\tLoss: 2.304842\n",
      "Train Epoch: 6 [1152/1280 (90%)]\tLoss: 2.324359\n",
      "After training\n",
      "\n",
      "Test set: Average loss: 2.3144, Accuracy: 116/1280 (9%)\n",
      "\n",
      "Train Epoch: 7 [0/1280 (0%)]\tLoss: 2.315260\n",
      "Train Epoch: 7 [192/1280 (15%)]\tLoss: 2.314102\n",
      "Train Epoch: 7 [384/1280 (30%)]\tLoss: 2.307504\n",
      "Train Epoch: 7 [576/1280 (45%)]\tLoss: 2.313025\n",
      "Train Epoch: 7 [768/1280 (60%)]\tLoss: 2.298383\n",
      "Train Epoch: 7 [960/1280 (75%)]\tLoss: 2.304842\n",
      "Train Epoch: 7 [1152/1280 (90%)]\tLoss: 2.324359\n",
      "After training\n",
      "\n",
      "Test set: Average loss: 2.3144, Accuracy: 116/1280 (9%)\n",
      "\n",
      "Train Epoch: 8 [0/1280 (0%)]\tLoss: 2.315260\n",
      "Train Epoch: 8 [192/1280 (15%)]\tLoss: 2.314102\n",
      "Train Epoch: 8 [384/1280 (30%)]\tLoss: 2.307504\n",
      "Train Epoch: 8 [576/1280 (45%)]\tLoss: 2.313025\n",
      "Train Epoch: 8 [768/1280 (60%)]\tLoss: 2.298383\n",
      "Train Epoch: 8 [960/1280 (75%)]\tLoss: 2.304842\n",
      "Train Epoch: 8 [1152/1280 (90%)]\tLoss: 2.324359\n",
      "After training\n",
      "\n",
      "Test set: Average loss: 2.3144, Accuracy: 116/1280 (9%)\n",
      "\n",
      "Train Epoch: 9 [0/1280 (0%)]\tLoss: 2.315260\n",
      "Train Epoch: 9 [192/1280 (15%)]\tLoss: 2.314102\n",
      "Train Epoch: 9 [384/1280 (30%)]\tLoss: 2.307504\n",
      "Train Epoch: 9 [576/1280 (45%)]\tLoss: 2.313025\n",
      "Train Epoch: 9 [768/1280 (60%)]\tLoss: 2.298383\n",
      "Train Epoch: 9 [960/1280 (75%)]\tLoss: 2.304842\n",
      "Train Epoch: 9 [1152/1280 (90%)]\tLoss: 2.324359\n",
      "After training\n",
      "\n",
      "Test set: Average loss: 2.3144, Accuracy: 116/1280 (9%)\n",
      "\n",
      "Train Epoch: 10 [0/1280 (0%)]\tLoss: 2.315260\n",
      "Train Epoch: 10 [192/1280 (15%)]\tLoss: 2.314102\n",
      "Train Epoch: 10 [384/1280 (30%)]\tLoss: 2.307504\n",
      "Train Epoch: 10 [576/1280 (45%)]\tLoss: 2.313025\n",
      "Train Epoch: 10 [768/1280 (60%)]\tLoss: 2.298383\n",
      "Train Epoch: 10 [960/1280 (75%)]\tLoss: 2.304842\n",
      "Train Epoch: 10 [1152/1280 (90%)]\tLoss: 2.324359\n",
      "After training\n",
      "\n",
      "Test set: Average loss: 2.3144, Accuracy: 116/1280 (9%)\n",
      "\n",
      "CPU times: user 8 s, sys: 138 ms, total: 8.14 s\n",
      "Wall time: 8.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
    "\n",
    "model_list = []\n",
    "model_list = model_init(workers, Net().to(device))\n",
    "opt_list = opt_init(model_list)\n",
    "# not finish in train, finish latter\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model_list, device, less_train_dataloader, opt_list, epoch, workers)\n",
    "    print(\"After training\")\n",
    "    test(args, model_list[0], device, less_test_dataloader)\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Wrapper)>[PointerTensor | me:52758697780 -> tttt:10731448168]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "weight should have at least three dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPureFrameworkTensorFoundError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    328\u001b[0m             new_args, new_kwargs, new_type, args_type = hook_args.unwrap_args_from_function(\n\u001b[0;32m--> 329\u001b[0;31m                 \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_args_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36munwrap_args_from_function\u001b[0;34m(attr, args_, kwargs_, return_args_type)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# Try running it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36mseven_fold\u001b[0;34m(lambdas, args_, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m     return (\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# Last if not, rule is probably == 1 so use type to return the right transformation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32melse\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mforward_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# And do this for all the args / rules provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureFrameworkTensorFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureFrameworkTensorFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPureFrameworkTensorFoundError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-2d0410aad090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mt_on_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtttt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_on_worker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# print(workers[0].current_objects())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ceb0955942ca>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/syft/generic/frameworks/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mhandle_func_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;31m# in the execute_command function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;31m# Change the library path to avoid errors on layers like AvgPooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(cmd, args_, kwargs_)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: weight should have at least three dimensions"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "tttt = sy.VirtualWorker(hook, id=\"tttt\")\n",
    "tttt.clear_objects()\n",
    "model = model.send(tttt)\n",
    "\n",
    "\n",
    "t = torch.ones([1,28,28], dtype=torch.float64)\n",
    "t_on_worker = t.send(tttt)\n",
    "print((t_on_worker))\n",
    "model(t)\n",
    "# print(workers[0].current_objects())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VirtualWorker id:worker1 #objects:15>\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-293ccfed3689>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel_ondevice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggregater\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Net' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model_list = []\n",
    "model_ondevice = []\n",
    "aggregater = sy.VirtualWorker(hook, id=\"aggregater\")\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(less_train_dataloader):\n",
    "    data_on_device = data.send(workers[batch_idx])\n",
    "    if batch_idx<3:\n",
    "        model_ondevice.append(model.copy().send(workers[batch_idx]))\n",
    "        print(model_ondevice[batch_idx].location)\n",
    "        \n",
    "        pre = model_ondevice[batch_idx](data_on_device)\n",
    "        model_ondevice[batch_idx].move(aggregater)\n",
    "        print(model.location)\n",
    "        print(model.weight.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(model_list[0].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fb2982e66d0>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()\n",
    "model.sned(workers[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-2.8198e-01, -2.1895e-02, -2.8959e-01, -2.0107e-01,  2.2971e-01],\n",
      "          [ 1.8315e-01,  7.7493e-02,  1.6640e-01,  2.1500e-02,  1.6269e-01],\n",
      "          [ 3.7304e-01, -3.2290e-01, -1.3509e-01,  2.8803e-01,  2.2667e-01],\n",
      "          [ 3.1194e-01, -3.9431e-01,  1.6057e-01,  3.3954e-01,  3.6352e-01],\n",
      "          [-3.4737e-01,  2.0403e-01,  2.6506e-01,  1.0429e-01,  2.8679e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.6582e-02, -2.7106e-01,  1.8387e-01, -3.1548e-01,  5.3829e-02],\n",
      "          [-2.3096e-02,  2.5281e-01, -3.1633e-01,  3.5198e-01,  4.2042e-02],\n",
      "          [-2.1132e-01, -2.4991e-01,  3.6416e-01, -3.2156e-01, -1.2817e-01],\n",
      "          [-2.7399e-01,  3.2240e-01, -2.3954e-01, -1.1032e-01,  4.2613e-02],\n",
      "          [-2.7170e-01, -3.2338e-01, -3.1872e-01,  3.4642e-01,  1.2469e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.1491e-02,  3.6591e-01, -1.2837e-01,  3.6525e-01,  2.7922e-01],\n",
      "          [-9.6500e-02,  2.7981e-01, -1.3758e-01, -1.5327e-01,  4.9002e-02],\n",
      "          [ 1.0895e-01,  1.1725e-01,  3.1835e-01,  7.9826e-02,  1.6115e-01],\n",
      "          [ 2.5718e-01,  2.4877e-01,  1.1454e-01, -2.8351e-01, -1.9709e-01],\n",
      "          [ 3.9991e-01,  2.1298e-01,  2.0903e-01, -1.9695e-01,  1.1131e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6582e-01, -1.5958e-01,  6.3809e-02, -6.5951e-02, -3.9821e-01],\n",
      "          [-2.7276e-01,  3.1245e-01, -3.9305e-01,  2.5248e-01,  1.4521e-01],\n",
      "          [ 2.3881e-01, -7.2346e-02, -2.7596e-01,  4.4794e-02, -1.7526e-01],\n",
      "          [-3.9281e-01, -2.8136e-01,  3.2280e-01, -3.9205e-01, -5.2515e-02],\n",
      "          [-2.6365e-01, -1.1381e-01,  9.3166e-02,  2.2630e-03, -3.7055e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.2602e-02, -9.0724e-02,  3.9323e-01, -4.3323e-02,  1.0543e-01],\n",
      "          [ 1.3548e-01, -3.4944e-01,  3.9328e-01, -3.1585e-02,  7.6700e-02],\n",
      "          [ 1.1015e-01, -2.6561e-01, -3.9155e-01, -2.8933e-01,  2.0568e-01],\n",
      "          [-9.5918e-02,  7.8192e-02,  1.5591e-01, -3.6159e-01,  2.8651e-02],\n",
      "          [-2.4480e-01, -2.4811e-01, -3.4393e-01, -2.2822e-01, -1.2309e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4562e-01,  7.1022e-02,  1.1997e-01,  3.6166e-01, -2.0606e-01],\n",
      "          [ 2.4404e-01, -6.4657e-02,  5.5640e-02,  1.2667e-01, -2.0713e-02],\n",
      "          [ 3.7170e-01, -2.0739e-01, -2.9119e-01, -2.2373e-01, -2.3826e-01],\n",
      "          [-1.3098e-01, -4.4391e-02,  1.0707e-01, -3.8458e-01,  1.5596e-01],\n",
      "          [-3.4668e-01, -3.2186e-01, -1.1187e-01, -2.3591e-01,  3.6850e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6947e-01, -1.7836e-01, -1.6947e-01, -3.7380e-01, -4.4935e-02],\n",
      "          [-5.2373e-03,  2.7725e-01, -3.6839e-01, -5.0601e-02,  3.5585e-01],\n",
      "          [-1.5956e-01,  3.6777e-01,  1.5354e-01,  1.7593e-01, -1.1859e-01],\n",
      "          [ 1.5696e-01,  1.4782e-01, -1.1540e-01,  3.4920e-01, -5.9674e-02],\n",
      "          [-3.5170e-01, -3.9228e-01, -2.6926e-01,  7.8499e-05, -2.0557e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.4381e-02, -2.6769e-01, -3.4976e-01,  1.0883e-01,  3.3400e-01],\n",
      "          [ 2.9885e-01, -2.8092e-01,  2.7339e-02,  2.7794e-01,  3.1863e-01],\n",
      "          [ 1.7252e-01,  2.4901e-01,  3.9112e-01, -1.2789e-01, -1.5227e-01],\n",
      "          [ 2.2661e-02,  9.3353e-02, -1.8183e-01, -1.9586e-02, -3.3091e-01],\n",
      "          [-1.5949e-01, -3.4098e-01, -5.2835e-02, -9.7517e-02,  6.1492e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3050e-03, -2.8121e-01, -2.0543e-01,  2.4206e-02, -7.4157e-02],\n",
      "          [-3.9721e-01,  1.2658e-01, -1.5490e-01, -1.9827e-01,  2.5521e-01],\n",
      "          [-2.5662e-01,  2.1718e-01,  5.6141e-02,  7.7041e-02, -1.8819e-01],\n",
      "          [-2.2882e-03,  1.5536e-01, -1.7759e-01, -1.4177e-02, -4.2783e-02],\n",
      "          [-1.9400e-01, -9.9163e-02,  2.0381e-01,  3.2901e-01,  7.7098e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1838e-01,  2.8805e-01, -2.2198e-01, -2.2009e-01, -2.7927e-01],\n",
      "          [-3.0524e-01,  1.1558e-01,  3.5655e-01,  1.8446e-02,  1.0898e-01],\n",
      "          [-1.4398e-01, -1.7294e-01,  2.2117e-02,  6.4102e-02,  2.3005e-01],\n",
      "          [ 2.7181e-02,  3.0667e-01, -2.2773e-01,  1.6635e-01,  2.0143e-02],\n",
      "          [ 1.0916e-01,  2.5611e-01, -3.7556e-02,  1.0358e-01,  3.9954e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2416e-01, -2.5254e-01,  3.7485e-01, -3.6863e-01,  3.5208e-01],\n",
      "          [ 2.1680e-01,  2.1902e-01, -1.1664e-01,  2.6566e-01,  7.6975e-02],\n",
      "          [ 1.7723e-01, -2.8795e-01, -3.3467e-01, -3.5350e-01, -2.5804e-01],\n",
      "          [ 1.0197e-01,  3.8966e-01,  1.4566e-01, -2.8514e-01,  3.2912e-01],\n",
      "          [-2.1049e-02,  3.5709e-01, -3.1547e-01, -3.4435e-01,  1.9026e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.2628e-02, -3.3355e-01, -3.1520e-01, -3.1839e-01,  1.0454e-01],\n",
      "          [ 1.5432e-01, -1.6189e-01,  8.7969e-03,  2.3321e-01, -2.7104e-01],\n",
      "          [ 2.3582e-01, -3.2190e-01,  1.3839e-02, -3.3447e-01, -3.8431e-01],\n",
      "          [-1.3856e-01,  1.2679e-01, -8.2043e-02,  3.9731e-01, -1.8759e-01],\n",
      "          [-2.5679e-01,  1.5393e-01, -2.4946e-01,  3.1805e-01, -2.2487e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6594e-01, -1.0552e-01,  3.3603e-01, -3.7392e-01,  3.5263e-01],\n",
      "          [ 1.2825e-01, -3.6169e-01, -2.1985e-01, -4.2090e-03, -1.9167e-01],\n",
      "          [-3.1395e-01,  4.0938e-02,  1.9854e-01,  3.8540e-01,  1.0413e-01],\n",
      "          [ 3.8829e-02, -3.7629e-01,  3.1855e-01, -2.6123e-01, -3.9405e-01],\n",
      "          [-1.0922e-01, -3.2212e-01,  2.5817e-03, -1.6382e-02, -2.8921e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1672e-01,  1.4740e-02, -6.0410e-02,  3.6408e-01, -2.9513e-03],\n",
      "          [ 3.8627e-01, -1.3139e-01, -2.2667e-01,  4.3348e-03,  3.5322e-01],\n",
      "          [-2.5036e-02,  2.1034e-01, -2.1448e-01, -1.9077e-02,  7.1049e-02],\n",
      "          [ 3.6630e-01,  1.5338e-01,  1.5229e-01, -2.6947e-01,  1.7379e-01],\n",
      "          [ 3.4905e-01, -1.6763e-01,  1.7912e-01,  1.2330e-01,  3.3043e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1001e-01, -4.0000e-02, -1.6483e-01,  5.3893e-03,  3.4542e-01],\n",
      "          [ 3.6277e-01, -8.3475e-02, -1.8151e-01,  1.6228e-01, -1.1672e-01],\n",
      "          [-2.9543e-01, -3.0988e-01, -1.8082e-01, -1.4584e-01,  9.3259e-02],\n",
      "          [ 6.8738e-02, -1.7462e-02,  3.8038e-01,  2.8647e-01, -3.4940e-01],\n",
      "          [-1.1307e-02,  1.7019e-01,  3.7087e-01,  1.7250e-02,  6.5384e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.6027e-01,  3.3268e-01, -2.6638e-01,  5.8987e-02,  2.2046e-01],\n",
      "          [-3.3354e-01,  1.9106e-01,  2.5310e-01, -1.9321e-02, -5.9078e-02],\n",
      "          [-3.4840e-01, -2.3753e-01, -1.4129e-01, -1.3630e-01, -1.1926e-01],\n",
      "          [-3.8156e-01,  5.5595e-02, -9.8550e-02, -2.3789e-01,  2.4618e-01],\n",
      "          [ 1.4454e-01,  2.6420e-01, -3.9693e-01,  1.0422e-01, -9.4931e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.1129e-01,  2.5258e-01, -4.4685e-02, -1.1493e-01, -2.7055e-04],\n",
      "          [ 2.3182e-01, -1.5269e-02,  6.1825e-02,  1.6766e-01,  2.2418e-01],\n",
      "          [-2.7029e-01,  2.0609e-01,  1.8765e-01,  2.7551e-01, -1.8906e-01],\n",
      "          [ 2.1509e-01, -2.5216e-01,  1.3366e-02, -8.2573e-02,  2.0908e-01],\n",
      "          [-2.5357e-01,  3.8794e-01,  1.3739e-01,  2.6607e-01, -1.4800e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.8148e-02, -2.5287e-01, -4.8634e-03,  1.2787e-01, -5.7087e-02],\n",
      "          [ 2.0473e-01, -2.6002e-01,  3.2648e-01, -2.2390e-01,  1.2785e-05],\n",
      "          [-3.4105e-01,  2.0742e-01, -3.7949e-01,  2.2860e-01,  3.2042e-01],\n",
      "          [-1.9040e-01, -3.5563e-01,  2.9113e-01,  3.8608e-01, -2.9124e-02],\n",
      "          [ 3.1762e-01,  1.6228e-01,  3.7712e-01,  4.8741e-02, -8.7631e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3783e-01, -3.4163e-01,  4.7794e-02,  2.5640e-01, -6.1597e-02],\n",
      "          [ 1.9435e-02,  1.9096e-02,  2.8279e-01, -2.8880e-01,  1.7034e-01],\n",
      "          [-2.6624e-01, -2.6987e-01,  1.7206e-01,  1.5765e-01, -7.6548e-02],\n",
      "          [-2.3062e-02, -1.6680e-01, -1.7686e-01,  3.5165e-01,  2.0732e-01],\n",
      "          [ 3.3107e-01,  1.3572e-02,  3.0359e-01, -3.2555e-01, -2.6555e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4734e-01, -1.7742e-01,  1.7783e-01, -1.8185e-01, -3.7695e-01],\n",
      "          [ 1.2532e-01, -3.9257e-01, -9.2124e-02, -1.3690e-01,  1.0602e-01],\n",
      "          [ 4.6445e-02, -3.1820e-01,  3.7388e-01, -1.1755e-01, -2.0641e-01],\n",
      "          [-3.4275e-01,  3.1737e-01,  1.4543e-01,  3.1157e-01, -2.8537e-01],\n",
      "          [ 1.0872e-03,  2.4466e-01,  4.9538e-02, -1.3596e-01, -2.6442e-01]]]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1187, -0.0753,  0.0848,  0.0420,  0.1719, -0.3697,  0.1947, -0.0692,\n",
      "         0.3795, -0.2718,  0.2730, -0.3260,  0.1961,  0.2239, -0.3864, -0.3159,\n",
      "        -0.0622,  0.0110,  0.1710, -0.0213], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-3.4861e-02, -2.7184e-02,  3.3224e-03,  8.5887e-03, -3.7156e-03],\n",
      "          [ 8.9078e-02, -2.6241e-02,  8.3471e-02, -8.5000e-02, -7.7203e-02],\n",
      "          [ 6.5453e-02, -3.4000e-02, -1.5717e-02,  6.2418e-02, -7.6561e-02],\n",
      "          [-5.8714e-02, -6.9989e-02,  6.5488e-02,  5.8605e-03,  2.8066e-02],\n",
      "          [-2.2165e-05, -3.3109e-02,  9.7454e-03,  7.1283e-03, -7.2701e-02]],\n",
      "\n",
      "         [[-2.7309e-02,  5.0523e-02, -4.1551e-02, -4.6386e-02, -4.3695e-02],\n",
      "          [-7.1957e-02,  7.6542e-02, -4.5822e-02, -7.1325e-02,  5.7038e-02],\n",
      "          [ 2.9119e-02, -7.9136e-02, -8.7478e-02, -4.4595e-02, -6.9009e-02],\n",
      "          [-7.8172e-02,  6.8506e-03,  1.9837e-02, -3.9574e-02, -5.2690e-02],\n",
      "          [-7.3457e-03,  4.0819e-04, -2.2635e-02, -8.1005e-02, -3.0935e-02]],\n",
      "\n",
      "         [[ 4.6746e-02,  1.0900e-02, -3.2833e-02,  5.8658e-03,  5.9878e-02],\n",
      "          [-8.4059e-02, -1.0078e-03, -4.9510e-02, -1.1060e-04,  8.2631e-02],\n",
      "          [-6.7118e-02, -5.4295e-02,  6.2961e-02, -4.1195e-02, -5.9446e-02],\n",
      "          [ 7.1662e-02,  6.2708e-02, -3.5800e-02,  5.3163e-02,  8.0947e-02],\n",
      "          [-7.7441e-02, -2.0969e-02, -1.5463e-02, -6.8195e-02, -1.3372e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5374e-02, -4.9410e-02, -3.1120e-02, -3.6805e-02, -4.7823e-02],\n",
      "          [ 4.7376e-02, -3.9111e-02, -2.4745e-02,  1.6078e-02, -7.1852e-02],\n",
      "          [ 8.3958e-02,  7.5414e-02, -8.1383e-02, -6.8913e-02,  4.0621e-02],\n",
      "          [ 4.2040e-02, -4.3165e-02,  2.8139e-02,  2.3727e-02, -8.3412e-02],\n",
      "          [-6.1487e-02,  8.9300e-02, -7.4098e-02,  3.2656e-02, -2.8355e-02]],\n",
      "\n",
      "         [[ 8.8707e-02, -4.4194e-02,  3.6636e-02,  3.1725e-02,  4.4013e-03],\n",
      "          [ 2.9570e-02, -2.4446e-02, -2.1816e-03, -2.7793e-02, -3.4761e-02],\n",
      "          [ 5.3218e-02, -6.6517e-02,  6.8890e-02,  6.2805e-02,  6.1891e-02],\n",
      "          [ 5.6828e-02,  7.3085e-02,  6.8041e-02, -5.9358e-02, -1.8753e-02],\n",
      "          [ 1.2871e-02,  7.4758e-03, -8.6991e-02, -5.0834e-03,  2.3624e-02]],\n",
      "\n",
      "         [[ 4.7734e-02, -2.0548e-02, -4.2507e-02,  7.7877e-02, -1.9144e-03],\n",
      "          [-7.8460e-02, -1.8040e-02,  1.3713e-02,  2.7932e-02,  2.4101e-02],\n",
      "          [ 3.2909e-02,  6.5259e-02, -3.9004e-02, -1.4856e-04,  7.2639e-02],\n",
      "          [ 6.8569e-02, -3.0483e-02, -7.5235e-02, -6.7698e-02,  8.7212e-02],\n",
      "          [ 5.8864e-02,  1.0334e-02, -7.4800e-02,  8.1319e-02, -5.5190e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1560e-02,  4.6206e-02, -8.2022e-02, -3.9899e-02,  3.0654e-02],\n",
      "          [-7.0661e-02, -1.9013e-02,  7.6912e-02,  5.1550e-02,  8.4335e-04],\n",
      "          [-4.7900e-02, -6.8480e-02, -2.6391e-02,  8.3382e-02,  5.7949e-02],\n",
      "          [ 3.4507e-02, -2.5761e-02, -4.8874e-02,  7.0715e-02,  1.4924e-04],\n",
      "          [ 8.2038e-02, -4.2167e-02,  8.6798e-03, -3.3934e-02,  5.5408e-02]],\n",
      "\n",
      "         [[ 4.8836e-02,  3.7366e-02, -6.7843e-02, -8.2891e-02, -6.1835e-03],\n",
      "          [ 6.5436e-02, -2.0220e-02,  6.6947e-02,  1.2644e-02,  2.6239e-02],\n",
      "          [ 6.3517e-02, -5.3578e-02,  1.6650e-02, -8.4715e-02,  3.3741e-02],\n",
      "          [-6.3327e-03,  4.7721e-02,  3.0500e-02, -1.7724e-02, -1.3816e-02],\n",
      "          [ 8.1992e-02,  6.9699e-02,  2.8785e-02,  8.8052e-02, -4.4773e-02]],\n",
      "\n",
      "         [[ 2.1835e-02,  8.2717e-02, -6.7234e-02,  6.4576e-02, -1.0798e-02],\n",
      "          [ 5.0485e-02, -1.2739e-02, -2.4147e-03, -3.8777e-02, -1.4698e-02],\n",
      "          [-6.1792e-02,  6.5987e-03,  4.9985e-03,  5.1242e-02,  6.9186e-02],\n",
      "          [ 2.3685e-02, -1.3027e-02,  2.0280e-02, -2.0393e-02, -6.6308e-02],\n",
      "          [ 5.5178e-02,  5.4883e-02,  3.0443e-02, -2.3551e-02,  3.4110e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.6095e-02, -7.2552e-02, -6.2734e-02, -8.0497e-02,  6.2190e-02],\n",
      "          [ 2.1506e-03, -6.9250e-02, -5.0642e-02,  1.0898e-02, -5.1837e-02],\n",
      "          [ 2.9817e-02, -2.2359e-02, -1.7793e-02, -7.5651e-02,  8.9187e-02],\n",
      "          [-5.3578e-02,  1.1187e-02,  5.7201e-02, -2.5446e-02, -8.6502e-02],\n",
      "          [-8.2613e-02,  8.3918e-02, -2.7269e-02,  6.7570e-02,  4.8850e-04]],\n",
      "\n",
      "         [[ 4.2110e-02, -4.3392e-02, -6.5099e-03,  1.7838e-02,  4.2338e-02],\n",
      "          [-3.9689e-02, -6.8933e-02, -1.7964e-03,  4.2498e-02,  8.4266e-02],\n",
      "          [-2.6221e-02, -1.5020e-02, -2.4549e-02,  5.3433e-02,  3.0902e-02],\n",
      "          [-8.8320e-02, -2.2262e-03, -9.3445e-03,  8.9239e-02,  7.3775e-02],\n",
      "          [ 7.8342e-02,  4.2912e-02,  5.7264e-02,  5.3642e-02,  7.1818e-02]],\n",
      "\n",
      "         [[ 4.7149e-03, -5.9287e-02,  7.2749e-02, -1.2492e-02, -7.1524e-02],\n",
      "          [ 1.5427e-02,  8.6814e-03, -8.2518e-02, -1.2065e-02,  4.1612e-02],\n",
      "          [-5.7494e-03,  4.5213e-02,  5.4125e-02, -4.3012e-02,  4.6052e-02],\n",
      "          [-1.7683e-02,  4.6825e-02, -2.5068e-02,  5.0075e-02,  8.2253e-02],\n",
      "          [-6.5497e-02, -2.0961e-02, -6.7423e-02, -7.5571e-02,  8.1332e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1437e-02,  2.8626e-02,  8.5695e-02, -7.3336e-03, -5.0293e-02],\n",
      "          [ 8.7421e-02, -3.1666e-03,  2.3511e-02, -3.6850e-02,  4.0002e-02],\n",
      "          [ 2.7165e-02, -8.1677e-02, -1.1298e-02, -7.0234e-02,  6.2442e-02],\n",
      "          [-1.7460e-02,  7.9686e-02,  1.4233e-02,  5.6441e-03,  4.4205e-02],\n",
      "          [ 1.8393e-02,  3.8710e-02, -2.2575e-02,  3.3165e-02, -3.9101e-02]],\n",
      "\n",
      "         [[ 6.3359e-02, -2.5618e-02, -5.0068e-02,  2.3276e-02, -8.3423e-02],\n",
      "          [ 3.2395e-02, -3.6577e-02,  6.4002e-02,  1.7487e-02, -1.0312e-02],\n",
      "          [-7.1671e-02,  2.4136e-02, -6.4311e-02,  3.9805e-02,  2.0181e-02],\n",
      "          [ 4.9203e-02,  6.5116e-02,  8.9349e-02, -5.0018e-02,  3.8923e-02],\n",
      "          [ 1.3692e-02, -5.9137e-02,  1.1691e-02,  7.3752e-02, -7.1353e-02]],\n",
      "\n",
      "         [[ 6.4328e-02,  2.1539e-02,  3.6923e-02, -6.6698e-02,  6.3471e-02],\n",
      "          [-7.8386e-02, -1.6349e-02,  2.2730e-02,  5.8676e-02,  1.9688e-02],\n",
      "          [ 5.4910e-02,  6.9565e-02, -5.8148e-02,  1.3983e-02, -7.1454e-02],\n",
      "          [-8.0926e-02,  3.6044e-02, -7.2309e-02,  1.9135e-02, -7.7128e-02],\n",
      "          [-3.2734e-02,  7.2016e-02, -3.6613e-02, -9.3108e-04, -8.2939e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3589e-02, -4.7601e-03,  3.0890e-02,  6.8994e-02,  1.6253e-02],\n",
      "          [-1.3179e-02, -1.3168e-02, -7.8996e-02,  8.3053e-02,  5.5811e-02],\n",
      "          [ 4.4946e-02, -5.2744e-02, -3.7765e-02, -1.4376e-02, -3.9110e-02],\n",
      "          [ 1.5470e-02, -4.0579e-02, -3.2634e-02, -2.0063e-02,  4.1828e-02],\n",
      "          [-7.2741e-02,  8.0710e-02, -8.0877e-02,  2.3922e-03,  2.8826e-02]],\n",
      "\n",
      "         [[-4.8486e-02,  4.4916e-02, -4.3541e-02, -8.1917e-02, -7.9002e-02],\n",
      "          [-5.0562e-02, -8.4193e-02,  3.1727e-02,  5.9057e-02,  1.6427e-02],\n",
      "          [ 2.5558e-02, -3.2084e-02, -5.3810e-02, -8.4216e-02,  5.8005e-02],\n",
      "          [-7.5378e-03,  6.7425e-02, -8.5409e-02, -1.2446e-02,  5.8503e-02],\n",
      "          [ 4.2063e-02, -2.8129e-02,  5.9560e-02, -1.4630e-02,  8.9084e-02]],\n",
      "\n",
      "         [[ 5.9594e-02,  2.6884e-02,  4.3815e-02,  1.9017e-02, -1.4926e-02],\n",
      "          [-8.2429e-02,  7.6999e-02, -8.1574e-02, -2.4804e-02,  5.9459e-02],\n",
      "          [-8.4952e-02,  1.7558e-02,  5.6969e-02,  4.6956e-02, -1.5719e-02],\n",
      "          [ 8.7788e-02,  3.3313e-02,  1.4928e-02, -4.1664e-02,  3.6416e-02],\n",
      "          [-8.2827e-02,  3.5409e-02,  4.7834e-02,  7.2189e-02,  7.6387e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.4498e-02, -7.9211e-02, -5.6139e-02, -4.4114e-02,  8.6241e-02],\n",
      "          [-7.2433e-02,  4.3628e-02, -3.8728e-02, -5.4103e-02,  1.5482e-02],\n",
      "          [ 4.8701e-02, -4.7464e-02,  2.5920e-02, -5.9053e-02,  2.1751e-02],\n",
      "          [ 3.2432e-02,  2.6853e-02,  2.3068e-02, -4.5633e-02, -2.3226e-02],\n",
      "          [ 8.8847e-02,  4.3027e-02, -7.4527e-02, -5.6760e-02,  4.4556e-02]],\n",
      "\n",
      "         [[ 4.9705e-02,  2.6241e-03, -6.6249e-02,  7.3324e-02, -3.5422e-02],\n",
      "          [ 8.2894e-02, -2.1474e-02,  8.3043e-02,  6.0682e-02,  2.1210e-03],\n",
      "          [ 5.5557e-02,  4.0093e-02, -3.1590e-02, -2.9834e-02,  8.1700e-02],\n",
      "          [-3.6327e-02,  7.1084e-02,  5.8122e-03,  6.2601e-02, -2.0929e-02],\n",
      "          [-5.4391e-02, -7.0311e-02, -5.1128e-02, -3.6222e-02,  3.2438e-02]],\n",
      "\n",
      "         [[ 5.7693e-02,  7.7220e-02, -7.4012e-02,  5.3524e-02,  1.9015e-02],\n",
      "          [-2.4600e-02,  8.6666e-02, -4.6905e-02, -4.7027e-02,  3.6340e-02],\n",
      "          [ 7.7092e-02, -3.0965e-02,  3.8472e-02, -3.1116e-02,  6.9337e-02],\n",
      "          [-5.8537e-02,  1.1159e-02,  3.9945e-02,  4.4435e-02, -6.3393e-02],\n",
      "          [-1.1512e-02, -2.8330e-02,  7.1022e-02,  7.4934e-02, -2.1987e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.5155e-02, -8.1867e-02,  2.0062e-03,  5.2700e-02,  8.7803e-02],\n",
      "          [-3.7448e-02,  4.4261e-03, -5.7652e-03,  5.4102e-02, -7.4904e-02],\n",
      "          [ 6.1603e-02, -2.1891e-02, -8.6602e-02,  1.4286e-02,  3.6305e-02],\n",
      "          [ 5.0272e-02,  6.5417e-02, -2.3498e-02,  6.0342e-02,  4.9345e-02],\n",
      "          [ 1.2949e-03,  4.1364e-02,  5.3242e-02,  3.9262e-02, -2.8285e-02]],\n",
      "\n",
      "         [[-6.2082e-02, -5.9919e-02,  7.2256e-02,  2.2074e-02,  3.0251e-02],\n",
      "          [ 1.2823e-02,  3.1475e-02, -4.9598e-02, -3.3926e-02, -5.9004e-03],\n",
      "          [ 7.6414e-02, -7.8378e-02, -3.5995e-03,  4.5627e-02,  1.3184e-02],\n",
      "          [ 4.6519e-02, -1.0162e-02,  8.3363e-02, -2.7329e-02,  2.8627e-02],\n",
      "          [ 2.1735e-02,  2.8328e-02,  2.0639e-02, -6.8843e-02,  4.6158e-02]],\n",
      "\n",
      "         [[-7.7418e-03, -9.1768e-03, -6.4069e-02, -5.2680e-02,  5.6091e-03],\n",
      "          [-1.3271e-02, -4.8892e-03,  2.0508e-02,  3.8656e-02,  2.0919e-02],\n",
      "          [-6.1492e-02, -8.6105e-02,  5.4868e-02,  7.6629e-02, -2.8539e-02],\n",
      "          [ 8.9395e-02, -7.3249e-02, -7.0162e-02,  6.0332e-02,  4.8570e-02],\n",
      "          [ 8.3861e-02,  2.1136e-02, -2.4891e-02,  3.2659e-03, -2.5040e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4078e-02,  8.7564e-02, -1.0388e-03,  4.5700e-02,  4.3210e-02],\n",
      "          [ 2.8320e-02, -7.7708e-02, -1.5522e-02, -8.6673e-02,  2.4503e-03],\n",
      "          [ 4.1664e-02,  2.7508e-02, -3.8890e-02, -6.5434e-02, -1.9908e-02],\n",
      "          [-1.8120e-02,  8.4768e-02,  4.7364e-02,  3.9096e-02,  1.9647e-02],\n",
      "          [-7.4274e-02,  2.9758e-02,  2.7394e-02,  3.6976e-02,  1.7336e-02]],\n",
      "\n",
      "         [[-4.3009e-02, -5.7368e-02, -4.3082e-02,  5.2559e-02, -3.0380e-02],\n",
      "          [-2.6930e-02,  2.6732e-02,  4.0194e-02,  4.8227e-02, -7.9492e-02],\n",
      "          [ 8.1326e-02,  7.1750e-02, -3.0365e-02,  6.8847e-02,  4.8380e-02],\n",
      "          [-6.0694e-02, -1.3292e-02,  5.3865e-03,  3.5915e-02,  3.5757e-02],\n",
      "          [-2.4644e-02, -2.4916e-02, -1.2835e-02, -8.4153e-02, -7.3922e-02]],\n",
      "\n",
      "         [[ 3.6443e-02,  5.8953e-02, -3.9044e-02, -4.0917e-02,  2.3153e-02],\n",
      "          [ 4.0881e-02, -3.2650e-02,  3.6338e-02, -4.0540e-02,  8.4695e-02],\n",
      "          [-3.9349e-02,  5.7712e-02, -2.9305e-02,  4.4855e-02, -3.5471e-02],\n",
      "          [ 2.4643e-02,  5.5567e-02, -4.0936e-02,  5.0608e-02,  4.2465e-02],\n",
      "          [-8.2071e-02,  2.9300e-02,  6.6090e-02,  3.4917e-03,  5.8572e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.5579e-02,  3.5279e-03,  2.4172e-02,  8.9014e-02, -2.5212e-02],\n",
      "          [-6.3927e-02,  7.3270e-02,  6.0332e-02, -7.1341e-02, -6.0054e-02],\n",
      "          [-8.7951e-03, -1.8548e-02, -6.6018e-02,  1.6153e-02,  6.5710e-02],\n",
      "          [-7.5570e-02, -3.1942e-02,  3.1064e-02,  4.0957e-02,  7.4977e-02],\n",
      "          [-3.2991e-02, -2.8916e-02, -3.6980e-02,  5.6569e-02, -5.5367e-02]],\n",
      "\n",
      "         [[-5.3852e-02,  6.0786e-02, -3.8167e-02,  6.5661e-02,  3.9159e-02],\n",
      "          [-3.0652e-02, -3.4875e-02,  7.1692e-02,  4.0841e-02, -5.9725e-02],\n",
      "          [-1.3243e-02,  7.3342e-02, -2.1415e-02,  8.9884e-03, -2.0074e-02],\n",
      "          [-1.4046e-02, -5.9566e-02,  3.2390e-02, -6.9458e-02, -1.8858e-02],\n",
      "          [-6.2164e-02,  6.0875e-02, -5.1616e-03, -6.9688e-02,  7.9904e-02]],\n",
      "\n",
      "         [[ 3.1210e-03,  4.2144e-02,  8.1518e-02, -6.8821e-02, -1.9978e-02],\n",
      "          [ 5.7007e-02, -5.7196e-02, -3.4250e-02,  5.2838e-02,  7.5900e-02],\n",
      "          [ 2.4207e-02,  6.8334e-02, -3.8736e-02, -7.9960e-02, -1.3144e-04],\n",
      "          [-3.0088e-02,  6.2330e-02,  6.2143e-02,  3.9240e-02,  8.3104e-02],\n",
      "          [ 1.0531e-02,  8.2157e-02,  3.3407e-02,  2.3868e-02,  4.0041e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2452e-02, -1.4409e-02,  3.3121e-02, -7.3625e-02, -5.4752e-02],\n",
      "          [ 3.6146e-02,  8.5169e-02, -8.8771e-04,  3.2672e-02,  2.0652e-02],\n",
      "          [-8.5116e-02, -8.7920e-02,  8.6567e-02, -5.8485e-02,  7.3345e-02],\n",
      "          [ 1.6936e-03, -7.0994e-02,  6.7256e-02,  3.3432e-02,  6.4110e-02],\n",
      "          [-3.0235e-02,  1.4964e-02,  3.7998e-02, -1.6616e-02, -1.0156e-02]],\n",
      "\n",
      "         [[-5.1397e-03, -4.0627e-02, -2.6662e-02,  6.8473e-02,  2.4954e-02],\n",
      "          [ 8.6640e-02,  8.6442e-02,  3.5932e-02, -1.4310e-02, -6.6759e-02],\n",
      "          [ 7.0314e-02, -3.9258e-02,  6.9264e-02, -8.4615e-02,  5.1431e-02],\n",
      "          [ 1.1847e-02,  7.3975e-02,  4.4365e-02,  9.0710e-04,  2.9455e-02],\n",
      "          [ 7.1231e-02,  5.4844e-02,  7.2091e-02,  3.6743e-02, -1.8607e-02]],\n",
      "\n",
      "         [[-5.8499e-03,  9.5812e-03, -3.8028e-02, -1.1772e-03, -5.8330e-02],\n",
      "          [-3.8476e-02,  3.1022e-02,  3.4282e-02,  6.1541e-02,  4.8391e-02],\n",
      "          [-8.3796e-02,  1.9428e-02, -4.5822e-02,  6.1125e-03, -8.4494e-02],\n",
      "          [ 6.9365e-02, -5.0101e-02,  5.7880e-02,  7.3676e-02, -2.7954e-02],\n",
      "          [-1.9121e-02,  4.0529e-02, -6.7625e-02,  9.7305e-03, -5.5423e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.8412e-02, -4.6740e-02,  8.3747e-02,  1.8559e-02, -3.7295e-02],\n",
      "          [-6.0497e-02, -3.6263e-02, -4.5323e-02,  5.6093e-02,  3.6989e-02],\n",
      "          [ 4.0223e-02, -3.2576e-02, -7.8979e-02,  8.7499e-02, -4.4673e-02],\n",
      "          [-5.6147e-02, -2.2521e-02, -2.9920e-03,  7.3907e-02, -6.7791e-02],\n",
      "          [ 7.7212e-02, -7.8413e-02, -3.3645e-02, -8.5684e-02, -7.8950e-02]],\n",
      "\n",
      "         [[-6.0635e-02, -5.4332e-02, -6.1401e-02,  3.3636e-02, -8.3477e-02],\n",
      "          [ 6.6247e-02,  6.2036e-02, -7.8954e-02, -5.0475e-02,  5.3235e-03],\n",
      "          [ 8.2353e-02,  6.8204e-02, -7.1634e-02,  6.5501e-02,  6.5234e-02],\n",
      "          [ 3.5724e-02,  7.3576e-02,  8.4855e-02,  4.9646e-02,  4.7592e-03],\n",
      "          [ 7.5741e-02,  5.6304e-02,  4.4829e-02, -1.7854e-02, -1.9400e-02]],\n",
      "\n",
      "         [[ 4.0131e-03,  5.1053e-02,  1.2029e-02,  8.5495e-02,  3.9225e-02],\n",
      "          [ 8.6329e-02, -7.4736e-02,  4.9726e-02, -1.1663e-02, -4.2782e-02],\n",
      "          [-7.3435e-03, -2.9113e-02, -5.7293e-02,  2.1323e-02, -4.6932e-02],\n",
      "          [ 8.0735e-02,  2.3486e-03, -3.4335e-02,  8.4617e-02,  3.2171e-02],\n",
      "          [-6.1013e-02, -8.6127e-02,  3.4007e-02, -1.4227e-03,  2.6972e-02]]]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0409,  0.0840,  0.0729,  0.0620, -0.0442,  0.0064, -0.0096,  0.0406,\n",
      "        -0.0790,  0.0524, -0.0040,  0.0325,  0.0729, -0.0026, -0.0405,  0.0360,\n",
      "         0.0270,  0.0381,  0.0526,  0.0584, -0.0153, -0.0551,  0.0145,  0.0189,\n",
      "         0.0711, -0.0348,  0.0029,  0.0414,  0.0826,  0.0325, -0.0746,  0.0316,\n",
      "        -0.0181,  0.0849, -0.0743, -0.0708, -0.0863,  0.0201, -0.0032,  0.0006,\n",
      "        -0.0390, -0.0090,  0.0470, -0.0817,  0.0091, -0.0649, -0.0707,  0.0021,\n",
      "        -0.0469, -0.0492], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0591,  0.0014, -0.0263,  ...,  0.0266,  0.0553,  0.0100],\n",
      "        [-0.0012, -0.0177,  0.0099,  ...,  0.0457, -0.0684,  0.0481],\n",
      "        [-0.0142, -0.0688,  0.0563,  ..., -0.0187,  0.0088,  0.0487],\n",
      "        ...,\n",
      "        [-0.0358, -0.0588, -0.0027,  ...,  0.0245, -0.0522,  0.0222],\n",
      "        [-0.0147,  0.0059, -0.0020,  ..., -0.0005,  0.0597,  0.0011],\n",
      "        [ 0.0446, -0.0646, -0.0153,  ...,  0.0652,  0.0416, -0.0160]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 5.9020e-02, -3.7937e-02, -7.6575e-03,  6.5423e-02,  3.8590e-02,\n",
      "        -4.5724e-02, -3.1569e-02,  4.0762e-02, -3.3798e-02, -5.2954e-02,\n",
      "        -4.1515e-02, -1.1391e-02, -4.3984e-02,  3.7325e-02,  2.8706e-02,\n",
      "        -3.4245e-02, -2.3269e-02, -4.4486e-02,  1.3234e-02,  1.4264e-02,\n",
      "         6.9497e-02,  5.8629e-02,  8.8471e-03,  3.3637e-02,  2.0953e-02,\n",
      "        -9.5666e-03,  2.9725e-02,  4.8515e-02,  2.3186e-03, -6.4946e-02,\n",
      "        -1.9301e-02,  1.6523e-02, -6.6542e-02, -4.6306e-02, -1.9795e-02,\n",
      "        -3.7433e-02, -3.4715e-02, -3.3547e-02,  4.8001e-02,  3.8807e-02,\n",
      "        -4.2724e-02,  1.0966e-02,  9.4156e-03, -4.1934e-02,  2.5118e-02,\n",
      "        -1.5848e-02,  2.0334e-02,  2.8288e-02,  7.0617e-03, -2.1020e-02,\n",
      "        -6.4499e-02, -2.7973e-02,  1.7969e-02, -1.7190e-03,  7.1859e-03,\n",
      "        -4.2680e-02,  1.8534e-02, -2.4659e-02,  6.0547e-02, -1.6909e-02,\n",
      "        -1.9491e-02,  3.0412e-02, -1.0324e-02, -5.0364e-02, -3.2103e-02,\n",
      "         6.9761e-02, -5.7325e-02, -5.8351e-02,  6.9262e-03, -5.2830e-02,\n",
      "         5.8073e-02,  3.2839e-02,  3.6905e-02, -1.3676e-02, -4.4824e-02,\n",
      "        -3.3297e-02,  6.0755e-02, -5.5342e-02,  4.9228e-02,  7.0606e-02,\n",
      "         1.2402e-02,  2.9184e-02,  4.7221e-02, -6.6294e-02, -6.0187e-02,\n",
      "         1.3341e-02, -6.4590e-02, -6.1634e-02,  3.6237e-02, -5.6992e-02,\n",
      "         4.3863e-02, -4.4114e-02,  3.7935e-02,  4.7327e-02, -1.5194e-02,\n",
      "         3.2929e-02,  2.7642e-02, -3.9007e-02, -9.4413e-03, -5.5999e-02,\n",
      "         6.7225e-04, -5.4632e-02, -3.5990e-02,  4.6572e-02, -4.7081e-02,\n",
      "        -2.6468e-02, -3.1561e-02,  6.1836e-02, -6.3825e-02,  5.9582e-02,\n",
      "         6.0796e-02, -3.4992e-02, -3.6513e-02, -3.9309e-04, -3.2218e-02,\n",
      "         5.9792e-02, -2.8966e-02, -6.2768e-02, -5.5773e-02, -2.4228e-02,\n",
      "        -6.2694e-02, -3.1297e-03, -2.0514e-03, -6.5821e-02,  3.0136e-02,\n",
      "        -5.4474e-02, -3.7341e-02, -2.3735e-02,  5.5698e-02,  3.4864e-02,\n",
      "         3.3849e-02,  5.9515e-02, -1.6823e-02,  6.2803e-03, -6.9984e-02,\n",
      "        -3.6446e-02, -1.4024e-02,  2.4114e-02,  1.8786e-02,  3.2383e-02,\n",
      "         3.1478e-02,  6.5824e-02,  1.9581e-02, -1.2906e-02, -6.2946e-02,\n",
      "         1.2124e-02,  6.6322e-02,  1.5215e-02,  2.2080e-02,  2.9108e-02,\n",
      "        -7.7448e-04, -4.1228e-02,  1.1103e-02,  4.4952e-02, -6.7953e-02,\n",
      "         5.6484e-02, -6.0969e-02,  3.8985e-02, -5.3860e-02, -4.5954e-02,\n",
      "        -3.8856e-02, -3.4368e-02,  2.9906e-02,  4.2902e-02,  2.8253e-02,\n",
      "        -2.5871e-02,  1.6979e-02, -3.6181e-02,  6.1798e-03,  3.8720e-02,\n",
      "         1.8875e-02, -8.9653e-05, -1.5129e-02, -1.9277e-02, -5.6906e-02,\n",
      "        -3.7755e-02,  3.6105e-02,  5.7455e-02, -6.2990e-02, -7.0482e-02,\n",
      "        -5.8167e-02,  6.0995e-02,  7.4355e-03,  1.9112e-02, -4.2924e-03,\n",
      "        -2.1356e-02, -1.7913e-02, -5.5018e-02, -4.9087e-02, -3.6817e-02,\n",
      "         5.0411e-02,  1.7732e-02,  1.2150e-02, -5.7972e-03,  4.6710e-03,\n",
      "         5.2577e-02, -2.1913e-02, -3.1003e-04, -2.3594e-02, -6.0581e-02,\n",
      "         4.2932e-02,  6.6092e-02,  4.5186e-02, -1.6720e-02,  5.1022e-03,\n",
      "        -1.2176e-02, -6.2315e-02, -3.6213e-03,  4.3485e-02, -5.3419e-02,\n",
      "         5.5616e-02, -3.9915e-02,  2.3427e-02, -5.4376e-03, -2.6674e-03,\n",
      "         2.6201e-02, -5.3074e-02, -2.7073e-02, -6.1908e-02,  3.3762e-02,\n",
      "        -3.1924e-03, -1.6054e-02, -1.8589e-02,  6.7497e-02, -5.7908e-02,\n",
      "         1.0466e-02,  6.6201e-02,  5.6722e-02, -4.3157e-02, -2.5584e-02,\n",
      "         5.5829e-02,  4.0406e-02,  9.2469e-05, -7.3131e-03,  6.7937e-02,\n",
      "         2.0390e-03,  1.5325e-02,  6.0759e-02,  7.3605e-03, -2.9076e-02,\n",
      "         3.6387e-02,  4.5421e-02, -2.7884e-02,  2.9743e-02, -1.2584e-02,\n",
      "         7.0381e-02, -4.9701e-02,  2.1688e-02, -6.4613e-02, -4.7865e-02,\n",
      "        -2.0955e-02, -3.2207e-02, -1.1006e-02,  3.0957e-02,  6.1104e-02,\n",
      "        -4.6324e-02, -3.6696e-02, -6.9895e-02, -2.9094e-02, -2.6690e-02,\n",
      "         4.5617e-02, -6.2614e-03,  4.7825e-02,  5.1097e-02,  3.8164e-02,\n",
      "        -3.4943e-02, -3.8630e-02, -4.7071e-02, -6.6372e-02, -6.5125e-02,\n",
      "        -3.2791e-02, -2.6262e-04, -4.9708e-02, -3.1884e-02, -2.5236e-02,\n",
      "        -2.3263e-02, -2.3960e-02,  5.7466e-04, -2.7225e-03,  4.9873e-02,\n",
      "        -5.1481e-02,  1.9808e-02,  7.5943e-03, -5.8459e-03, -3.3574e-02,\n",
      "         5.4891e-02, -6.3314e-02, -6.7084e-03, -4.1105e-02,  6.2736e-02,\n",
      "         4.0729e-02,  5.0857e-02, -1.4384e-02,  2.6027e-02, -1.2641e-02,\n",
      "        -3.8160e-02,  8.1303e-03,  2.8631e-02,  4.7481e-02, -6.7682e-02,\n",
      "        -3.0596e-02,  5.8350e-02,  6.6656e-02, -1.7202e-03, -5.4974e-02,\n",
      "         4.9234e-02, -2.8649e-02, -1.1025e-02,  4.1438e-02,  2.4118e-02,\n",
      "        -2.0107e-02,  5.4661e-02, -3.9511e-02,  3.6998e-02, -4.1752e-02,\n",
      "         6.3118e-02, -2.2701e-02,  4.8237e-02,  6.5721e-02,  5.8608e-02,\n",
      "        -1.4569e-02, -3.0311e-02,  6.4336e-02,  4.0541e-02,  7.0319e-02,\n",
      "         1.4854e-02,  5.5423e-02, -3.2932e-02,  2.2414e-02,  2.6338e-02,\n",
      "        -1.9865e-02,  3.7269e-03,  1.3958e-02, -6.0950e-02, -2.1294e-03,\n",
      "        -3.3802e-03, -6.1174e-02, -4.2387e-02, -3.4417e-02, -5.3802e-02,\n",
      "        -8.8651e-03, -5.3419e-03, -4.8363e-02, -7.7855e-04,  6.4350e-02,\n",
      "         6.8880e-02,  6.8570e-02, -1.3345e-02, -1.0090e-02,  4.9777e-02,\n",
      "         1.4328e-02, -5.2631e-02,  5.7871e-02,  6.7648e-02,  6.9318e-02,\n",
      "        -8.1005e-03, -2.9121e-02,  4.0331e-02,  4.8746e-02,  6.0084e-02,\n",
      "         5.2210e-02, -1.0534e-02,  6.9005e-02,  9.3249e-03, -4.2272e-02,\n",
      "         4.4936e-02, -4.6488e-02,  4.0312e-02,  3.6786e-02,  5.7029e-02,\n",
      "         4.8512e-02,  9.3286e-03,  2.2012e-02, -6.4964e-03,  5.8304e-02,\n",
      "         5.5628e-02,  5.0304e-02, -5.9000e-02,  3.5312e-02,  1.8593e-02,\n",
      "        -4.0610e-02,  5.1659e-02, -6.2876e-02, -1.5582e-02, -5.0477e-02,\n",
      "        -7.0201e-02, -6.7237e-02, -1.8073e-02, -4.5341e-03, -3.2837e-02,\n",
      "         4.7658e-02, -5.2050e-02, -1.2737e-02,  4.0812e-02, -5.0873e-02,\n",
      "         4.1175e-02, -3.9820e-02,  6.2666e-02,  1.4170e-02,  6.2707e-02,\n",
      "         8.9621e-03, -6.5003e-02, -1.2171e-02, -7.1515e-03,  1.8061e-02,\n",
      "        -4.0785e-02, -4.1943e-02, -4.3968e-02,  6.9563e-03, -8.6357e-03,\n",
      "         1.6219e-02, -4.3178e-02,  2.8582e-02, -1.4051e-02,  4.6930e-03,\n",
      "         6.3162e-02,  1.0767e-02,  9.5556e-03,  1.1360e-02,  2.9216e-02,\n",
      "         4.6653e-02,  2.0776e-02, -4.5619e-02,  2.4084e-02, -3.9231e-02,\n",
      "         4.2462e-02, -4.8290e-02, -3.1002e-02, -4.1946e-02, -2.4842e-02,\n",
      "        -5.7323e-02, -2.8200e-02, -1.2977e-03, -7.0010e-02,  1.5985e-02,\n",
      "         3.8185e-02, -4.7776e-02, -4.0691e-02,  3.9862e-02,  4.3077e-02,\n",
      "         6.6655e-02, -2.7276e-02,  1.6400e-02, -3.5586e-02, -1.3124e-02,\n",
      "        -5.8808e-02,  5.2398e-02, -2.9995e-02,  3.2008e-02, -5.4038e-02,\n",
      "        -4.5953e-02, -3.3206e-02,  4.1000e-02, -3.9709e-02,  2.5264e-03,\n",
      "         3.2072e-02, -6.6548e-02, -6.7214e-02, -4.3787e-02,  1.0577e-02,\n",
      "         2.0112e-02, -2.3261e-02,  1.0767e-02, -5.5411e-02,  6.2246e-02,\n",
      "        -4.9962e-02, -2.1493e-02, -2.9517e-02,  6.5722e-03, -5.2184e-02,\n",
      "        -3.3804e-02, -6.3705e-02,  4.6695e-02,  6.2465e-02,  3.8636e-02,\n",
      "        -4.5545e-02,  1.7830e-02,  4.9964e-02, -5.9512e-02, -8.5392e-03,\n",
      "        -5.9455e-03,  2.0752e-02,  2.2392e-02, -2.5936e-02, -2.1703e-02,\n",
      "         2.4891e-02, -3.4914e-02,  1.9264e-04,  7.0433e-02, -1.3402e-02,\n",
      "        -4.5126e-02,  3.2251e-02, -3.7516e-02, -6.2724e-02, -5.2450e-02,\n",
      "        -1.4044e-02,  4.8290e-03, -2.7912e-02,  3.5515e-02, -2.5910e-02],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0260,  0.0568,  0.0203,  ..., -0.0149, -0.0481, -0.0045],\n",
      "        [ 0.0616,  0.0265,  0.0612,  ..., -0.0360, -0.0531,  0.0312],\n",
      "        [ 0.0340,  0.0083,  0.0632,  ...,  0.0616, -0.0573,  0.0367],\n",
      "        ...,\n",
      "        [-0.0154, -0.0273,  0.0760,  ..., -0.0886, -0.0619, -0.0326],\n",
      "        [-0.0642,  0.0691,  0.0264,  ..., -0.0371,  0.0866,  0.0266],\n",
      "        [ 0.0518, -0.0122,  0.0083,  ...,  0.0542, -0.0101, -0.0717]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0207,  0.0792, -0.0036, -0.0718,  0.0065, -0.0048,  0.0014,  0.0138,\n",
      "         0.0308, -0.0425], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in model.parameters():\n",
    "    test.append(i.data)\n",
    "new_test = []\n",
    "for i in test:\n",
    "    new_test.append(i+i)\n",
    "tmp_model = Net()\n",
    "with torch.no_grad():\n",
    "    for i,par in enumerate(tmp_model.parameters()):\n",
    "        par.set_(new_test[i])\n",
    "for i in tmp_model.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(torch.tensor((1,2)))\n",
    "for i in x:\n",
    "    i+i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01297603,  0.02842132,  0.01014335, ..., -0.00745563,\n",
       "        -0.02407177, -0.00225234],\n",
       "       [ 0.03080916,  0.01323886,  0.03059926, ..., -0.01799139,\n",
       "        -0.0265331 ,  0.01559756],\n",
       "       [ 0.01701068,  0.00417169,  0.0316051 , ...,  0.03077709,\n",
       "        -0.02863705,  0.01833366],\n",
       "       ...,\n",
       "       [-0.00771326, -0.01363829,  0.03800831, ..., -0.04430421,\n",
       "        -0.03094019, -0.01628821],\n",
       "       [-0.0320928 ,  0.03452658,  0.01318498, ..., -0.0185255 ,\n",
       "         0.04329454,  0.01331757],\n",
       "       [ 0.02591962, -0.00609975,  0.00413742, ...,  0.02711744,\n",
       "        -0.00503955, -0.03584282]], dtype=float32)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc2.weight.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Parameter.set_>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc2.bias.set_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
