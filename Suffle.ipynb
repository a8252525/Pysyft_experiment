{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "n_train_items = 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import syft as sy  # <-- NEW: import the Pysyft library\n",
    "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
    "# simulation functions\n",
    "def connect_to_workers(n_workers):\n",
    "    return [\n",
    "        sy.VirtualWorker(hook, id=f\"worker{i+1}\")\n",
    "        for i in range(n_workers)\n",
    "    ]\n",
    "\n",
    "\n",
    "workers = connect_to_workers(n_workers=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.test_batch_size = 64\n",
    "        self.epochs = epochs\n",
    "        self.lr = 0.01\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 3\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The following options are not supported: num_workers: 1, pin_memory: True\n"
     ]
    }
   ],
   "source": [
    "# federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
    "#     datasets.MNIST('../data', train=True, download=True,\n",
    "#                    transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),\n",
    "#                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                    ]))\n",
    "#     .federate(workers), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "#     batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),\n",
    "#                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                    ])),\n",
    "#     batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size\n",
    ")\n",
    "\n",
    "    \n",
    "#---\n",
    "\n",
    "less_train_dataloader = [\n",
    "        ((data), (target))\n",
    "        for i, (data, target) in enumerate(train_loader)\n",
    "        if i < n_train_items / args.batch_size\n",
    "    ]\n",
    "less_test_dataloader = [\n",
    "        ((data), (target))\n",
    "        for i, (data, target) in enumerate(test_loader)\n",
    "        if i < n_train_items / args.batch_size\n",
    "    ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy \n",
    "# #mnist_dataset.__getitem__(2)[1]\n",
    "# a = (mnist_dataset.__getitem__(0)[0]).numpy()\n",
    "# a.dtype = 'uint8'\n",
    "# print(a)\n",
    "# Image.fromarray(a[0], mode= 'P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(workers, Net):\n",
    "    model_list = list()\n",
    "    for worker in workers:\n",
    "        model_list.append(Net)\n",
    "    return model_list\n",
    "model_list = model_init(workers, Net())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model_list, device, less_train_dataloader, optimizer, epoch, workers):\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(less_train_dataloader): # <-- now it is a distributed dataset\n",
    "        model_on_worker = model_list[batch_idx%len(workers)].copy()\n",
    "        model_on_worker.train()\n",
    "        model_on_worker.send(workers[batch_idx%len(workers)]) # <-- NEW: send the model to the right location\n",
    "        \n",
    "        data_on_worker = data.send(workers[batch_idx%len(workers)])\n",
    "        target_on_worker = target.send(workers[batch_idx%len(workers)])\n",
    "        \n",
    "        data_on_worker, target_on_worker = data_on_worker.to(device), target_on_worker.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model_on_worker(data_on_worker)\n",
    "        loss = F.nll_loss(output, target_on_worker)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model_on_worker.get() # <-- NEW: get the model back\n",
    "        \n",
    "        model_list[batch_idx%len(workers)] = model_on_worker #When len(dataloader) is longer than the len(worker) send and get must be modified\n",
    "        #model_list here is full of the model which has trained on the workers, there are all different now.\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            loss = loss.get() # <-- NEW: get the loss back\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * args.batch_size, len(less_train_dataloader) * args.batch_size,\n",
    "                100. * batch_idx / len(less_train_dataloader), loss.item()))\n",
    "            \n",
    "    ##Aggregation time\n",
    "    with torch.no_grad():\n",
    "        for model in model_list:\n",
    "            for par in model:\n",
    "                #average the model_list \n",
    "            \n",
    "        \n",
    "        #init model with new_model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader*args.batch_size)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader* args.batch_size),\n",
    "        100. * correct / (len(test_loader)*args.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1280 (0%)]\tLoss: 2.324638\n",
      "Train Epoch: 1 [192/1280 (15%)]\tLoss: 2.314684\n",
      "Train Epoch: 1 [384/1280 (30%)]\tLoss: 2.291706\n",
      "Train Epoch: 1 [576/1280 (45%)]\tLoss: 2.310091\n",
      "Train Epoch: 1 [768/1280 (60%)]\tLoss: 2.275877\n",
      "Train Epoch: 1 [960/1280 (75%)]\tLoss: 2.281027\n",
      "Train Epoch: 1 [1152/1280 (90%)]\tLoss: 2.268555\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 2.2690, Accuracy: 252/1280 (20%)\n",
      "\n",
      "Train Epoch: 2 [0/1280 (0%)]\tLoss: 2.277216\n",
      "Train Epoch: 2 [192/1280 (15%)]\tLoss: 2.262702\n",
      "Train Epoch: 2 [384/1280 (30%)]\tLoss: 2.245050\n",
      "Train Epoch: 2 [576/1280 (45%)]\tLoss: 2.264976\n",
      "Train Epoch: 2 [768/1280 (60%)]\tLoss: 2.227021\n",
      "Train Epoch: 2 [960/1280 (75%)]\tLoss: 2.228276\n",
      "Train Epoch: 2 [1152/1280 (90%)]\tLoss: 2.211541\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 2.2258, Accuracy: 538/1280 (42%)\n",
      "\n",
      "Train Epoch: 3 [0/1280 (0%)]\tLoss: 2.226589\n",
      "Train Epoch: 3 [192/1280 (15%)]\tLoss: 2.203862\n",
      "Train Epoch: 3 [384/1280 (30%)]\tLoss: 2.188233\n",
      "Train Epoch: 3 [576/1280 (45%)]\tLoss: 2.211404\n",
      "Train Epoch: 3 [768/1280 (60%)]\tLoss: 2.163832\n",
      "Train Epoch: 3 [960/1280 (75%)]\tLoss: 2.158487\n",
      "Train Epoch: 3 [1152/1280 (90%)]\tLoss: 2.132762\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 2.1616, Accuracy: 558/1280 (44%)\n",
      "\n",
      "Train Epoch: 4 [0/1280 (0%)]\tLoss: 2.153714\n",
      "Train Epoch: 4 [192/1280 (15%)]\tLoss: 2.114891\n",
      "Train Epoch: 4 [384/1280 (30%)]\tLoss: 2.100732\n",
      "Train Epoch: 4 [576/1280 (45%)]\tLoss: 2.128700\n",
      "Train Epoch: 4 [768/1280 (60%)]\tLoss: 2.060370\n",
      "Train Epoch: 4 [960/1280 (75%)]\tLoss: 2.044523\n",
      "Train Epoch: 4 [1152/1280 (90%)]\tLoss: 2.003530\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 2.0504, Accuracy: 607/1280 (47%)\n",
      "\n",
      "Train Epoch: 5 [0/1280 (0%)]\tLoss: 2.029537\n",
      "Train Epoch: 5 [192/1280 (15%)]\tLoss: 1.957552\n",
      "Train Epoch: 5 [384/1280 (30%)]\tLoss: 1.948145\n",
      "Train Epoch: 5 [576/1280 (45%)]\tLoss: 1.981956\n",
      "Train Epoch: 5 [768/1280 (60%)]\tLoss: 1.874076\n",
      "Train Epoch: 5 [960/1280 (75%)]\tLoss: 1.841531\n",
      "Train Epoch: 5 [1152/1280 (90%)]\tLoss: 1.778745\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 1.8518, Accuracy: 678/1280 (53%)\n",
      "\n",
      "Train Epoch: 6 [0/1280 (0%)]\tLoss: 1.809550\n",
      "Train Epoch: 6 [192/1280 (15%)]\tLoss: 1.679309\n",
      "Train Epoch: 6 [384/1280 (30%)]\tLoss: 1.684945\n",
      "Train Epoch: 6 [576/1280 (45%)]\tLoss: 1.735237\n",
      "Train Epoch: 6 [768/1280 (60%)]\tLoss: 1.555564\n",
      "Train Epoch: 6 [960/1280 (75%)]\tLoss: 1.514473\n",
      "Train Epoch: 6 [1152/1280 (90%)]\tLoss: 1.436680\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 1.5526, Accuracy: 765/1280 (60%)\n",
      "\n",
      "Train Epoch: 7 [0/1280 (0%)]\tLoss: 1.478951\n",
      "Train Epoch: 7 [192/1280 (15%)]\tLoss: 1.296345\n",
      "Train Epoch: 7 [384/1280 (30%)]\tLoss: 1.331200\n",
      "Train Epoch: 7 [576/1280 (45%)]\tLoss: 1.418389\n",
      "Train Epoch: 7 [768/1280 (60%)]\tLoss: 1.157233\n",
      "Train Epoch: 7 [960/1280 (75%)]\tLoss: 1.135285\n",
      "Train Epoch: 7 [1152/1280 (90%)]\tLoss: 1.062929\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 1.2383, Accuracy: 855/1280 (67%)\n",
      "\n",
      "Train Epoch: 8 [0/1280 (0%)]\tLoss: 1.132568\n",
      "Train Epoch: 8 [192/1280 (15%)]\tLoss: 0.939146\n",
      "Train Epoch: 8 [384/1280 (30%)]\tLoss: 1.005010\n",
      "Train Epoch: 8 [576/1280 (45%)]\tLoss: 1.134784\n",
      "Train Epoch: 8 [768/1280 (60%)]\tLoss: 0.833044\n",
      "Train Epoch: 8 [960/1280 (75%)]\tLoss: 0.849073\n",
      "Train Epoch: 8 [1152/1280 (90%)]\tLoss: 0.771674\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 1.0080, Accuracy: 909/1280 (71%)\n",
      "\n",
      "Train Epoch: 9 [0/1280 (0%)]\tLoss: 0.885917\n",
      "Train Epoch: 9 [192/1280 (15%)]\tLoss: 0.703052\n",
      "Train Epoch: 9 [384/1280 (30%)]\tLoss: 0.785647\n",
      "Train Epoch: 9 [576/1280 (45%)]\tLoss: 0.929986\n",
      "Train Epoch: 9 [768/1280 (60%)]\tLoss: 0.640221\n",
      "Train Epoch: 9 [960/1280 (75%)]\tLoss: 0.687586\n",
      "Train Epoch: 9 [1152/1280 (90%)]\tLoss: 0.581957\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 0.8679, Accuracy: 928/1280 (72%)\n",
      "\n",
      "Train Epoch: 10 [0/1280 (0%)]\tLoss: 0.733676\n",
      "Train Epoch: 10 [192/1280 (15%)]\tLoss: 0.568930\n",
      "Train Epoch: 10 [384/1280 (30%)]\tLoss: 0.647158\n",
      "Train Epoch: 10 [576/1280 (45%)]\tLoss: 0.786850\n",
      "Train Epoch: 10 [768/1280 (60%)]\tLoss: 0.531604\n",
      "Train Epoch: 10 [960/1280 (75%)]\tLoss: 0.599982\n",
      "Train Epoch: 10 [1152/1280 (90%)]\tLoss: 0.463047\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 0.7895, Accuracy: 944/1280 (74%)\n",
      "\n",
      "CPU times: user 8.86 s, sys: 0 ns, total: 8.86 s\n",
      "Wall time: 8.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, device, less_train_dataloader, optimizer, epoch, workers)\n",
    "    test(args, model, device, less_test_dataloader)\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VirtualWorker id:worker1 #objects:35>\n"
     ]
    }
   ],
   "source": [
    "print(workers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VirtualWorker id:worker1 #objects:180>\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-293ccfed3689>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel_ondevice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggregater\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Net' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model_list = []\n",
    "model_ondevice = []\n",
    "aggregater = sy.VirtualWorker(hook, id=\"aggregater\")\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(less_train_dataloader):\n",
    "    data_on_device = data.send(workers[batch_idx])\n",
    "    if batch_idx<3:\n",
    "        model_ondevice.append(model.copy().send(workers[batch_idx]))\n",
    "        print(model_ondevice[batch_idx].location)\n",
    "        \n",
    "        pre = model_ondevice[batch_idx](data_on_device)\n",
    "        model_ondevice[batch_idx].move(aggregater)\n",
    "        print(model.location)\n",
    "        print(model.weight.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-215-fa2944c89d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(model_list[0].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fb2982e6e08>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-1.4099e-01, -1.0948e-02, -1.4480e-01, -1.0054e-01,  1.1486e-01],\n",
      "          [ 9.1577e-02,  3.8746e-02,  8.3199e-02,  1.0750e-02,  8.1345e-02],\n",
      "          [ 1.8652e-01, -1.6145e-01, -6.7543e-02,  1.4402e-01,  1.1334e-01],\n",
      "          [ 1.5597e-01, -1.9715e-01,  8.0286e-02,  1.6977e-01,  1.8176e-01],\n",
      "          [-1.7369e-01,  1.0201e-01,  1.3253e-01,  5.2145e-02,  1.4339e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.3291e-02, -1.3553e-01,  9.1933e-02, -1.5774e-01,  2.6915e-02],\n",
      "          [-1.1548e-02,  1.2641e-01, -1.5817e-01,  1.7599e-01,  2.1021e-02],\n",
      "          [-1.0566e-01, -1.2496e-01,  1.8208e-01, -1.6078e-01, -6.4086e-02],\n",
      "          [-1.3699e-01,  1.6120e-01, -1.1977e-01, -5.5159e-02,  2.1307e-02],\n",
      "          [-1.3585e-01, -1.6169e-01, -1.5936e-01,  1.7321e-01,  6.2347e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0746e-02,  1.8295e-01, -6.4183e-02,  1.8262e-01,  1.3961e-01],\n",
      "          [-4.8250e-02,  1.3991e-01, -6.8790e-02, -7.6633e-02,  2.4501e-02],\n",
      "          [ 5.4475e-02,  5.8626e-02,  1.5917e-01,  3.9913e-02,  8.0575e-02],\n",
      "          [ 1.2859e-01,  1.2438e-01,  5.7268e-02, -1.4176e-01, -9.8547e-02],\n",
      "          [ 1.9996e-01,  1.0649e-01,  1.0452e-01, -9.8475e-02,  5.5655e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.2911e-02, -7.9789e-02,  3.1905e-02, -3.2975e-02, -1.9910e-01],\n",
      "          [-1.3638e-01,  1.5622e-01, -1.9653e-01,  1.2624e-01,  7.2604e-02],\n",
      "          [ 1.1941e-01, -3.6173e-02, -1.3798e-01,  2.2397e-02, -8.7628e-02],\n",
      "          [-1.9641e-01, -1.4068e-01,  1.6140e-01, -1.9602e-01, -2.6258e-02],\n",
      "          [-1.3182e-01, -5.6905e-02,  4.6583e-02,  1.1315e-03, -1.8527e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.1301e-02, -4.5362e-02,  1.9661e-01, -2.1661e-02,  5.2717e-02],\n",
      "          [ 6.7740e-02, -1.7472e-01,  1.9664e-01, -1.5793e-02,  3.8350e-02],\n",
      "          [ 5.5075e-02, -1.3281e-01, -1.9577e-01, -1.4467e-01,  1.0284e-01],\n",
      "          [-4.7959e-02,  3.9096e-02,  7.7954e-02, -1.8079e-01,  1.4325e-02],\n",
      "          [-1.2240e-01, -1.2406e-01, -1.7197e-01, -1.1411e-01, -6.1545e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.2811e-02,  3.5511e-02,  5.9983e-02,  1.8083e-01, -1.0303e-01],\n",
      "          [ 1.2202e-01, -3.2328e-02,  2.7820e-02,  6.3337e-02, -1.0356e-02],\n",
      "          [ 1.8585e-01, -1.0369e-01, -1.4559e-01, -1.1186e-01, -1.1913e-01],\n",
      "          [-6.5491e-02, -2.2196e-02,  5.3535e-02, -1.9229e-01,  7.7979e-02],\n",
      "          [-1.7334e-01, -1.6093e-01, -5.5934e-02, -1.1795e-01,  1.8425e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3474e-01, -8.9182e-02, -8.4735e-02, -1.8690e-01, -2.2468e-02],\n",
      "          [-2.6186e-03,  1.3862e-01, -1.8419e-01, -2.5300e-02,  1.7793e-01],\n",
      "          [-7.9781e-02,  1.8389e-01,  7.6772e-02,  8.7966e-02, -5.9295e-02],\n",
      "          [ 7.8480e-02,  7.3910e-02, -5.7702e-02,  1.7460e-01, -2.9837e-02],\n",
      "          [-1.7585e-01, -1.9614e-01, -1.3463e-01,  3.9250e-05, -1.0279e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.2191e-02, -1.3385e-01, -1.7488e-01,  5.4413e-02,  1.6700e-01],\n",
      "          [ 1.4943e-01, -1.4046e-01,  1.3670e-02,  1.3897e-01,  1.5931e-01],\n",
      "          [ 8.6258e-02,  1.2451e-01,  1.9556e-01, -6.3945e-02, -7.6133e-02],\n",
      "          [ 1.1330e-02,  4.6676e-02, -9.0915e-02, -9.7932e-03, -1.6546e-01],\n",
      "          [-7.9745e-02, -1.7049e-01, -2.6418e-02, -4.8758e-02,  3.0746e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.5251e-04, -1.4060e-01, -1.0271e-01,  1.2103e-02, -3.7078e-02],\n",
      "          [-1.9860e-01,  6.3292e-02, -7.7452e-02, -9.9134e-02,  1.2760e-01],\n",
      "          [-1.2831e-01,  1.0859e-01,  2.8070e-02,  3.8520e-02, -9.4095e-02],\n",
      "          [-1.1441e-03,  7.7681e-02, -8.8797e-02, -7.0887e-03, -2.1392e-02],\n",
      "          [-9.7000e-02, -4.9582e-02,  1.0191e-01,  1.6451e-01,  3.8549e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0919e-01,  1.4403e-01, -1.1099e-01, -1.1004e-01, -1.3963e-01],\n",
      "          [-1.5262e-01,  5.7788e-02,  1.7828e-01,  9.2230e-03,  5.4492e-02],\n",
      "          [-7.1989e-02, -8.6472e-02,  1.1059e-02,  3.2051e-02,  1.1502e-01],\n",
      "          [ 1.3590e-02,  1.5334e-01, -1.1386e-01,  8.3175e-02,  1.0072e-02],\n",
      "          [ 5.4582e-02,  1.2806e-01, -1.8778e-02,  5.1791e-02,  1.9977e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2081e-02, -1.2627e-01,  1.8742e-01, -1.8431e-01,  1.7604e-01],\n",
      "          [ 1.0840e-01,  1.0951e-01, -5.8318e-02,  1.3283e-01,  3.8488e-02],\n",
      "          [ 8.8617e-02, -1.4398e-01, -1.6734e-01, -1.7675e-01, -1.2902e-01],\n",
      "          [ 5.0984e-02,  1.9483e-01,  7.2828e-02, -1.4257e-01,  1.6456e-01],\n",
      "          [-1.0524e-02,  1.7855e-01, -1.5773e-01, -1.7217e-01,  9.5129e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1314e-02, -1.6677e-01, -1.5760e-01, -1.5920e-01,  5.2272e-02],\n",
      "          [ 7.7160e-02, -8.0943e-02,  4.3984e-03,  1.1660e-01, -1.3552e-01],\n",
      "          [ 1.1791e-01, -1.6095e-01,  6.9194e-03, -1.6724e-01, -1.9215e-01],\n",
      "          [-6.9279e-02,  6.3394e-02, -4.1022e-02,  1.9865e-01, -9.3795e-02],\n",
      "          [-1.2840e-01,  7.6965e-02, -1.2473e-01,  1.5903e-01, -1.1244e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8297e-01, -5.2758e-02,  1.6801e-01, -1.8696e-01,  1.7631e-01],\n",
      "          [ 6.4123e-02, -1.8085e-01, -1.0993e-01, -2.1045e-03, -9.5837e-02],\n",
      "          [-1.5697e-01,  2.0469e-02,  9.9270e-02,  1.9270e-01,  5.2066e-02],\n",
      "          [ 1.9415e-02, -1.8814e-01,  1.5927e-01, -1.3062e-01, -1.9703e-01],\n",
      "          [-5.4612e-02, -1.6106e-01,  1.2908e-03, -8.1912e-03, -1.4460e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0836e-01,  7.3698e-03, -3.0205e-02,  1.8204e-01, -1.4756e-03],\n",
      "          [ 1.9314e-01, -6.5693e-02, -1.1334e-01,  2.1674e-03,  1.7661e-01],\n",
      "          [-1.2518e-02,  1.0517e-01, -1.0724e-01, -9.5385e-03,  3.5525e-02],\n",
      "          [ 1.8315e-01,  7.6689e-02,  7.6146e-02, -1.3474e-01,  8.6894e-02],\n",
      "          [ 1.7453e-01, -8.3813e-02,  8.9561e-02,  6.1652e-02,  1.6521e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5006e-02, -2.0000e-02, -8.2416e-02,  2.6947e-03,  1.7271e-01],\n",
      "          [ 1.8138e-01, -4.1737e-02, -9.0757e-02,  8.1141e-02, -5.8360e-02],\n",
      "          [-1.4772e-01, -1.5494e-01, -9.0410e-02, -7.2920e-02,  4.6629e-02],\n",
      "          [ 3.4369e-02, -8.7311e-03,  1.9019e-01,  1.4323e-01, -1.7470e-01],\n",
      "          [-5.6536e-03,  8.5093e-02,  1.8544e-01,  8.6251e-03,  3.2692e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3013e-01,  1.6634e-01, -1.3319e-01,  2.9494e-02,  1.1023e-01],\n",
      "          [-1.6677e-01,  9.5528e-02,  1.2655e-01, -9.6604e-03, -2.9539e-02],\n",
      "          [-1.7420e-01, -1.1877e-01, -7.0644e-02, -6.8149e-02, -5.9630e-02],\n",
      "          [-1.9078e-01,  2.7797e-02, -4.9275e-02, -1.1894e-01,  1.2309e-01],\n",
      "          [ 7.2268e-02,  1.3210e-01, -1.9847e-01,  5.2108e-02, -4.7466e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0565e-01,  1.2629e-01, -2.2342e-02, -5.7465e-02, -1.3527e-04],\n",
      "          [ 1.1591e-01, -7.6346e-03,  3.0912e-02,  8.3829e-02,  1.1209e-01],\n",
      "          [-1.3515e-01,  1.0304e-01,  9.3827e-02,  1.3775e-01, -9.4530e-02],\n",
      "          [ 1.0755e-01, -1.2608e-01,  6.6831e-03, -4.1286e-02,  1.0454e-01],\n",
      "          [-1.2679e-01,  1.9397e-01,  6.8693e-02,  1.3303e-01, -7.4000e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4074e-02, -1.2643e-01, -2.4317e-03,  6.3933e-02, -2.8543e-02],\n",
      "          [ 1.0236e-01, -1.3001e-01,  1.6324e-01, -1.1195e-01,  6.3926e-06],\n",
      "          [-1.7053e-01,  1.0371e-01, -1.8975e-01,  1.1430e-01,  1.6021e-01],\n",
      "          [-9.5198e-02, -1.7781e-01,  1.4556e-01,  1.9304e-01, -1.4562e-02],\n",
      "          [ 1.5881e-01,  8.1140e-02,  1.8856e-01,  2.4370e-02, -4.3816e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6892e-01, -1.7082e-01,  2.3897e-02,  1.2820e-01, -3.0799e-02],\n",
      "          [ 9.7173e-03,  9.5482e-03,  1.4140e-01, -1.4440e-01,  8.5168e-02],\n",
      "          [-1.3312e-01, -1.3494e-01,  8.6030e-02,  7.8827e-02, -3.8274e-02],\n",
      "          [-1.1531e-02, -8.3400e-02, -8.8430e-02,  1.7582e-01,  1.0366e-01],\n",
      "          [ 1.6554e-01,  6.7860e-03,  1.5180e-01, -1.6277e-01, -1.3277e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2367e-01, -8.8712e-02,  8.8917e-02, -9.0927e-02, -1.8848e-01],\n",
      "          [ 6.2661e-02, -1.9629e-01, -4.6062e-02, -6.8450e-02,  5.3010e-02],\n",
      "          [ 2.3222e-02, -1.5910e-01,  1.8694e-01, -5.8775e-02, -1.0320e-01],\n",
      "          [-1.7138e-01,  1.5869e-01,  7.2713e-02,  1.5579e-01, -1.4269e-01],\n",
      "          [ 5.4359e-04,  1.2233e-01,  2.4769e-02, -6.7980e-02, -1.3221e-01]]]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0593, -0.0376,  0.0424,  0.0210,  0.0859, -0.1849,  0.0974, -0.0346,\n",
      "         0.1898, -0.1359,  0.1365, -0.1630,  0.0981,  0.1119, -0.1932, -0.1580,\n",
      "        -0.0311,  0.0055,  0.0855, -0.0106], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-1.7430e-02, -1.3592e-02,  1.6612e-03,  4.2944e-03, -1.8578e-03],\n",
      "          [ 4.4539e-02, -1.3120e-02,  4.1736e-02, -4.2500e-02, -3.8602e-02],\n",
      "          [ 3.2727e-02, -1.7000e-02, -7.8587e-03,  3.1209e-02, -3.8281e-02],\n",
      "          [-2.9357e-02, -3.4995e-02,  3.2744e-02,  2.9303e-03,  1.4033e-02],\n",
      "          [-1.1083e-05, -1.6555e-02,  4.8727e-03,  3.5641e-03, -3.6350e-02]],\n",
      "\n",
      "         [[-1.3655e-02,  2.5261e-02, -2.0776e-02, -2.3193e-02, -2.1848e-02],\n",
      "          [-3.5979e-02,  3.8271e-02, -2.2911e-02, -3.5663e-02,  2.8519e-02],\n",
      "          [ 1.4560e-02, -3.9568e-02, -4.3739e-02, -2.2298e-02, -3.4505e-02],\n",
      "          [-3.9086e-02,  3.4253e-03,  9.9185e-03, -1.9787e-02, -2.6345e-02],\n",
      "          [-3.6728e-03,  2.0409e-04, -1.1317e-02, -4.0502e-02, -1.5468e-02]],\n",
      "\n",
      "         [[ 2.3373e-02,  5.4498e-03, -1.6417e-02,  2.9329e-03,  2.9939e-02],\n",
      "          [-4.2030e-02, -5.0388e-04, -2.4755e-02, -5.5302e-05,  4.1315e-02],\n",
      "          [-3.3559e-02, -2.7148e-02,  3.1481e-02, -2.0598e-02, -2.9723e-02],\n",
      "          [ 3.5831e-02,  3.1354e-02, -1.7900e-02,  2.6582e-02,  4.0474e-02],\n",
      "          [-3.8721e-02, -1.0484e-02, -7.7314e-03, -3.4097e-02, -6.6862e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7687e-02, -2.4705e-02, -1.5560e-02, -1.8402e-02, -2.3912e-02],\n",
      "          [ 2.3688e-02, -1.9555e-02, -1.2373e-02,  8.0392e-03, -3.5926e-02],\n",
      "          [ 4.1979e-02,  3.7707e-02, -4.0691e-02, -3.4456e-02,  2.0310e-02],\n",
      "          [ 2.1020e-02, -2.1582e-02,  1.4070e-02,  1.1863e-02, -4.1706e-02],\n",
      "          [-3.0744e-02,  4.4650e-02, -3.7049e-02,  1.6328e-02, -1.4178e-02]],\n",
      "\n",
      "         [[ 4.4354e-02, -2.2097e-02,  1.8318e-02,  1.5863e-02,  2.2007e-03],\n",
      "          [ 1.4785e-02, -1.2223e-02, -1.0908e-03, -1.3896e-02, -1.7380e-02],\n",
      "          [ 2.6609e-02, -3.3259e-02,  3.4445e-02,  3.1403e-02,  3.0946e-02],\n",
      "          [ 2.8414e-02,  3.6542e-02,  3.4020e-02, -2.9679e-02, -9.3764e-03],\n",
      "          [ 6.4355e-03,  3.7379e-03, -4.3496e-02, -2.5417e-03,  1.1812e-02]],\n",
      "\n",
      "         [[ 2.3867e-02, -1.0274e-02, -2.1254e-02,  3.8938e-02, -9.5718e-04],\n",
      "          [-3.9230e-02, -9.0201e-03,  6.8566e-03,  1.3966e-02,  1.2050e-02],\n",
      "          [ 1.6454e-02,  3.2630e-02, -1.9502e-02, -7.4279e-05,  3.6320e-02],\n",
      "          [ 3.4284e-02, -1.5241e-02, -3.7617e-02, -3.3849e-02,  4.3606e-02],\n",
      "          [ 2.9432e-02,  5.1668e-03, -3.7400e-02,  4.0659e-02, -2.7595e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0780e-02,  2.3103e-02, -4.1011e-02, -1.9950e-02,  1.5327e-02],\n",
      "          [-3.5331e-02, -9.5066e-03,  3.8456e-02,  2.5775e-02,  4.2167e-04],\n",
      "          [-2.3950e-02, -3.4240e-02, -1.3196e-02,  4.1691e-02,  2.8975e-02],\n",
      "          [ 1.7254e-02, -1.2880e-02, -2.4437e-02,  3.5358e-02,  7.4621e-05],\n",
      "          [ 4.1019e-02, -2.1084e-02,  4.3399e-03, -1.6967e-02,  2.7704e-02]],\n",
      "\n",
      "         [[ 2.4418e-02,  1.8683e-02, -3.3921e-02, -4.1445e-02, -3.0918e-03],\n",
      "          [ 3.2718e-02, -1.0110e-02,  3.3474e-02,  6.3218e-03,  1.3119e-02],\n",
      "          [ 3.1758e-02, -2.6789e-02,  8.3252e-03, -4.2357e-02,  1.6871e-02],\n",
      "          [-3.1663e-03,  2.3860e-02,  1.5250e-02, -8.8619e-03, -6.9078e-03],\n",
      "          [ 4.0996e-02,  3.4850e-02,  1.4393e-02,  4.4026e-02, -2.2387e-02]],\n",
      "\n",
      "         [[ 1.0918e-02,  4.1358e-02, -3.3617e-02,  3.2288e-02, -5.3990e-03],\n",
      "          [ 2.5243e-02, -6.3697e-03, -1.2073e-03, -1.9389e-02, -7.3490e-03],\n",
      "          [-3.0896e-02,  3.2993e-03,  2.4992e-03,  2.5621e-02,  3.4593e-02],\n",
      "          [ 1.1842e-02, -6.5133e-03,  1.0140e-02, -1.0196e-02, -3.3154e-02],\n",
      "          [ 2.7589e-02,  2.7441e-02,  1.5222e-02, -1.1775e-02,  1.7055e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.8047e-02, -3.6276e-02, -3.1367e-02, -4.0249e-02,  3.1095e-02],\n",
      "          [ 1.0753e-03, -3.4625e-02, -2.5321e-02,  5.4492e-03, -2.5918e-02],\n",
      "          [ 1.4908e-02, -1.1180e-02, -8.8965e-03, -3.7826e-02,  4.4593e-02],\n",
      "          [-2.6789e-02,  5.5937e-03,  2.8601e-02, -1.2723e-02, -4.3251e-02],\n",
      "          [-4.1306e-02,  4.1959e-02, -1.3634e-02,  3.3785e-02,  2.4425e-04]],\n",
      "\n",
      "         [[ 2.1055e-02, -2.1696e-02, -3.2550e-03,  8.9188e-03,  2.1169e-02],\n",
      "          [-1.9844e-02, -3.4467e-02, -8.9822e-04,  2.1249e-02,  4.2133e-02],\n",
      "          [-1.3111e-02, -7.5100e-03, -1.2275e-02,  2.6717e-02,  1.5451e-02],\n",
      "          [-4.4160e-02, -1.1131e-03, -4.6723e-03,  4.4619e-02,  3.6888e-02],\n",
      "          [ 3.9171e-02,  2.1456e-02,  2.8632e-02,  2.6821e-02,  3.5909e-02]],\n",
      "\n",
      "         [[ 2.3575e-03, -2.9644e-02,  3.6375e-02, -6.2461e-03, -3.5762e-02],\n",
      "          [ 7.7134e-03,  4.3407e-03, -4.1259e-02, -6.0327e-03,  2.0806e-02],\n",
      "          [-2.8747e-03,  2.2607e-02,  2.7063e-02, -2.1506e-02,  2.3026e-02],\n",
      "          [-8.8417e-03,  2.3412e-02, -1.2534e-02,  2.5037e-02,  4.1127e-02],\n",
      "          [-3.2748e-02, -1.0481e-02, -3.3712e-02, -3.7785e-02,  4.0666e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5719e-02,  1.4313e-02,  4.2848e-02, -3.6668e-03, -2.5146e-02],\n",
      "          [ 4.3710e-02, -1.5833e-03,  1.1756e-02, -1.8425e-02,  2.0001e-02],\n",
      "          [ 1.3582e-02, -4.0838e-02, -5.6489e-03, -3.5117e-02,  3.1221e-02],\n",
      "          [-8.7302e-03,  3.9843e-02,  7.1164e-03,  2.8221e-03,  2.2102e-02],\n",
      "          [ 9.1963e-03,  1.9355e-02, -1.1287e-02,  1.6583e-02, -1.9550e-02]],\n",
      "\n",
      "         [[ 3.1679e-02, -1.2809e-02, -2.5034e-02,  1.1638e-02, -4.1712e-02],\n",
      "          [ 1.6197e-02, -1.8289e-02,  3.2001e-02,  8.7437e-03, -5.1561e-03],\n",
      "          [-3.5835e-02,  1.2068e-02, -3.2156e-02,  1.9903e-02,  1.0090e-02],\n",
      "          [ 2.4602e-02,  3.2558e-02,  4.4674e-02, -2.5009e-02,  1.9462e-02],\n",
      "          [ 6.8461e-03, -2.9569e-02,  5.8453e-03,  3.6876e-02, -3.5677e-02]],\n",
      "\n",
      "         [[ 3.2164e-02,  1.0769e-02,  1.8462e-02, -3.3349e-02,  3.1736e-02],\n",
      "          [-3.9193e-02, -8.1743e-03,  1.1365e-02,  2.9338e-02,  9.8438e-03],\n",
      "          [ 2.7455e-02,  3.4783e-02, -2.9074e-02,  6.9914e-03, -3.5727e-02],\n",
      "          [-4.0463e-02,  1.8022e-02, -3.6154e-02,  9.5675e-03, -3.8564e-02],\n",
      "          [-1.6367e-02,  3.6008e-02, -1.8306e-02, -4.6554e-04, -4.1470e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6795e-02, -2.3800e-03,  1.5445e-02,  3.4497e-02,  8.1264e-03],\n",
      "          [-6.5896e-03, -6.5839e-03, -3.9498e-02,  4.1526e-02,  2.7906e-02],\n",
      "          [ 2.2473e-02, -2.6372e-02, -1.8882e-02, -7.1881e-03, -1.9555e-02],\n",
      "          [ 7.7351e-03, -2.0289e-02, -1.6317e-02, -1.0031e-02,  2.0914e-02],\n",
      "          [-3.6370e-02,  4.0355e-02, -4.0438e-02,  1.1961e-03,  1.4413e-02]],\n",
      "\n",
      "         [[-2.4243e-02,  2.2458e-02, -2.1771e-02, -4.0958e-02, -3.9501e-02],\n",
      "          [-2.5281e-02, -4.2097e-02,  1.5864e-02,  2.9529e-02,  8.2133e-03],\n",
      "          [ 1.2779e-02, -1.6042e-02, -2.6905e-02, -4.2108e-02,  2.9002e-02],\n",
      "          [-3.7689e-03,  3.3713e-02, -4.2705e-02, -6.2229e-03,  2.9251e-02],\n",
      "          [ 2.1032e-02, -1.4065e-02,  2.9780e-02, -7.3149e-03,  4.4542e-02]],\n",
      "\n",
      "         [[ 2.9797e-02,  1.3442e-02,  2.1907e-02,  9.5086e-03, -7.4628e-03],\n",
      "          [-4.1214e-02,  3.8499e-02, -4.0787e-02, -1.2402e-02,  2.9729e-02],\n",
      "          [-4.2476e-02,  8.7790e-03,  2.8485e-02,  2.3478e-02, -7.8595e-03],\n",
      "          [ 4.3894e-02,  1.6657e-02,  7.4642e-03, -2.0832e-02,  1.8208e-02],\n",
      "          [-4.1413e-02,  1.7705e-02,  2.3917e-02,  3.6095e-02,  3.8194e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.7249e-02, -3.9606e-02, -2.8070e-02, -2.2057e-02,  4.3121e-02],\n",
      "          [-3.6217e-02,  2.1814e-02, -1.9364e-02, -2.7052e-02,  7.7412e-03],\n",
      "          [ 2.4350e-02, -2.3732e-02,  1.2960e-02, -2.9526e-02,  1.0876e-02],\n",
      "          [ 1.6216e-02,  1.3426e-02,  1.1534e-02, -2.2817e-02, -1.1613e-02],\n",
      "          [ 4.4424e-02,  2.1514e-02, -3.7264e-02, -2.8380e-02,  2.2278e-02]],\n",
      "\n",
      "         [[ 2.4852e-02,  1.3120e-03, -3.3125e-02,  3.6662e-02, -1.7711e-02],\n",
      "          [ 4.1447e-02, -1.0737e-02,  4.1522e-02,  3.0341e-02,  1.0605e-03],\n",
      "          [ 2.7778e-02,  2.0047e-02, -1.5795e-02, -1.4917e-02,  4.0850e-02],\n",
      "          [-1.8164e-02,  3.5542e-02,  2.9061e-03,  3.1300e-02, -1.0464e-02],\n",
      "          [-2.7196e-02, -3.5155e-02, -2.5564e-02, -1.8111e-02,  1.6219e-02]],\n",
      "\n",
      "         [[ 2.8847e-02,  3.8610e-02, -3.7006e-02,  2.6762e-02,  9.5074e-03],\n",
      "          [-1.2300e-02,  4.3333e-02, -2.3453e-02, -2.3514e-02,  1.8170e-02],\n",
      "          [ 3.8546e-02, -1.5482e-02,  1.9236e-02, -1.5558e-02,  3.4669e-02],\n",
      "          [-2.9268e-02,  5.5795e-03,  1.9972e-02,  2.2218e-02, -3.1697e-02],\n",
      "          [-5.7558e-03, -1.4165e-02,  3.5511e-02,  3.7467e-02, -1.0994e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2578e-02, -4.0934e-02,  1.0031e-03,  2.6350e-02,  4.3902e-02],\n",
      "          [-1.8724e-02,  2.2131e-03, -2.8826e-03,  2.7051e-02, -3.7452e-02],\n",
      "          [ 3.0801e-02, -1.0946e-02, -4.3301e-02,  7.1428e-03,  1.8152e-02],\n",
      "          [ 2.5136e-02,  3.2709e-02, -1.1749e-02,  3.0171e-02,  2.4673e-02],\n",
      "          [ 6.4744e-04,  2.0682e-02,  2.6621e-02,  1.9631e-02, -1.4142e-02]],\n",
      "\n",
      "         [[-3.1041e-02, -2.9959e-02,  3.6128e-02,  1.1037e-02,  1.5126e-02],\n",
      "          [ 6.4114e-03,  1.5738e-02, -2.4799e-02, -1.6963e-02, -2.9502e-03],\n",
      "          [ 3.8207e-02, -3.9189e-02, -1.7998e-03,  2.2813e-02,  6.5922e-03],\n",
      "          [ 2.3260e-02, -5.0811e-03,  4.1681e-02, -1.3664e-02,  1.4314e-02],\n",
      "          [ 1.0868e-02,  1.4164e-02,  1.0320e-02, -3.4421e-02,  2.3079e-02]],\n",
      "\n",
      "         [[-3.8709e-03, -4.5884e-03, -3.2034e-02, -2.6340e-02,  2.8046e-03],\n",
      "          [-6.6354e-03, -2.4446e-03,  1.0254e-02,  1.9328e-02,  1.0460e-02],\n",
      "          [-3.0746e-02, -4.3053e-02,  2.7434e-02,  3.8315e-02, -1.4270e-02],\n",
      "          [ 4.4698e-02, -3.6625e-02, -3.5081e-02,  3.0166e-02,  2.4285e-02],\n",
      "          [ 4.1931e-02,  1.0568e-02, -1.2445e-02,  1.6330e-03, -1.2520e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.0389e-03,  4.3782e-02, -5.1940e-04,  2.2850e-02,  2.1605e-02],\n",
      "          [ 1.4160e-02, -3.8854e-02, -7.7611e-03, -4.3337e-02,  1.2252e-03],\n",
      "          [ 2.0832e-02,  1.3754e-02, -1.9445e-02, -3.2717e-02, -9.9540e-03],\n",
      "          [-9.0599e-03,  4.2384e-02,  2.3682e-02,  1.9548e-02,  9.8236e-03],\n",
      "          [-3.7137e-02,  1.4879e-02,  1.3697e-02,  1.8488e-02,  8.6679e-03]],\n",
      "\n",
      "         [[-2.1504e-02, -2.8684e-02, -2.1541e-02,  2.6280e-02, -1.5190e-02],\n",
      "          [-1.3465e-02,  1.3366e-02,  2.0097e-02,  2.4113e-02, -3.9746e-02],\n",
      "          [ 4.0663e-02,  3.5875e-02, -1.5183e-02,  3.4423e-02,  2.4190e-02],\n",
      "          [-3.0347e-02, -6.6462e-03,  2.6932e-03,  1.7958e-02,  1.7879e-02],\n",
      "          [-1.2322e-02, -1.2458e-02, -6.4174e-03, -4.2076e-02, -3.6961e-02]],\n",
      "\n",
      "         [[ 1.8222e-02,  2.9477e-02, -1.9522e-02, -2.0459e-02,  1.1576e-02],\n",
      "          [ 2.0440e-02, -1.6325e-02,  1.8169e-02, -2.0270e-02,  4.2348e-02],\n",
      "          [-1.9674e-02,  2.8856e-02, -1.4653e-02,  2.2428e-02, -1.7735e-02],\n",
      "          [ 1.2322e-02,  2.7783e-02, -2.0468e-02,  2.5304e-02,  2.1232e-02],\n",
      "          [-4.1035e-02,  1.4650e-02,  3.3045e-02,  1.7458e-03,  2.9286e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7789e-02,  1.7640e-03,  1.2086e-02,  4.4507e-02, -1.2606e-02],\n",
      "          [-3.1964e-02,  3.6635e-02,  3.0166e-02, -3.5671e-02, -3.0027e-02],\n",
      "          [-4.3975e-03, -9.2740e-03, -3.3009e-02,  8.0766e-03,  3.2855e-02],\n",
      "          [-3.7785e-02, -1.5971e-02,  1.5532e-02,  2.0479e-02,  3.7489e-02],\n",
      "          [-1.6496e-02, -1.4458e-02, -1.8490e-02,  2.8285e-02, -2.7683e-02]],\n",
      "\n",
      "         [[-2.6926e-02,  3.0393e-02, -1.9083e-02,  3.2830e-02,  1.9580e-02],\n",
      "          [-1.5326e-02, -1.7438e-02,  3.5846e-02,  2.0421e-02, -2.9862e-02],\n",
      "          [-6.6215e-03,  3.6671e-02, -1.0708e-02,  4.4942e-03, -1.0037e-02],\n",
      "          [-7.0230e-03, -2.9783e-02,  1.6195e-02, -3.4729e-02, -9.4289e-03],\n",
      "          [-3.1082e-02,  3.0437e-02, -2.5808e-03, -3.4844e-02,  3.9952e-02]],\n",
      "\n",
      "         [[ 1.5605e-03,  2.1072e-02,  4.0759e-02, -3.4410e-02, -9.9889e-03],\n",
      "          [ 2.8503e-02, -2.8598e-02, -1.7125e-02,  2.6419e-02,  3.7950e-02],\n",
      "          [ 1.2104e-02,  3.4167e-02, -1.9368e-02, -3.9980e-02, -6.5718e-05],\n",
      "          [-1.5044e-02,  3.1165e-02,  3.1072e-02,  1.9620e-02,  4.1552e-02],\n",
      "          [ 5.2656e-03,  4.1078e-02,  1.6703e-02,  1.1934e-02,  2.0020e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1226e-02, -7.2046e-03,  1.6561e-02, -3.6813e-02, -2.7376e-02],\n",
      "          [ 1.8073e-02,  4.2585e-02, -4.4385e-04,  1.6336e-02,  1.0326e-02],\n",
      "          [-4.2558e-02, -4.3960e-02,  4.3284e-02, -2.9243e-02,  3.6673e-02],\n",
      "          [ 8.4679e-04, -3.5497e-02,  3.3628e-02,  1.6716e-02,  3.2055e-02],\n",
      "          [-1.5117e-02,  7.4818e-03,  1.8999e-02, -8.3082e-03, -5.0781e-03]],\n",
      "\n",
      "         [[-2.5699e-03, -2.0313e-02, -1.3331e-02,  3.4237e-02,  1.2477e-02],\n",
      "          [ 4.3320e-02,  4.3221e-02,  1.7966e-02, -7.1549e-03, -3.3380e-02],\n",
      "          [ 3.5157e-02, -1.9629e-02,  3.4632e-02, -4.2308e-02,  2.5715e-02],\n",
      "          [ 5.9236e-03,  3.6988e-02,  2.2183e-02,  4.5355e-04,  1.4727e-02],\n",
      "          [ 3.5615e-02,  2.7422e-02,  3.6046e-02,  1.8371e-02, -9.3035e-03]],\n",
      "\n",
      "         [[-2.9249e-03,  4.7906e-03, -1.9014e-02, -5.8861e-04, -2.9165e-02],\n",
      "          [-1.9238e-02,  1.5511e-02,  1.7141e-02,  3.0770e-02,  2.4195e-02],\n",
      "          [-4.1898e-02,  9.7142e-03, -2.2911e-02,  3.0562e-03, -4.2247e-02],\n",
      "          [ 3.4683e-02, -2.5050e-02,  2.8940e-02,  3.6838e-02, -1.3977e-02],\n",
      "          [-9.5603e-03,  2.0265e-02, -3.3812e-02,  4.8652e-03, -2.7712e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9206e-02, -2.3370e-02,  4.1874e-02,  9.2794e-03, -1.8647e-02],\n",
      "          [-3.0248e-02, -1.8132e-02, -2.2661e-02,  2.8046e-02,  1.8495e-02],\n",
      "          [ 2.0112e-02, -1.6288e-02, -3.9490e-02,  4.3749e-02, -2.2336e-02],\n",
      "          [-2.8074e-02, -1.1261e-02, -1.4960e-03,  3.6954e-02, -3.3895e-02],\n",
      "          [ 3.8606e-02, -3.9207e-02, -1.6823e-02, -4.2842e-02, -3.9475e-02]],\n",
      "\n",
      "         [[-3.0318e-02, -2.7166e-02, -3.0701e-02,  1.6818e-02, -4.1738e-02],\n",
      "          [ 3.3124e-02,  3.1018e-02, -3.9477e-02, -2.5237e-02,  2.6618e-03],\n",
      "          [ 4.1177e-02,  3.4102e-02, -3.5817e-02,  3.2750e-02,  3.2617e-02],\n",
      "          [ 1.7862e-02,  3.6788e-02,  4.2428e-02,  2.4823e-02,  2.3796e-03],\n",
      "          [ 3.7870e-02,  2.8152e-02,  2.2414e-02, -8.9268e-03, -9.7000e-03]],\n",
      "\n",
      "         [[ 2.0066e-03,  2.5526e-02,  6.0145e-03,  4.2747e-02,  1.9613e-02],\n",
      "          [ 4.3165e-02, -3.7368e-02,  2.4863e-02, -5.8314e-03, -2.1391e-02],\n",
      "          [-3.6718e-03, -1.4557e-02, -2.8647e-02,  1.0661e-02, -2.3466e-02],\n",
      "          [ 4.0367e-02,  1.1743e-03, -1.7168e-02,  4.2309e-02,  1.6085e-02],\n",
      "          [-3.0506e-02, -4.3064e-02,  1.7004e-02, -7.1136e-04,  1.3486e-02]]]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0205,  0.0420,  0.0365,  0.0310, -0.0221,  0.0032, -0.0048,  0.0203,\n",
      "        -0.0395,  0.0262, -0.0020,  0.0163,  0.0365, -0.0013, -0.0203,  0.0180,\n",
      "         0.0135,  0.0191,  0.0263,  0.0292, -0.0076, -0.0275,  0.0073,  0.0095,\n",
      "         0.0355, -0.0174,  0.0014,  0.0207,  0.0413,  0.0163, -0.0373,  0.0158,\n",
      "        -0.0091,  0.0424, -0.0372, -0.0354, -0.0431,  0.0100, -0.0016,  0.0003,\n",
      "        -0.0195, -0.0045,  0.0235, -0.0408,  0.0046, -0.0324, -0.0353,  0.0011,\n",
      "        -0.0234, -0.0246], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0296,  0.0007, -0.0131,  ...,  0.0133,  0.0276,  0.0050],\n",
      "        [-0.0006, -0.0089,  0.0049,  ...,  0.0228, -0.0342,  0.0240],\n",
      "        [-0.0071, -0.0344,  0.0281,  ..., -0.0094,  0.0044,  0.0243],\n",
      "        ...,\n",
      "        [-0.0179, -0.0294, -0.0013,  ...,  0.0122, -0.0261,  0.0111],\n",
      "        [-0.0073,  0.0029, -0.0010,  ..., -0.0003,  0.0298,  0.0005],\n",
      "        [ 0.0223, -0.0323, -0.0076,  ...,  0.0326,  0.0208, -0.0080]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 2.9510e-02, -1.8969e-02, -3.8287e-03,  3.2711e-02,  1.9295e-02,\n",
      "        -2.2862e-02, -1.5785e-02,  2.0381e-02, -1.6899e-02, -2.6477e-02,\n",
      "        -2.0757e-02, -5.6957e-03, -2.1992e-02,  1.8663e-02,  1.4353e-02,\n",
      "        -1.7122e-02, -1.1634e-02, -2.2243e-02,  6.6168e-03,  7.1320e-03,\n",
      "         3.4748e-02,  2.9315e-02,  4.4236e-03,  1.6818e-02,  1.0476e-02,\n",
      "        -4.7833e-03,  1.4863e-02,  2.4257e-02,  1.1593e-03, -3.2473e-02,\n",
      "        -9.6503e-03,  8.2614e-03, -3.3271e-02, -2.3153e-02, -9.8975e-03,\n",
      "        -1.8717e-02, -1.7357e-02, -1.6774e-02,  2.4000e-02,  1.9404e-02,\n",
      "        -2.1362e-02,  5.4832e-03,  4.7078e-03, -2.0967e-02,  1.2559e-02,\n",
      "        -7.9238e-03,  1.0167e-02,  1.4144e-02,  3.5309e-03, -1.0510e-02,\n",
      "        -3.2250e-02, -1.3986e-02,  8.9844e-03, -8.5950e-04,  3.5929e-03,\n",
      "        -2.1340e-02,  9.2669e-03, -1.2330e-02,  3.0274e-02, -8.4545e-03,\n",
      "        -9.7455e-03,  1.5206e-02, -5.1620e-03, -2.5182e-02, -1.6052e-02,\n",
      "         3.4880e-02, -2.8663e-02, -2.9176e-02,  3.4631e-03, -2.6415e-02,\n",
      "         2.9037e-02,  1.6419e-02,  1.8452e-02, -6.8381e-03, -2.2412e-02,\n",
      "        -1.6648e-02,  3.0377e-02, -2.7671e-02,  2.4614e-02,  3.5303e-02,\n",
      "         6.2008e-03,  1.4592e-02,  2.3610e-02, -3.3147e-02, -3.0093e-02,\n",
      "         6.6706e-03, -3.2295e-02, -3.0817e-02,  1.8119e-02, -2.8496e-02,\n",
      "         2.1931e-02, -2.2057e-02,  1.8967e-02,  2.3663e-02, -7.5968e-03,\n",
      "         1.6465e-02,  1.3821e-02, -1.9504e-02, -4.7206e-03, -2.8000e-02,\n",
      "         3.3613e-04, -2.7316e-02, -1.7995e-02,  2.3286e-02, -2.3540e-02,\n",
      "        -1.3234e-02, -1.5781e-02,  3.0918e-02, -3.1912e-02,  2.9791e-02,\n",
      "         3.0398e-02, -1.7496e-02, -1.8256e-02, -1.9655e-04, -1.6109e-02,\n",
      "         2.9896e-02, -1.4483e-02, -3.1384e-02, -2.7887e-02, -1.2114e-02,\n",
      "        -3.1347e-02, -1.5648e-03, -1.0257e-03, -3.2911e-02,  1.5068e-02,\n",
      "        -2.7237e-02, -1.8671e-02, -1.1867e-02,  2.7849e-02,  1.7432e-02,\n",
      "         1.6924e-02,  2.9757e-02, -8.4115e-03,  3.1402e-03, -3.4992e-02,\n",
      "        -1.8223e-02, -7.0121e-03,  1.2057e-02,  9.3931e-03,  1.6192e-02,\n",
      "         1.5739e-02,  3.2912e-02,  9.7905e-03, -6.4530e-03, -3.1473e-02,\n",
      "         6.0622e-03,  3.3161e-02,  7.6073e-03,  1.1040e-02,  1.4554e-02,\n",
      "        -3.8724e-04, -2.0614e-02,  5.5517e-03,  2.2476e-02, -3.3977e-02,\n",
      "         2.8242e-02, -3.0485e-02,  1.9492e-02, -2.6930e-02, -2.2977e-02,\n",
      "        -1.9428e-02, -1.7184e-02,  1.4953e-02,  2.1451e-02,  1.4127e-02,\n",
      "        -1.2936e-02,  8.4896e-03, -1.8090e-02,  3.0899e-03,  1.9360e-02,\n",
      "         9.4375e-03, -4.4826e-05, -7.5645e-03, -9.6383e-03, -2.8453e-02,\n",
      "        -1.8878e-02,  1.8052e-02,  2.8727e-02, -3.1495e-02, -3.5241e-02,\n",
      "        -2.9084e-02,  3.0497e-02,  3.7177e-03,  9.5561e-03, -2.1462e-03,\n",
      "        -1.0678e-02, -8.9567e-03, -2.7509e-02, -2.4544e-02, -1.8408e-02,\n",
      "         2.5206e-02,  8.8662e-03,  6.0750e-03, -2.8986e-03,  2.3355e-03,\n",
      "         2.6289e-02, -1.0956e-02, -1.5502e-04, -1.1797e-02, -3.0290e-02,\n",
      "         2.1466e-02,  3.3046e-02,  2.2593e-02, -8.3602e-03,  2.5511e-03,\n",
      "        -6.0879e-03, -3.1157e-02, -1.8107e-03,  2.1742e-02, -2.6710e-02,\n",
      "         2.7808e-02, -1.9958e-02,  1.1714e-02, -2.7188e-03, -1.3337e-03,\n",
      "         1.3100e-02, -2.6537e-02, -1.3537e-02, -3.0954e-02,  1.6881e-02,\n",
      "        -1.5962e-03, -8.0269e-03, -9.2944e-03,  3.3749e-02, -2.8954e-02,\n",
      "         5.2328e-03,  3.3100e-02,  2.8361e-02, -2.1578e-02, -1.2792e-02,\n",
      "         2.7915e-02,  2.0203e-02,  4.6235e-05, -3.6566e-03,  3.3969e-02,\n",
      "         1.0195e-03,  7.6625e-03,  3.0379e-02,  3.6802e-03, -1.4538e-02,\n",
      "         1.8194e-02,  2.2711e-02, -1.3942e-02,  1.4871e-02, -6.2922e-03,\n",
      "         3.5190e-02, -2.4850e-02,  1.0844e-02, -3.2307e-02, -2.3932e-02,\n",
      "        -1.0477e-02, -1.6104e-02, -5.5028e-03,  1.5479e-02,  3.0552e-02,\n",
      "        -2.3162e-02, -1.8348e-02, -3.4948e-02, -1.4547e-02, -1.3345e-02,\n",
      "         2.2808e-02, -3.1307e-03,  2.3912e-02,  2.5548e-02,  1.9082e-02,\n",
      "        -1.7472e-02, -1.9315e-02, -2.3536e-02, -3.3186e-02, -3.2563e-02,\n",
      "        -1.6395e-02, -1.3131e-04, -2.4854e-02, -1.5942e-02, -1.2618e-02,\n",
      "        -1.1632e-02, -1.1980e-02,  2.8733e-04, -1.3612e-03,  2.4937e-02,\n",
      "        -2.5740e-02,  9.9039e-03,  3.7971e-03, -2.9229e-03, -1.6787e-02,\n",
      "         2.7445e-02, -3.1657e-02, -3.3542e-03, -2.0553e-02,  3.1368e-02,\n",
      "         2.0365e-02,  2.5428e-02, -7.1919e-03,  1.3014e-02, -6.3205e-03,\n",
      "        -1.9080e-02,  4.0652e-03,  1.4316e-02,  2.3740e-02, -3.3841e-02,\n",
      "        -1.5298e-02,  2.9175e-02,  3.3328e-02, -8.6012e-04, -2.7487e-02,\n",
      "         2.4617e-02, -1.4324e-02, -5.5125e-03,  2.0719e-02,  1.2059e-02,\n",
      "        -1.0054e-02,  2.7330e-02, -1.9756e-02,  1.8499e-02, -2.0876e-02,\n",
      "         3.1559e-02, -1.1351e-02,  2.4118e-02,  3.2860e-02,  2.9304e-02,\n",
      "        -7.2844e-03, -1.5155e-02,  3.2168e-02,  2.0271e-02,  3.5160e-02,\n",
      "         7.4270e-03,  2.7712e-02, -1.6466e-02,  1.1207e-02,  1.3169e-02,\n",
      "        -9.9325e-03,  1.8634e-03,  6.9790e-03, -3.0475e-02, -1.0647e-03,\n",
      "        -1.6901e-03, -3.0587e-02, -2.1194e-02, -1.7208e-02, -2.6901e-02,\n",
      "        -4.4325e-03, -2.6709e-03, -2.4181e-02, -3.8927e-04,  3.2175e-02,\n",
      "         3.4440e-02,  3.4285e-02, -6.6723e-03, -5.0451e-03,  2.4888e-02,\n",
      "         7.1641e-03, -2.6315e-02,  2.8936e-02,  3.3824e-02,  3.4659e-02,\n",
      "        -4.0502e-03, -1.4561e-02,  2.0166e-02,  2.4373e-02,  3.0042e-02,\n",
      "         2.6105e-02, -5.2671e-03,  3.4503e-02,  4.6625e-03, -2.1136e-02,\n",
      "         2.2468e-02, -2.3244e-02,  2.0156e-02,  1.8393e-02,  2.8515e-02,\n",
      "         2.4256e-02,  4.6643e-03,  1.1006e-02, -3.2482e-03,  2.9152e-02,\n",
      "         2.7814e-02,  2.5152e-02, -2.9500e-02,  1.7656e-02,  9.2967e-03,\n",
      "        -2.0305e-02,  2.5830e-02, -3.1438e-02, -7.7912e-03, -2.5238e-02,\n",
      "        -3.5100e-02, -3.3619e-02, -9.0364e-03, -2.2671e-03, -1.6419e-02,\n",
      "         2.3829e-02, -2.6025e-02, -6.3686e-03,  2.0406e-02, -2.5437e-02,\n",
      "         2.0587e-02, -1.9910e-02,  3.1333e-02,  7.0849e-03,  3.1353e-02,\n",
      "         4.4810e-03, -3.2502e-02, -6.0855e-03, -3.5757e-03,  9.0307e-03,\n",
      "        -2.0392e-02, -2.0972e-02, -2.1984e-02,  3.4781e-03, -4.3178e-03,\n",
      "         8.1096e-03, -2.1589e-02,  1.4291e-02, -7.0254e-03,  2.3465e-03,\n",
      "         3.1581e-02,  5.3834e-03,  4.7778e-03,  5.6800e-03,  1.4608e-02,\n",
      "         2.3326e-02,  1.0388e-02, -2.2809e-02,  1.2042e-02, -1.9616e-02,\n",
      "         2.1231e-02, -2.4145e-02, -1.5501e-02, -2.0973e-02, -1.2421e-02,\n",
      "        -2.8661e-02, -1.4100e-02, -6.4883e-04, -3.5005e-02,  7.9924e-03,\n",
      "         1.9092e-02, -2.3888e-02, -2.0346e-02,  1.9931e-02,  2.1538e-02,\n",
      "         3.3327e-02, -1.3638e-02,  8.2001e-03, -1.7793e-02, -6.5622e-03,\n",
      "        -2.9404e-02,  2.6199e-02, -1.4997e-02,  1.6004e-02, -2.7019e-02,\n",
      "        -2.2976e-02, -1.6603e-02,  2.0500e-02, -1.9854e-02,  1.2632e-03,\n",
      "         1.6036e-02, -3.3274e-02, -3.3607e-02, -2.1894e-02,  5.2884e-03,\n",
      "         1.0056e-02, -1.1630e-02,  5.3837e-03, -2.7705e-02,  3.1123e-02,\n",
      "        -2.4981e-02, -1.0746e-02, -1.4759e-02,  3.2861e-03, -2.6092e-02,\n",
      "        -1.6902e-02, -3.1853e-02,  2.3347e-02,  3.1233e-02,  1.9318e-02,\n",
      "        -2.2772e-02,  8.9149e-03,  2.4982e-02, -2.9756e-02, -4.2696e-03,\n",
      "        -2.9727e-03,  1.0376e-02,  1.1196e-02, -1.2968e-02, -1.0851e-02,\n",
      "         1.2446e-02, -1.7457e-02,  9.6321e-05,  3.5216e-02, -6.7010e-03,\n",
      "        -2.2563e-02,  1.6125e-02, -1.8758e-02, -3.1362e-02, -2.6225e-02,\n",
      "        -7.0219e-03,  2.4145e-03, -1.3956e-02,  1.7757e-02, -1.2955e-02],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0130,  0.0284,  0.0101,  ..., -0.0075, -0.0241, -0.0023],\n",
      "        [ 0.0308,  0.0132,  0.0306,  ..., -0.0180, -0.0265,  0.0156],\n",
      "        [ 0.0170,  0.0042,  0.0316,  ...,  0.0308, -0.0286,  0.0183],\n",
      "        ...,\n",
      "        [-0.0077, -0.0136,  0.0380,  ..., -0.0443, -0.0309, -0.0163],\n",
      "        [-0.0321,  0.0345,  0.0132,  ..., -0.0185,  0.0433,  0.0133],\n",
      "        [ 0.0259, -0.0061,  0.0041,  ...,  0.0271, -0.0050, -0.0358]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0104,  0.0396, -0.0018, -0.0359,  0.0033, -0.0024,  0.0007,  0.0069,\n",
      "         0.0154, -0.0213], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in model.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01297603,  0.02842132,  0.01014335, ..., -0.00745563,\n",
       "        -0.02407177, -0.00225234],\n",
       "       [ 0.03080916,  0.01323886,  0.03059926, ..., -0.01799139,\n",
       "        -0.0265331 ,  0.01559756],\n",
       "       [ 0.01701068,  0.00417169,  0.0316051 , ...,  0.03077709,\n",
       "        -0.02863705,  0.01833366],\n",
       "       ...,\n",
       "       [-0.00771326, -0.01363829,  0.03800831, ..., -0.04430421,\n",
       "        -0.03094019, -0.01628821],\n",
       "       [-0.0320928 ,  0.03452658,  0.01318498, ..., -0.0185255 ,\n",
       "         0.04329454,  0.01331757],\n",
       "       [ 0.02591962, -0.00609975,  0.00413742, ...,  0.02711744,\n",
       "        -0.00503955, -0.03584282]], dtype=float32)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc2.weight.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Parameter.set_>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc2.bias.set_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
