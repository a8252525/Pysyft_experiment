{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "n_train_items = 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import syft as sy  # <-- NEW: import the Pysyft library\n",
    "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
    "# simulation functions\n",
    "def connect_to_workers(n_workers):\n",
    "    return [\n",
    "        sy.VirtualWorker(hook, id=f\"worker{i+1}\")\n",
    "        for i in range(n_workers)\n",
    "    ]\n",
    "\n",
    "\n",
    "workers = connect_to_workers(n_workers=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.test_batch_size = 64\n",
    "        self.epochs = epochs\n",
    "        self.lr = 0.01\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 3\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The following options are not supported: num_workers: 1, pin_memory: True\n"
     ]
    }
   ],
   "source": [
    "# federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
    "#     datasets.MNIST('../data', train=True, download=True,\n",
    "#                    transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),\n",
    "#                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                    ]))\n",
    "#     .federate(workers), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "#     batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),\n",
    "#                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                    ])),\n",
    "#     batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size\n",
    ")\n",
    "\n",
    "    \n",
    "#---\n",
    "\n",
    "less_train_dataloader = [\n",
    "        ((data), (target))\n",
    "        for i, (data, target) in enumerate(train_loader)\n",
    "        if i < n_train_items / args.batch_size\n",
    "    ]\n",
    "less_test_dataloader = [\n",
    "        ((data), (target))\n",
    "        for i, (data, target) in enumerate(test_loader)\n",
    "        if i < n_train_items / args.batch_size\n",
    "    ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy \n",
    "# #mnist_dataset.__getitem__(2)[1]\n",
    "# a = (mnist_dataset.__getitem__(0)[0]).numpy()\n",
    "# a.dtype = 'uint8'\n",
    "# print(a)\n",
    "# Image.fromarray(a[0], mode= 'P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, less_train_dataloader, optimizer, epoch, workers):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(less_train_dataloader): # <-- now it is a distributed dataset\n",
    "        model.send(workers[batch_idx%len(workers)]) # <-- NEW: send the model to the right location\n",
    "        \n",
    "        data_on_worker = data.send(workers[batch_idx%len(workers)])\n",
    "        target_on_worker = target.send(workers[batch_idx%len(workers)])\n",
    "        \n",
    "        data_on_worker, target_on_worker = data_on_worker.to(device), target_on_worker.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_on_worker)\n",
    "        loss = F.nll_loss(output, target_on_worker)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.get() # <-- NEW: get the model back\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            loss = loss.get() # <-- NEW: get the loss back\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * args.batch_size, len(less_train_dataloader) * args.batch_size,\n",
    "                100. * batch_idx / len(less_train_dataloader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader*args.batch_size)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader* args.batch_size),\n",
    "        100. * correct / (len(test_loader)*args.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1280 (0%)]\tLoss: 2.324638\n",
      "Train Epoch: 1 [192/1280 (15%)]\tLoss: 2.314684\n",
      "Train Epoch: 1 [384/1280 (30%)]\tLoss: 2.291706\n",
      "Train Epoch: 1 [576/1280 (45%)]\tLoss: 2.310091\n",
      "Train Epoch: 1 [768/1280 (60%)]\tLoss: 2.275877\n",
      "Train Epoch: 1 [960/1280 (75%)]\tLoss: 2.281027\n",
      "Train Epoch: 1 [1152/1280 (90%)]\tLoss: 2.268555\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 2.2690, Accuracy: 252/1280 (20%)\n",
      "\n",
      "Train Epoch: 2 [0/1280 (0%)]\tLoss: 2.277216\n",
      "Train Epoch: 2 [192/1280 (15%)]\tLoss: 2.262702\n",
      "Train Epoch: 2 [384/1280 (30%)]\tLoss: 2.245050\n",
      "Train Epoch: 2 [576/1280 (45%)]\tLoss: 2.264976\n",
      "Train Epoch: 2 [768/1280 (60%)]\tLoss: 2.227021\n",
      "Train Epoch: 2 [960/1280 (75%)]\tLoss: 2.228276\n",
      "Train Epoch: 2 [1152/1280 (90%)]\tLoss: 2.211541\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 2.2258, Accuracy: 538/1280 (42%)\n",
      "\n",
      "Train Epoch: 3 [0/1280 (0%)]\tLoss: 2.226589\n",
      "Train Epoch: 3 [192/1280 (15%)]\tLoss: 2.203862\n",
      "Train Epoch: 3 [384/1280 (30%)]\tLoss: 2.188233\n",
      "Train Epoch: 3 [576/1280 (45%)]\tLoss: 2.211404\n",
      "Train Epoch: 3 [768/1280 (60%)]\tLoss: 2.163832\n",
      "Train Epoch: 3 [960/1280 (75%)]\tLoss: 2.158487\n",
      "Train Epoch: 3 [1152/1280 (90%)]\tLoss: 2.132762\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 2.1616, Accuracy: 558/1280 (44%)\n",
      "\n",
      "Train Epoch: 4 [0/1280 (0%)]\tLoss: 2.153714\n",
      "Train Epoch: 4 [192/1280 (15%)]\tLoss: 2.114891\n",
      "Train Epoch: 4 [384/1280 (30%)]\tLoss: 2.100732\n",
      "Train Epoch: 4 [576/1280 (45%)]\tLoss: 2.128700\n",
      "Train Epoch: 4 [768/1280 (60%)]\tLoss: 2.060370\n",
      "Train Epoch: 4 [960/1280 (75%)]\tLoss: 2.044523\n",
      "Train Epoch: 4 [1152/1280 (90%)]\tLoss: 2.003530\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 2.0504, Accuracy: 607/1280 (47%)\n",
      "\n",
      "Train Epoch: 5 [0/1280 (0%)]\tLoss: 2.029537\n",
      "Train Epoch: 5 [192/1280 (15%)]\tLoss: 1.957552\n",
      "Train Epoch: 5 [384/1280 (30%)]\tLoss: 1.948145\n",
      "Train Epoch: 5 [576/1280 (45%)]\tLoss: 1.981956\n",
      "Train Epoch: 5 [768/1280 (60%)]\tLoss: 1.874076\n",
      "Train Epoch: 5 [960/1280 (75%)]\tLoss: 1.841531\n",
      "Train Epoch: 5 [1152/1280 (90%)]\tLoss: 1.778745\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 1.8518, Accuracy: 678/1280 (53%)\n",
      "\n",
      "Train Epoch: 6 [0/1280 (0%)]\tLoss: 1.809550\n",
      "Train Epoch: 6 [192/1280 (15%)]\tLoss: 1.679309\n",
      "Train Epoch: 6 [384/1280 (30%)]\tLoss: 1.684945\n",
      "Train Epoch: 6 [576/1280 (45%)]\tLoss: 1.735237\n",
      "Train Epoch: 6 [768/1280 (60%)]\tLoss: 1.555564\n",
      "Train Epoch: 6 [960/1280 (75%)]\tLoss: 1.514473\n",
      "Train Epoch: 6 [1152/1280 (90%)]\tLoss: 1.436680\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 1.5526, Accuracy: 765/1280 (60%)\n",
      "\n",
      "Train Epoch: 7 [0/1280 (0%)]\tLoss: 1.478951\n",
      "Train Epoch: 7 [192/1280 (15%)]\tLoss: 1.296345\n",
      "Train Epoch: 7 [384/1280 (30%)]\tLoss: 1.331200\n",
      "Train Epoch: 7 [576/1280 (45%)]\tLoss: 1.418389\n",
      "Train Epoch: 7 [768/1280 (60%)]\tLoss: 1.157233\n",
      "Train Epoch: 7 [960/1280 (75%)]\tLoss: 1.135285\n",
      "Train Epoch: 7 [1152/1280 (90%)]\tLoss: 1.062929\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 1.2383, Accuracy: 855/1280 (67%)\n",
      "\n",
      "Train Epoch: 8 [0/1280 (0%)]\tLoss: 1.132568\n",
      "Train Epoch: 8 [192/1280 (15%)]\tLoss: 0.939146\n",
      "Train Epoch: 8 [384/1280 (30%)]\tLoss: 1.005010\n",
      "Train Epoch: 8 [576/1280 (45%)]\tLoss: 1.134784\n",
      "Train Epoch: 8 [768/1280 (60%)]\tLoss: 0.833044\n",
      "Train Epoch: 8 [960/1280 (75%)]\tLoss: 0.849073\n",
      "Train Epoch: 8 [1152/1280 (90%)]\tLoss: 0.771674\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 1.0080, Accuracy: 909/1280 (71%)\n",
      "\n",
      "Train Epoch: 9 [0/1280 (0%)]\tLoss: 0.885917\n",
      "Train Epoch: 9 [192/1280 (15%)]\tLoss: 0.703052\n",
      "Train Epoch: 9 [384/1280 (30%)]\tLoss: 0.785647\n",
      "Train Epoch: 9 [576/1280 (45%)]\tLoss: 0.929986\n",
      "Train Epoch: 9 [768/1280 (60%)]\tLoss: 0.640221\n",
      "Train Epoch: 9 [960/1280 (75%)]\tLoss: 0.687586\n",
      "Train Epoch: 9 [1152/1280 (90%)]\tLoss: 0.581957\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 0.8679, Accuracy: 928/1280 (72%)\n",
      "\n",
      "Train Epoch: 10 [0/1280 (0%)]\tLoss: 0.733676\n",
      "Train Epoch: 10 [192/1280 (15%)]\tLoss: 0.568930\n",
      "Train Epoch: 10 [384/1280 (30%)]\tLoss: 0.647158\n",
      "Train Epoch: 10 [576/1280 (45%)]\tLoss: 0.786850\n",
      "Train Epoch: 10 [768/1280 (60%)]\tLoss: 0.531604\n",
      "Train Epoch: 10 [960/1280 (75%)]\tLoss: 0.599982\n",
      "Train Epoch: 10 [1152/1280 (90%)]\tLoss: 0.463047\n",
      "before test\n",
      "\n",
      "Test set: Average loss: 0.7895, Accuracy: 944/1280 (74%)\n",
      "\n",
      "CPU times: user 8.86 s, sys: 0 ns, total: 8.86 s\n",
      "Wall time: 8.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, device, less_train_dataloader, optimizer, epoch, workers)\n",
    "    test(args, model, device, less_test_dataloader)\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VirtualWorker id:worker1 #objects:35>\n"
     ]
    }
   ],
   "source": [
    "print(workers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Wrapper)>[PointerTensor | me:60407973905 -> worker1:78163135291]\n",
      "(Wrapper)>[PointerTensor | me:74050153873 -> worker1:11814332395]\n",
      "(Wrapper)>[PointerTensor | me:93651540692 -> worker1:98042234477]\n",
      "(Wrapper)>[PointerTensor | me:1792853962 -> worker1:10207084528]\n",
      "(Wrapper)>[PointerTensor | me:84209531306 -> worker1:30075516339]\n",
      "(Wrapper)>[PointerTensor | me:4457758866 -> worker1:81018670476]\n",
      "(Wrapper)>[PointerTensor | me:37733711282 -> worker1:94469615650]\n",
      "(Wrapper)>[PointerTensor | me:41956409820 -> worker1:31235277075]\n",
      "(Wrapper)>[PointerTensor | me:894364867 -> worker1:14226006381]\n",
      "(Wrapper)>[PointerTensor | me:38101863086 -> worker1:87171777304]\n",
      "(Wrapper)>[PointerTensor | me:95239140209 -> worker1:51638303354]\n",
      "(Wrapper)>[PointerTensor | me:35612061462 -> worker1:68752432269]\n",
      "(Wrapper)>[PointerTensor | me:64152108992 -> worker1:31182305053]\n",
      "(Wrapper)>[PointerTensor | me:51875992271 -> worker1:65242662746]\n",
      "(Wrapper)>[PointerTensor | me:86903732979 -> worker1:47402955970]\n",
      "(Wrapper)>[PointerTensor | me:74349443719 -> worker1:62935393057]\n",
      "(Wrapper)>[PointerTensor | me:24641961433 -> worker1:27217973564]\n",
      "(Wrapper)>[PointerTensor | me:66355971699 -> worker1:79600686106]\n",
      "(Wrapper)>[PointerTensor | me:35692158590 -> worker1:84083579481]\n",
      "(Wrapper)>[PointerTensor | me:75134439842 -> worker1:86741308451]\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "for batch_idx, (data, target) in enumerate(less_train_dataloader):\n",
    "    data = data.send(workers[0])\n",
    "    print(data)\n",
    "#     if batch_idx<3:\n",
    "#         model.send(workers[0])\n",
    "#         print(data.size())\n",
    "        \n",
    "#         pre = model(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          ...,\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "\n",
       "\n",
       "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          ...,\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "\n",
       "\n",
       "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          ...,\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          ...,\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "\n",
       "\n",
       "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          ...,\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "\n",
       "\n",
       "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          ...,\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers[0]._objects[50490937571]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
