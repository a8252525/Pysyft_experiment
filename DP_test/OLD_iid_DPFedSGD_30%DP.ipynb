{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "n_train_items = 6000\n",
    "rounds = 650\n",
    "total_client = 100\n",
    "C = 0.1\n",
    "n_workers = int(total_client * C)\n",
    "batch_size = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import syft as sy  # <-- NEW: import the Pysyft library\n",
    "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
    "# simulation functions\n",
    "def connect_to_workers(n_workers):\n",
    "    return [\n",
    "        sy.VirtualWorker(hook, id=f\"worker{i+1}\")\n",
    "        for i in range(n_workers)\n",
    "    ]\n",
    "\n",
    "\n",
    "workers = connect_to_workers(n_workers=n_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = batch_size\n",
    "        self.test_batch_size = 60\n",
    "        self.epochs = epochs\n",
    "        self.rounds = rounds\n",
    "        self.lr = 0.02\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 2\n",
    "        self.save_model = False\n",
    "        self.n_train_items = n_train_items\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
    "#     datasets.MNIST('../data', train=True, download=True,\n",
    "#                    transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),\n",
    "#                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                    ]))\n",
    "#     .federate(workers), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "#     batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),\n",
    "#                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                    ])),\n",
    "#     batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../data', train=True, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../data', train=False, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size\n",
    ")\n",
    "\n",
    "    \n",
    "#---\n",
    "\n",
    "# less_train_dataloader = [\n",
    "#         ((data), (target))\n",
    "#         for i, (data, target) in enumerate(train_loader)\n",
    "#         if i < (n_train_items / args.batch_size) * 10\n",
    "#     ]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "# print(len(less_train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy \n",
    "# #mnist_dataset.__getitem__(2)[1]\n",
    "# a = (mnist_dataset.__getitem__(0)[0]).numpy()\n",
    "# a.dtype = 'uint8'\n",
    "# print(a)\n",
    "# Image.fromarray(a[0], mode= 'P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*64, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(workers, Net):\n",
    "    model_list = list()\n",
    "    for worker in workers:\n",
    "        model_list.append(Net)\n",
    "    return model_list\n",
    "def opt_init(model_list):\n",
    "    opt_list = list()\n",
    "    for model  in model_list:\n",
    "        opt_list.append(optim.SGD(model.parameters(), lr=args.lr))\n",
    "    return opt_list\n",
    "def random_sample(train_dataloader):\n",
    "    choice_list = sorted(random.sample(range(100), 10))\n",
    "    count = 0\n",
    "    tmp = []\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        if  i == choice_list[count]:\n",
    "            tmp.append(data)\n",
    "            if count == 9:\n",
    "                pass\n",
    "            else:\n",
    "                count += 1\n",
    "    return tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, device, train_loader, opt_list, workers):\n",
    "    global model_list\n",
    "    ## start training and record the model into model_list\n",
    "    \n",
    "    less_train_dataloader = random_sample(train_loader)\n",
    "    for epoch in range(args.epochs):\n",
    "        for batch_idx, (data, target) in enumerate(less_train_dataloader): # <-- now it is a distributed dataset\n",
    "            model_on_worker = model_list[batch_idx%len(workers)]\n",
    "            model_on_worker.train()\n",
    "            model_on_worker.send(workers[batch_idx%len(workers)]) # <-- NEW: send the model to the right location\n",
    "\n",
    "            data_on_worker = data.send(workers[batch_idx%len(workers)])\n",
    "            target_on_worker = target.send(workers[batch_idx%len(workers)])\n",
    "\n",
    "            data_on_worker, target_on_worker = data_on_worker.to(device), target_on_worker.to(device)\n",
    "\n",
    "            opt_list[batch_idx%len(workers)].zero_grad()\n",
    "\n",
    "            output = model_on_worker(data_on_worker)\n",
    "            loss = F.nll_loss(output, target_on_worker)\n",
    "            loss.backward()\n",
    "\n",
    "            opt_list[batch_idx%len(workers)].step()\n",
    "            model_on_worker.get() # <-- NEW: get the model back\n",
    "\n",
    "            model_list[batch_idx%len(workers)] = model_on_worker #When len(dataloader) is longer than the len(worker) send and get must be modified\n",
    "            #model_list here is full of the model which has trained on the workers, there are all different now.\n",
    "\n",
    "        if epoch % args.log_interval == 0:\n",
    "            loss = loss.get() # <-- NEW: get the loss back\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, n_train_items, n_train_items ,\n",
    "                100. * epoch / args.epochs, loss.item()))\n",
    "\n",
    "\n",
    "    ##Aggregation time\n",
    "    new_model = []\n",
    "    tmp_model = Net().to(device)\n",
    "    with torch.no_grad():\n",
    "        for p in model_list[0].parameters():\n",
    "            new_model.append(0)\n",
    "            \n",
    "        for m in model_list:\n",
    "            for par_idx, par in enumerate(m.parameters()):\n",
    "                #average the model_list\n",
    "                new_model[par_idx] = new_model[par_idx]+par.data\n",
    "                # we get new model in list format and need to set_ to model\n",
    "        \n",
    "        for i in range(3):\n",
    "            for n in new_model:\n",
    "                n.add_(torch.normal(0,3*1.5,n.size(),device=device)*args.lr/args.batch_size)\n",
    "        \n",
    "        for worker in range(len(workers)):\n",
    "            for par_idx in range(len(new_model)):\n",
    "                list(model_list[worker].parameters())[par_idx].set_(new_model[par_idx]/len(workers))\n",
    "        #init model with new_model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader, r):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)*(args.test_batch_size)\n",
    "    accuracy = 100. * correct / (len(test_loader)*args.test_batch_size)\n",
    "    #Since the test loader here is a list, we can get the len by * it with batch.size\n",
    "    \n",
    "    \n",
    "    writer.add_scalar('Accuracy', accuracy,r)\n",
    "    writer.add_scalar('Loss', test_loss, r)\n",
    "    print('\\nTest set in round{}: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        r , test_loss, correct, len(test_loader)* (args.test_batch_size),\n",
    "        accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 2.230115\n",
      "After training\n",
      "\n",
      "Test set in round1: Average loss: 2.2204, Accuracy: 3647/10020 (36.40%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 2.119044\n",
      "After training\n",
      "\n",
      "Test set in round2: Average loss: 2.1103, Accuracy: 6068/10020 (60.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 1.942170\n",
      "After training\n",
      "\n",
      "Test set in round3: Average loss: 1.9189, Accuracy: 7124/10020 (71.10%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 1.604916\n",
      "After training\n",
      "\n",
      "Test set in round4: Average loss: 1.5778, Accuracy: 6971/10020 (69.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 1.249088\n",
      "After training\n",
      "\n",
      "Test set in round5: Average loss: 1.1455, Accuracy: 7624/10020 (76.09%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.861324\n",
      "After training\n",
      "\n",
      "Test set in round6: Average loss: 0.8372, Accuracy: 7991/10020 (79.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.915983\n",
      "After training\n",
      "\n",
      "Test set in round7: Average loss: 0.9424, Accuracy: 7345/10020 (73.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.762736\n",
      "After training\n",
      "\n",
      "Test set in round8: Average loss: 0.7453, Accuracy: 7447/10020 (74.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.537284\n",
      "After training\n",
      "\n",
      "Test set in round9: Average loss: 0.5489, Accuracy: 8206/10020 (81.90%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.482977\n",
      "After training\n",
      "\n",
      "Test set in round10: Average loss: 0.4530, Accuracy: 8674/10020 (86.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.468905\n",
      "After training\n",
      "\n",
      "Test set in round11: Average loss: 0.4869, Accuracy: 8382/10020 (83.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.338149\n",
      "After training\n",
      "\n",
      "Test set in round12: Average loss: 0.3765, Accuracy: 8964/10020 (89.46%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.359995\n",
      "After training\n",
      "\n",
      "Test set in round13: Average loss: 0.3818, Accuracy: 8896/10020 (88.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.359132\n",
      "After training\n",
      "\n",
      "Test set in round14: Average loss: 0.3656, Accuracy: 8900/10020 (88.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.407919\n",
      "After training\n",
      "\n",
      "Test set in round15: Average loss: 0.3727, Accuracy: 8873/10020 (88.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.277238\n",
      "After training\n",
      "\n",
      "Test set in round16: Average loss: 0.3114, Accuracy: 9093/10020 (90.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.266040\n",
      "After training\n",
      "\n",
      "Test set in round17: Average loss: 0.2959, Accuracy: 9138/10020 (91.20%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.271504\n",
      "After training\n",
      "\n",
      "Test set in round18: Average loss: 0.2839, Accuracy: 9187/10020 (91.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.202899\n",
      "After training\n",
      "\n",
      "Test set in round19: Average loss: 0.2686, Accuracy: 9218/10020 (92.00%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.346181\n",
      "After training\n",
      "\n",
      "Test set in round20: Average loss: 0.2723, Accuracy: 9231/10020 (92.13%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.300477\n",
      "After training\n",
      "\n",
      "Test set in round21: Average loss: 0.2887, Accuracy: 9168/10020 (91.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.216036\n",
      "After training\n",
      "\n",
      "Test set in round22: Average loss: 0.2446, Accuracy: 9270/10020 (92.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.226035\n",
      "After training\n",
      "\n",
      "Test set in round23: Average loss: 0.2491, Accuracy: 9253/10020 (92.35%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.198087\n",
      "After training\n",
      "\n",
      "Test set in round24: Average loss: 0.2305, Accuracy: 9341/10020 (93.22%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.225652\n",
      "After training\n",
      "\n",
      "Test set in round25: Average loss: 0.2299, Accuracy: 9343/10020 (93.24%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.198506\n",
      "After training\n",
      "\n",
      "Test set in round26: Average loss: 0.2221, Accuracy: 9357/10020 (93.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.184846\n",
      "After training\n",
      "\n",
      "Test set in round27: Average loss: 0.2158, Accuracy: 9342/10020 (93.23%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.138437\n",
      "After training\n",
      "\n",
      "Test set in round28: Average loss: 0.2100, Accuracy: 9379/10020 (93.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.251610\n",
      "After training\n",
      "\n",
      "Test set in round29: Average loss: 0.2161, Accuracy: 9346/10020 (93.27%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.195886\n",
      "After training\n",
      "\n",
      "Test set in round30: Average loss: 0.1982, Accuracy: 9426/10020 (94.07%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.241346\n",
      "After training\n",
      "\n",
      "Test set in round31: Average loss: 0.2099, Accuracy: 9348/10020 (93.29%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.167399\n",
      "After training\n",
      "\n",
      "Test set in round32: Average loss: 0.1898, Accuracy: 9451/10020 (94.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.093333\n",
      "After training\n",
      "\n",
      "Test set in round33: Average loss: 0.1892, Accuracy: 9469/10020 (94.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.185377\n",
      "After training\n",
      "\n",
      "Test set in round34: Average loss: 0.1882, Accuracy: 9438/10020 (94.19%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.247729\n",
      "After training\n",
      "\n",
      "Test set in round35: Average loss: 0.1863, Accuracy: 9473/10020 (94.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.115538\n",
      "After training\n",
      "\n",
      "Test set in round36: Average loss: 0.1798, Accuracy: 9475/10020 (94.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.247667\n",
      "After training\n",
      "\n",
      "Test set in round37: Average loss: 0.1948, Accuracy: 9387/10020 (93.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.189593\n",
      "After training\n",
      "\n",
      "Test set in round38: Average loss: 0.1712, Accuracy: 9491/10020 (94.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.177387\n",
      "After training\n",
      "\n",
      "Test set in round39: Average loss: 0.1689, Accuracy: 9485/10020 (94.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.182426\n",
      "After training\n",
      "\n",
      "Test set in round40: Average loss: 0.1621, Accuracy: 9534/10020 (95.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.156200\n",
      "After training\n",
      "\n",
      "Test set in round41: Average loss: 0.1617, Accuracy: 9514/10020 (94.95%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.181142\n",
      "After training\n",
      "\n",
      "Test set in round42: Average loss: 0.1551, Accuracy: 9557/10020 (95.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.141645\n",
      "After training\n",
      "\n",
      "Test set in round43: Average loss: 0.1521, Accuracy: 9553/10020 (95.34%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.130352\n",
      "After training\n",
      "\n",
      "Test set in round44: Average loss: 0.1490, Accuracy: 9571/10020 (95.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.146460\n",
      "After training\n",
      "\n",
      "Test set in round45: Average loss: 0.1516, Accuracy: 9547/10020 (95.28%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.087791\n",
      "After training\n",
      "\n",
      "Test set in round46: Average loss: 0.1450, Accuracy: 9566/10020 (95.47%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.205614\n",
      "After training\n",
      "\n",
      "Test set in round47: Average loss: 0.1517, Accuracy: 9558/10020 (95.39%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.134668\n",
      "After training\n",
      "\n",
      "Test set in round48: Average loss: 0.1436, Accuracy: 9583/10020 (95.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.129877\n",
      "After training\n",
      "\n",
      "Test set in round49: Average loss: 0.1388, Accuracy: 9598/10020 (95.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.131550\n",
      "After training\n",
      "\n",
      "Test set in round50: Average loss: 0.1345, Accuracy: 9615/10020 (95.96%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.124445\n",
      "After training\n",
      "\n",
      "Test set in round51: Average loss: 0.1398, Accuracy: 9608/10020 (95.89%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.119558\n",
      "After training\n",
      "\n",
      "Test set in round52: Average loss: 0.1313, Accuracy: 9615/10020 (95.96%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.104718\n",
      "After training\n",
      "\n",
      "Test set in round53: Average loss: 0.1276, Accuracy: 9637/10020 (96.18%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.082524\n",
      "After training\n",
      "\n",
      "Test set in round54: Average loss: 0.1269, Accuracy: 9634/10020 (96.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.160008\n",
      "After training\n",
      "\n",
      "Test set in round55: Average loss: 0.1280, Accuracy: 9620/10020 (96.01%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.160036\n",
      "After training\n",
      "\n",
      "Test set in round56: Average loss: 0.1297, Accuracy: 9619/10020 (96.00%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.118988\n",
      "After training\n",
      "\n",
      "Test set in round57: Average loss: 0.1212, Accuracy: 9654/10020 (96.35%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.098062\n",
      "After training\n",
      "\n",
      "Test set in round58: Average loss: 0.1197, Accuracy: 9643/10020 (96.24%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.101789\n",
      "After training\n",
      "\n",
      "Test set in round59: Average loss: 0.1180, Accuracy: 9651/10020 (96.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.142374\n",
      "After training\n",
      "\n",
      "Test set in round60: Average loss: 0.1160, Accuracy: 9663/10020 (96.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.161852\n",
      "After training\n",
      "\n",
      "Test set in round61: Average loss: 0.1218, Accuracy: 9635/10020 (96.16%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.096328\n",
      "After training\n",
      "\n",
      "Test set in round62: Average loss: 0.1173, Accuracy: 9667/10020 (96.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.101647\n",
      "After training\n",
      "\n",
      "Test set in round63: Average loss: 0.1141, Accuracy: 9668/10020 (96.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.086037\n",
      "After training\n",
      "\n",
      "Test set in round64: Average loss: 0.1094, Accuracy: 9690/10020 (96.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.069737\n",
      "After training\n",
      "\n",
      "Test set in round65: Average loss: 0.1081, Accuracy: 9677/10020 (96.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.132984\n",
      "After training\n",
      "\n",
      "Test set in round66: Average loss: 0.1090, Accuracy: 9688/10020 (96.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.088790\n",
      "After training\n",
      "\n",
      "Test set in round67: Average loss: 0.1073, Accuracy: 9696/10020 (96.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.152777\n",
      "After training\n",
      "\n",
      "Test set in round68: Average loss: 0.1122, Accuracy: 9673/10020 (96.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.145670\n",
      "After training\n",
      "\n",
      "Test set in round69: Average loss: 0.1083, Accuracy: 9677/10020 (96.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.096207\n",
      "After training\n",
      "\n",
      "Test set in round70: Average loss: 0.1042, Accuracy: 9696/10020 (96.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.111521\n",
      "After training\n",
      "\n",
      "Test set in round71: Average loss: 0.1082, Accuracy: 9686/10020 (96.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.083900\n",
      "After training\n",
      "\n",
      "Test set in round72: Average loss: 0.1026, Accuracy: 9688/10020 (96.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.099525\n",
      "After training\n",
      "\n",
      "Test set in round73: Average loss: 0.1098, Accuracy: 9680/10020 (96.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042788\n",
      "After training\n",
      "\n",
      "Test set in round74: Average loss: 0.0997, Accuracy: 9692/10020 (96.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.060088\n",
      "After training\n",
      "\n",
      "Test set in round75: Average loss: 0.0973, Accuracy: 9716/10020 (96.97%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.085678\n",
      "After training\n",
      "\n",
      "Test set in round76: Average loss: 0.0956, Accuracy: 9713/10020 (96.94%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.092637\n",
      "After training\n",
      "\n",
      "Test set in round77: Average loss: 0.1009, Accuracy: 9709/10020 (96.90%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.085079\n",
      "After training\n",
      "\n",
      "Test set in round78: Average loss: 0.0935, Accuracy: 9730/10020 (97.11%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.085704\n",
      "After training\n",
      "\n",
      "Test set in round79: Average loss: 0.0972, Accuracy: 9710/10020 (96.91%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.134344\n",
      "After training\n",
      "\n",
      "Test set in round80: Average loss: 0.0950, Accuracy: 9716/10020 (96.97%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.134984\n",
      "After training\n",
      "\n",
      "Test set in round81: Average loss: 0.0941, Accuracy: 9722/10020 (97.03%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.120650\n",
      "After training\n",
      "\n",
      "Test set in round82: Average loss: 0.0906, Accuracy: 9722/10020 (97.03%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032152\n",
      "After training\n",
      "\n",
      "Test set in round83: Average loss: 0.0917, Accuracy: 9722/10020 (97.03%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.074838\n",
      "After training\n",
      "\n",
      "Test set in round84: Average loss: 0.0940, Accuracy: 9725/10020 (97.06%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.079530\n",
      "After training\n",
      "\n",
      "Test set in round85: Average loss: 0.0890, Accuracy: 9738/10020 (97.19%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.109033\n",
      "After training\n",
      "\n",
      "Test set in round86: Average loss: 0.0888, Accuracy: 9728/10020 (97.09%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.146321\n",
      "After training\n",
      "\n",
      "Test set in round87: Average loss: 0.1000, Accuracy: 9675/10020 (96.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.149750\n",
      "After training\n",
      "\n",
      "Test set in round88: Average loss: 0.0881, Accuracy: 9734/10020 (97.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.122666\n",
      "After training\n",
      "\n",
      "Test set in round89: Average loss: 0.0867, Accuracy: 9743/10020 (97.24%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.104463\n",
      "After training\n",
      "\n",
      "Test set in round90: Average loss: 0.0849, Accuracy: 9748/10020 (97.29%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049833\n",
      "After training\n",
      "\n",
      "Test set in round91: Average loss: 0.0826, Accuracy: 9763/10020 (97.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.141296\n",
      "After training\n",
      "\n",
      "Test set in round92: Average loss: 0.0848, Accuracy: 9749/10020 (97.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044294\n",
      "After training\n",
      "\n",
      "Test set in round93: Average loss: 0.0832, Accuracy: 9757/10020 (97.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.045490\n",
      "After training\n",
      "\n",
      "Test set in round94: Average loss: 0.0827, Accuracy: 9747/10020 (97.28%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028710\n",
      "After training\n",
      "\n",
      "Test set in round95: Average loss: 0.0828, Accuracy: 9749/10020 (97.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.067292\n",
      "After training\n",
      "\n",
      "Test set in round96: Average loss: 0.0796, Accuracy: 9763/10020 (97.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.117149\n",
      "After training\n",
      "\n",
      "Test set in round97: Average loss: 0.0844, Accuracy: 9738/10020 (97.19%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.067622\n",
      "After training\n",
      "\n",
      "Test set in round98: Average loss: 0.0789, Accuracy: 9772/10020 (97.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.082371\n",
      "After training\n",
      "\n",
      "Test set in round99: Average loss: 0.0834, Accuracy: 9752/10020 (97.33%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.139375\n",
      "After training\n",
      "\n",
      "Test set in round100: Average loss: 0.0798, Accuracy: 9764/10020 (97.45%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.045550\n",
      "After training\n",
      "\n",
      "Test set in round101: Average loss: 0.0766, Accuracy: 9775/10020 (97.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.116865\n",
      "After training\n",
      "\n",
      "Test set in round102: Average loss: 0.0764, Accuracy: 9767/10020 (97.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.135393\n",
      "After training\n",
      "\n",
      "Test set in round103: Average loss: 0.0781, Accuracy: 9774/10020 (97.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.065024\n",
      "After training\n",
      "\n",
      "Test set in round104: Average loss: 0.0760, Accuracy: 9783/10020 (97.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.067830\n",
      "After training\n",
      "\n",
      "Test set in round105: Average loss: 0.0751, Accuracy: 9777/10020 (97.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027439\n",
      "After training\n",
      "\n",
      "Test set in round106: Average loss: 0.0788, Accuracy: 9751/10020 (97.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.085533\n",
      "After training\n",
      "\n",
      "Test set in round107: Average loss: 0.0725, Accuracy: 9786/10020 (97.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026026\n",
      "After training\n",
      "\n",
      "Test set in round108: Average loss: 0.0728, Accuracy: 9771/10020 (97.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.070429\n",
      "After training\n",
      "\n",
      "Test set in round109: Average loss: 0.0711, Accuracy: 9784/10020 (97.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.114700\n",
      "After training\n",
      "\n",
      "Test set in round110: Average loss: 0.0753, Accuracy: 9769/10020 (97.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023265\n",
      "After training\n",
      "\n",
      "Test set in round111: Average loss: 0.0729, Accuracy: 9774/10020 (97.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049970\n",
      "After training\n",
      "\n",
      "Test set in round112: Average loss: 0.0695, Accuracy: 9786/10020 (97.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.102166\n",
      "After training\n",
      "\n",
      "Test set in round113: Average loss: 0.0713, Accuracy: 9783/10020 (97.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.040418\n",
      "After training\n",
      "\n",
      "Test set in round114: Average loss: 0.0726, Accuracy: 9784/10020 (97.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.101573\n",
      "After training\n",
      "\n",
      "Test set in round115: Average loss: 0.0703, Accuracy: 9783/10020 (97.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.104140\n",
      "After training\n",
      "\n",
      "Test set in round116: Average loss: 0.0686, Accuracy: 9796/10020 (97.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.069432\n",
      "After training\n",
      "\n",
      "Test set in round117: Average loss: 0.0692, Accuracy: 9791/10020 (97.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051843\n",
      "After training\n",
      "\n",
      "Test set in round118: Average loss: 0.0682, Accuracy: 9794/10020 (97.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.059266\n",
      "After training\n",
      "\n",
      "Test set in round119: Average loss: 0.0703, Accuracy: 9780/10020 (97.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.084678\n",
      "After training\n",
      "\n",
      "Test set in round120: Average loss: 0.0681, Accuracy: 9789/10020 (97.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047343\n",
      "After training\n",
      "\n",
      "Test set in round121: Average loss: 0.0682, Accuracy: 9795/10020 (97.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.059087\n",
      "After training\n",
      "\n",
      "Test set in round122: Average loss: 0.0662, Accuracy: 9795/10020 (97.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.102002\n",
      "After training\n",
      "\n",
      "Test set in round123: Average loss: 0.0688, Accuracy: 9790/10020 (97.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.056861\n",
      "After training\n",
      "\n",
      "Test set in round124: Average loss: 0.0663, Accuracy: 9801/10020 (97.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.084127\n",
      "After training\n",
      "\n",
      "Test set in round125: Average loss: 0.0655, Accuracy: 9807/10020 (97.87%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038830\n",
      "After training\n",
      "\n",
      "Test set in round126: Average loss: 0.0651, Accuracy: 9804/10020 (97.84%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.085563\n",
      "After training\n",
      "\n",
      "Test set in round127: Average loss: 0.0670, Accuracy: 9795/10020 (97.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.054066\n",
      "After training\n",
      "\n",
      "Test set in round128: Average loss: 0.0694, Accuracy: 9790/10020 (97.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020576\n",
      "After training\n",
      "\n",
      "Test set in round129: Average loss: 0.0642, Accuracy: 9798/10020 (97.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.080380\n",
      "After training\n",
      "\n",
      "Test set in round130: Average loss: 0.0639, Accuracy: 9811/10020 (97.91%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.086872\n",
      "After training\n",
      "\n",
      "Test set in round131: Average loss: 0.0632, Accuracy: 9806/10020 (97.86%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049947\n",
      "After training\n",
      "\n",
      "Test set in round132: Average loss: 0.0647, Accuracy: 9797/10020 (97.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021140\n",
      "After training\n",
      "\n",
      "Test set in round133: Average loss: 0.0631, Accuracy: 9802/10020 (97.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034662\n",
      "After training\n",
      "\n",
      "Test set in round134: Average loss: 0.0624, Accuracy: 9809/10020 (97.89%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.064871\n",
      "After training\n",
      "\n",
      "Test set in round135: Average loss: 0.0615, Accuracy: 9804/10020 (97.84%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.088074\n",
      "After training\n",
      "\n",
      "Test set in round136: Average loss: 0.0635, Accuracy: 9805/10020 (97.85%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016520\n",
      "After training\n",
      "\n",
      "Test set in round137: Average loss: 0.0623, Accuracy: 9812/10020 (97.92%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.065952\n",
      "After training\n",
      "\n",
      "Test set in round138: Average loss: 0.0619, Accuracy: 9800/10020 (97.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.097884\n",
      "After training\n",
      "\n",
      "Test set in round139: Average loss: 0.0645, Accuracy: 9797/10020 (97.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.100296\n",
      "After training\n",
      "\n",
      "Test set in round140: Average loss: 0.0609, Accuracy: 9809/10020 (97.89%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049888\n",
      "After training\n",
      "\n",
      "Test set in round141: Average loss: 0.0628, Accuracy: 9801/10020 (97.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017558\n",
      "After training\n",
      "\n",
      "Test set in round142: Average loss: 0.0607, Accuracy: 9806/10020 (97.86%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044800\n",
      "After training\n",
      "\n",
      "Test set in round143: Average loss: 0.0626, Accuracy: 9801/10020 (97.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034983\n",
      "After training\n",
      "\n",
      "Test set in round144: Average loss: 0.0603, Accuracy: 9814/10020 (97.94%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017449\n",
      "After training\n",
      "\n",
      "Test set in round145: Average loss: 0.0589, Accuracy: 9813/10020 (97.93%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017061\n",
      "After training\n",
      "\n",
      "Test set in round146: Average loss: 0.0592, Accuracy: 9819/10020 (97.99%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.130425\n",
      "After training\n",
      "\n",
      "Test set in round147: Average loss: 0.0618, Accuracy: 9807/10020 (97.87%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.077652\n",
      "After training\n",
      "\n",
      "Test set in round148: Average loss: 0.0578, Accuracy: 9815/10020 (97.95%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.089441\n",
      "After training\n",
      "\n",
      "Test set in round149: Average loss: 0.0603, Accuracy: 9815/10020 (97.95%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.091945\n",
      "After training\n",
      "\n",
      "Test set in round150: Average loss: 0.0610, Accuracy: 9814/10020 (97.94%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053517\n",
      "After training\n",
      "\n",
      "Test set in round151: Average loss: 0.0566, Accuracy: 9831/10020 (98.11%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028255\n",
      "After training\n",
      "\n",
      "Test set in round152: Average loss: 0.0590, Accuracy: 9824/10020 (98.04%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042435\n",
      "After training\n",
      "\n",
      "Test set in round153: Average loss: 0.0587, Accuracy: 9809/10020 (97.89%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049408\n",
      "After training\n",
      "\n",
      "Test set in round154: Average loss: 0.0573, Accuracy: 9819/10020 (97.99%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042119\n",
      "After training\n",
      "\n",
      "Test set in round155: Average loss: 0.0577, Accuracy: 9820/10020 (98.00%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017653\n",
      "After training\n",
      "\n",
      "Test set in round156: Average loss: 0.0557, Accuracy: 9826/10020 (98.06%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.130251\n",
      "After training\n",
      "\n",
      "Test set in round157: Average loss: 0.0562, Accuracy: 9831/10020 (98.11%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030803\n",
      "After training\n",
      "\n",
      "Test set in round158: Average loss: 0.0573, Accuracy: 9827/10020 (98.07%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.069755\n",
      "After training\n",
      "\n",
      "Test set in round159: Average loss: 0.0567, Accuracy: 9833/10020 (98.13%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.071096\n",
      "After training\n",
      "\n",
      "Test set in round160: Average loss: 0.0558, Accuracy: 9819/10020 (97.99%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017489\n",
      "After training\n",
      "\n",
      "Test set in round161: Average loss: 0.0555, Accuracy: 9826/10020 (98.06%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029172\n",
      "After training\n",
      "\n",
      "Test set in round162: Average loss: 0.0565, Accuracy: 9828/10020 (98.08%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.086346\n",
      "After training\n",
      "\n",
      "Test set in round163: Average loss: 0.0552, Accuracy: 9830/10020 (98.10%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.048041\n",
      "After training\n",
      "\n",
      "Test set in round164: Average loss: 0.0561, Accuracy: 9829/10020 (98.09%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044279\n",
      "After training\n",
      "\n",
      "Test set in round165: Average loss: 0.0551, Accuracy: 9831/10020 (98.11%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044989\n",
      "After training\n",
      "\n",
      "Test set in round166: Average loss: 0.0533, Accuracy: 9835/10020 (98.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.074254\n",
      "After training\n",
      "\n",
      "Test set in round167: Average loss: 0.0533, Accuracy: 9830/10020 (98.10%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038979\n",
      "After training\n",
      "\n",
      "Test set in round168: Average loss: 0.0521, Accuracy: 9841/10020 (98.21%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036742\n",
      "After training\n",
      "\n",
      "Test set in round169: Average loss: 0.0549, Accuracy: 9824/10020 (98.04%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051027\n",
      "After training\n",
      "\n",
      "Test set in round170: Average loss: 0.0528, Accuracy: 9843/10020 (98.23%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051191\n",
      "After training\n",
      "\n",
      "Test set in round171: Average loss: 0.0567, Accuracy: 9824/10020 (98.04%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051541\n",
      "After training\n",
      "\n",
      "Test set in round172: Average loss: 0.0536, Accuracy: 9836/10020 (98.16%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.069403\n",
      "After training\n",
      "\n",
      "Test set in round173: Average loss: 0.0532, Accuracy: 9837/10020 (98.17%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.014663\n",
      "After training\n",
      "\n",
      "Test set in round174: Average loss: 0.0537, Accuracy: 9818/10020 (97.98%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015976\n",
      "After training\n",
      "\n",
      "Test set in round175: Average loss: 0.0534, Accuracy: 9824/10020 (98.04%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.054640\n",
      "After training\n",
      "\n",
      "Test set in round176: Average loss: 0.0529, Accuracy: 9837/10020 (98.17%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044886\n",
      "After training\n",
      "\n",
      "Test set in round177: Average loss: 0.0523, Accuracy: 9835/10020 (98.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051253\n",
      "After training\n",
      "\n",
      "Test set in round178: Average loss: 0.0514, Accuracy: 9842/10020 (98.22%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051892\n",
      "After training\n",
      "\n",
      "Test set in round179: Average loss: 0.0533, Accuracy: 9831/10020 (98.11%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.074235\n",
      "After training\n",
      "\n",
      "Test set in round180: Average loss: 0.0573, Accuracy: 9820/10020 (98.00%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.068292\n",
      "After training\n",
      "\n",
      "Test set in round181: Average loss: 0.0560, Accuracy: 9818/10020 (97.98%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.082183\n",
      "After training\n",
      "\n",
      "Test set in round182: Average loss: 0.0539, Accuracy: 9841/10020 (98.21%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039925\n",
      "After training\n",
      "\n",
      "Test set in round183: Average loss: 0.0500, Accuracy: 9842/10020 (98.22%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.122040\n",
      "After training\n",
      "\n",
      "Test set in round184: Average loss: 0.0509, Accuracy: 9833/10020 (98.13%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.062947\n",
      "After training\n",
      "\n",
      "Test set in round185: Average loss: 0.0500, Accuracy: 9846/10020 (98.26%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.067317\n",
      "After training\n",
      "\n",
      "Test set in round186: Average loss: 0.0564, Accuracy: 9821/10020 (98.01%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.076760\n",
      "After training\n",
      "\n",
      "Test set in round187: Average loss: 0.0501, Accuracy: 9842/10020 (98.22%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039867\n",
      "After training\n",
      "\n",
      "Test set in round188: Average loss: 0.0498, Accuracy: 9839/10020 (98.19%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.112550\n",
      "After training\n",
      "\n",
      "Test set in round189: Average loss: 0.0512, Accuracy: 9834/10020 (98.14%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012976\n",
      "After training\n",
      "\n",
      "Test set in round190: Average loss: 0.0504, Accuracy: 9840/10020 (98.20%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.063021\n",
      "After training\n",
      "\n",
      "Test set in round191: Average loss: 0.0490, Accuracy: 9843/10020 (98.23%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.060608\n",
      "After training\n",
      "\n",
      "Test set in round192: Average loss: 0.0525, Accuracy: 9826/10020 (98.06%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047411\n",
      "After training\n",
      "\n",
      "Test set in round193: Average loss: 0.0507, Accuracy: 9848/10020 (98.28%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042658\n",
      "After training\n",
      "\n",
      "Test set in round194: Average loss: 0.0497, Accuracy: 9835/10020 (98.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051847\n",
      "After training\n",
      "\n",
      "Test set in round195: Average loss: 0.0514, Accuracy: 9831/10020 (98.11%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036345\n",
      "After training\n",
      "\n",
      "Test set in round196: Average loss: 0.0510, Accuracy: 9838/10020 (98.18%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.076456\n",
      "After training\n",
      "\n",
      "Test set in round197: Average loss: 0.0490, Accuracy: 9841/10020 (98.21%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.075425\n",
      "After training\n",
      "\n",
      "Test set in round198: Average loss: 0.0510, Accuracy: 9838/10020 (98.18%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038772\n",
      "After training\n",
      "\n",
      "Test set in round199: Average loss: 0.0494, Accuracy: 9840/10020 (98.20%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.067262\n",
      "After training\n",
      "\n",
      "Test set in round200: Average loss: 0.0511, Accuracy: 9840/10020 (98.20%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.118699\n",
      "After training\n",
      "\n",
      "Test set in round201: Average loss: 0.0499, Accuracy: 9850/10020 (98.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.014131\n",
      "After training\n",
      "\n",
      "Test set in round202: Average loss: 0.0478, Accuracy: 9842/10020 (98.22%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042319\n",
      "After training\n",
      "\n",
      "Test set in round203: Average loss: 0.0481, Accuracy: 9842/10020 (98.22%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.076326\n",
      "After training\n",
      "\n",
      "Test set in round204: Average loss: 0.0472, Accuracy: 9841/10020 (98.21%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039144\n",
      "After training\n",
      "\n",
      "Test set in round205: Average loss: 0.0482, Accuracy: 9850/10020 (98.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.071046\n",
      "After training\n",
      "\n",
      "Test set in round206: Average loss: 0.0586, Accuracy: 9815/10020 (97.95%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035991\n",
      "After training\n",
      "\n",
      "Test set in round207: Average loss: 0.0482, Accuracy: 9844/10020 (98.24%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025424\n",
      "After training\n",
      "\n",
      "Test set in round208: Average loss: 0.0471, Accuracy: 9849/10020 (98.29%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.073450\n",
      "After training\n",
      "\n",
      "Test set in round209: Average loss: 0.0491, Accuracy: 9859/10020 (98.39%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025469\n",
      "After training\n",
      "\n",
      "Test set in round210: Average loss: 0.0459, Accuracy: 9859/10020 (98.39%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053517\n",
      "After training\n",
      "\n",
      "Test set in round211: Average loss: 0.0467, Accuracy: 9846/10020 (98.26%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.059861\n",
      "After training\n",
      "\n",
      "Test set in round212: Average loss: 0.0476, Accuracy: 9843/10020 (98.23%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.065095\n",
      "After training\n",
      "\n",
      "Test set in round213: Average loss: 0.0460, Accuracy: 9855/10020 (98.35%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022832\n",
      "After training\n",
      "\n",
      "Test set in round214: Average loss: 0.0464, Accuracy: 9858/10020 (98.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.011453\n",
      "After training\n",
      "\n",
      "Test set in round215: Average loss: 0.0472, Accuracy: 9847/10020 (98.27%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034239\n",
      "After training\n",
      "\n",
      "Test set in round216: Average loss: 0.0470, Accuracy: 9845/10020 (98.25%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046990\n",
      "After training\n",
      "\n",
      "Test set in round217: Average loss: 0.0478, Accuracy: 9849/10020 (98.29%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.062435\n",
      "After training\n",
      "\n",
      "Test set in round218: Average loss: 0.0519, Accuracy: 9838/10020 (98.18%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.054838\n",
      "After training\n",
      "\n",
      "Test set in round219: Average loss: 0.0461, Accuracy: 9849/10020 (98.29%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.109424\n",
      "After training\n",
      "\n",
      "Test set in round220: Average loss: 0.0462, Accuracy: 9850/10020 (98.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039046\n",
      "After training\n",
      "\n",
      "Test set in round221: Average loss: 0.0444, Accuracy: 9857/10020 (98.37%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.065732\n",
      "After training\n",
      "\n",
      "Test set in round222: Average loss: 0.0453, Accuracy: 9858/10020 (98.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036413\n",
      "After training\n",
      "\n",
      "Test set in round223: Average loss: 0.0468, Accuracy: 9856/10020 (98.36%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.050694\n",
      "After training\n",
      "\n",
      "Test set in round224: Average loss: 0.0453, Accuracy: 9856/10020 (98.36%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055362\n",
      "After training\n",
      "\n",
      "Test set in round225: Average loss: 0.0480, Accuracy: 9844/10020 (98.24%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.100787\n",
      "After training\n",
      "\n",
      "Test set in round226: Average loss: 0.0479, Accuracy: 9848/10020 (98.28%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039745\n",
      "After training\n",
      "\n",
      "Test set in round227: Average loss: 0.0471, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.065661\n",
      "After training\n",
      "\n",
      "Test set in round228: Average loss: 0.0433, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046557\n",
      "After training\n",
      "\n",
      "Test set in round229: Average loss: 0.0450, Accuracy: 9854/10020 (98.34%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022158\n",
      "After training\n",
      "\n",
      "Test set in round230: Average loss: 0.0448, Accuracy: 9854/10020 (98.34%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053316\n",
      "After training\n",
      "\n",
      "Test set in round231: Average loss: 0.0432, Accuracy: 9866/10020 (98.46%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053737\n",
      "After training\n",
      "\n",
      "Test set in round232: Average loss: 0.0465, Accuracy: 9847/10020 (98.27%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034487\n",
      "After training\n",
      "\n",
      "Test set in round233: Average loss: 0.0438, Accuracy: 9856/10020 (98.36%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.056393\n",
      "After training\n",
      "\n",
      "Test set in round234: Average loss: 0.0434, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047944\n",
      "After training\n",
      "\n",
      "Test set in round235: Average loss: 0.0441, Accuracy: 9857/10020 (98.37%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046476\n",
      "After training\n",
      "\n",
      "Test set in round236: Average loss: 0.0441, Accuracy: 9851/10020 (98.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.056834\n",
      "After training\n",
      "\n",
      "Test set in round237: Average loss: 0.0429, Accuracy: 9860/10020 (98.40%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039550\n",
      "After training\n",
      "\n",
      "Test set in round238: Average loss: 0.0455, Accuracy: 9855/10020 (98.35%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.107625\n",
      "After training\n",
      "\n",
      "Test set in round239: Average loss: 0.0457, Accuracy: 9859/10020 (98.39%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010710\n",
      "After training\n",
      "\n",
      "Test set in round240: Average loss: 0.0435, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.105818\n",
      "After training\n",
      "\n",
      "Test set in round241: Average loss: 0.0435, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012834\n",
      "After training\n",
      "\n",
      "Test set in round242: Average loss: 0.0412, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033877\n",
      "After training\n",
      "\n",
      "Test set in round243: Average loss: 0.0438, Accuracy: 9860/10020 (98.40%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031740\n",
      "After training\n",
      "\n",
      "Test set in round244: Average loss: 0.0423, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038238\n",
      "After training\n",
      "\n",
      "Test set in round245: Average loss: 0.0435, Accuracy: 9865/10020 (98.45%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.100464\n",
      "After training\n",
      "\n",
      "Test set in round246: Average loss: 0.0440, Accuracy: 9852/10020 (98.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021679\n",
      "After training\n",
      "\n",
      "Test set in round247: Average loss: 0.0435, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032455\n",
      "After training\n",
      "\n",
      "Test set in round248: Average loss: 0.0439, Accuracy: 9854/10020 (98.34%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.098138\n",
      "After training\n",
      "\n",
      "Test set in round249: Average loss: 0.0414, Accuracy: 9867/10020 (98.47%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038435\n",
      "After training\n",
      "\n",
      "Test set in round250: Average loss: 0.0417, Accuracy: 9864/10020 (98.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035071\n",
      "After training\n",
      "\n",
      "Test set in round251: Average loss: 0.0418, Accuracy: 9867/10020 (98.47%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037180\n",
      "After training\n",
      "\n",
      "Test set in round252: Average loss: 0.0413, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.040334\n",
      "After training\n",
      "\n",
      "Test set in round253: Average loss: 0.0428, Accuracy: 9859/10020 (98.39%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033083\n",
      "After training\n",
      "\n",
      "Test set in round254: Average loss: 0.0412, Accuracy: 9866/10020 (98.46%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028625\n",
      "After training\n",
      "\n",
      "Test set in round255: Average loss: 0.0425, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046364\n",
      "After training\n",
      "\n",
      "Test set in round256: Average loss: 0.0420, Accuracy: 9864/10020 (98.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039623\n",
      "After training\n",
      "\n",
      "Test set in round257: Average loss: 0.0412, Accuracy: 9861/10020 (98.41%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.092476\n",
      "After training\n",
      "\n",
      "Test set in round258: Average loss: 0.0429, Accuracy: 9857/10020 (98.37%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.009782\n",
      "After training\n",
      "\n",
      "Test set in round259: Average loss: 0.0428, Accuracy: 9850/10020 (98.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033744\n",
      "After training\n",
      "\n",
      "Test set in round260: Average loss: 0.0419, Accuracy: 9864/10020 (98.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008452\n",
      "After training\n",
      "\n",
      "Test set in round261: Average loss: 0.0419, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053720\n",
      "After training\n",
      "\n",
      "Test set in round262: Average loss: 0.0437, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039681\n",
      "After training\n",
      "\n",
      "Test set in round263: Average loss: 0.0437, Accuracy: 9859/10020 (98.39%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.092949\n",
      "After training\n",
      "\n",
      "Test set in round264: Average loss: 0.0413, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024902\n",
      "After training\n",
      "\n",
      "Test set in round265: Average loss: 0.0422, Accuracy: 9865/10020 (98.45%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039588\n",
      "After training\n",
      "\n",
      "Test set in round266: Average loss: 0.0400, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.048510\n",
      "After training\n",
      "\n",
      "Test set in round267: Average loss: 0.0425, Accuracy: 9855/10020 (98.35%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041970\n",
      "After training\n",
      "\n",
      "Test set in round268: Average loss: 0.0399, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049815\n",
      "After training\n",
      "\n",
      "Test set in round269: Average loss: 0.0434, Accuracy: 9865/10020 (98.45%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.050901\n",
      "After training\n",
      "\n",
      "Test set in round270: Average loss: 0.0413, Accuracy: 9865/10020 (98.45%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042203\n",
      "After training\n",
      "\n",
      "Test set in round271: Average loss: 0.0406, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.043549\n",
      "After training\n",
      "\n",
      "Test set in round272: Average loss: 0.0405, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033478\n",
      "After training\n",
      "\n",
      "Test set in round273: Average loss: 0.0401, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031979\n",
      "After training\n",
      "\n",
      "Test set in round274: Average loss: 0.0414, Accuracy: 9866/10020 (98.46%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034430\n",
      "After training\n",
      "\n",
      "Test set in round275: Average loss: 0.0402, Accuracy: 9864/10020 (98.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035441\n",
      "After training\n",
      "\n",
      "Test set in round276: Average loss: 0.0401, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025683\n",
      "After training\n",
      "\n",
      "Test set in round277: Average loss: 0.0437, Accuracy: 9861/10020 (98.41%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049560\n",
      "After training\n",
      "\n",
      "Test set in round278: Average loss: 0.0441, Accuracy: 9856/10020 (98.36%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036293\n",
      "After training\n",
      "\n",
      "Test set in round279: Average loss: 0.0397, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035036\n",
      "After training\n",
      "\n",
      "Test set in round280: Average loss: 0.0392, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027761\n",
      "After training\n",
      "\n",
      "Test set in round281: Average loss: 0.0392, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.097262\n",
      "After training\n",
      "\n",
      "Test set in round282: Average loss: 0.0407, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032091\n",
      "After training\n",
      "\n",
      "Test set in round283: Average loss: 0.0402, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026579\n",
      "After training\n",
      "\n",
      "Test set in round284: Average loss: 0.0387, Accuracy: 9876/10020 (98.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.048782\n",
      "After training\n",
      "\n",
      "Test set in round285: Average loss: 0.0391, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018881\n",
      "After training\n",
      "\n",
      "Test set in round286: Average loss: 0.0386, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030058\n",
      "After training\n",
      "\n",
      "Test set in round287: Average loss: 0.0375, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044891\n",
      "After training\n",
      "\n",
      "Test set in round288: Average loss: 0.0420, Accuracy: 9858/10020 (98.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031926\n",
      "After training\n",
      "\n",
      "Test set in round289: Average loss: 0.0393, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010685\n",
      "After training\n",
      "\n",
      "Test set in round290: Average loss: 0.0392, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008940\n",
      "After training\n",
      "\n",
      "Test set in round291: Average loss: 0.0376, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.045085\n",
      "After training\n",
      "\n",
      "Test set in round292: Average loss: 0.0376, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.009416\n",
      "After training\n",
      "\n",
      "Test set in round293: Average loss: 0.0385, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019032\n",
      "After training\n",
      "\n",
      "Test set in round294: Average loss: 0.0377, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028115\n",
      "After training\n",
      "\n",
      "Test set in round295: Average loss: 0.0381, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.014940\n",
      "After training\n",
      "\n",
      "Test set in round296: Average loss: 0.0391, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036745\n",
      "After training\n",
      "\n",
      "Test set in round297: Average loss: 0.0381, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031323\n",
      "After training\n",
      "\n",
      "Test set in round298: Average loss: 0.0376, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008656\n",
      "After training\n",
      "\n",
      "Test set in round299: Average loss: 0.0378, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028101\n",
      "After training\n",
      "\n",
      "Test set in round300: Average loss: 0.0398, Accuracy: 9873/10020 (98.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.061639\n",
      "After training\n",
      "\n",
      "Test set in round301: Average loss: 0.0396, Accuracy: 9867/10020 (98.47%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.009306\n",
      "After training\n",
      "\n",
      "Test set in round302: Average loss: 0.0371, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017697\n",
      "After training\n",
      "\n",
      "Test set in round303: Average loss: 0.0379, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024057\n",
      "After training\n",
      "\n",
      "Test set in round304: Average loss: 0.0395, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.090577\n",
      "After training\n",
      "\n",
      "Test set in round305: Average loss: 0.0389, Accuracy: 9873/10020 (98.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032210\n",
      "After training\n",
      "\n",
      "Test set in round306: Average loss: 0.0375, Accuracy: 9879/10020 (98.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036690\n",
      "After training\n",
      "\n",
      "Test set in round307: Average loss: 0.0370, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.086572\n",
      "After training\n",
      "\n",
      "Test set in round308: Average loss: 0.0386, Accuracy: 9867/10020 (98.47%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055226\n",
      "After training\n",
      "\n",
      "Test set in round309: Average loss: 0.0393, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.009052\n",
      "After training\n",
      "\n",
      "Test set in round310: Average loss: 0.0373, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039791\n",
      "After training\n",
      "\n",
      "Test set in round311: Average loss: 0.0370, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055121\n",
      "After training\n",
      "\n",
      "Test set in round312: Average loss: 0.0389, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.082066\n",
      "After training\n",
      "\n",
      "Test set in round313: Average loss: 0.0386, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027730\n",
      "After training\n",
      "\n",
      "Test set in round314: Average loss: 0.0363, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.079847\n",
      "After training\n",
      "\n",
      "Test set in round315: Average loss: 0.0382, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.040302\n",
      "After training\n",
      "\n",
      "Test set in round316: Average loss: 0.0353, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.075138\n",
      "After training\n",
      "\n",
      "Test set in round317: Average loss: 0.0378, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027551\n",
      "After training\n",
      "\n",
      "Test set in round318: Average loss: 0.0361, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015958\n",
      "After training\n",
      "\n",
      "Test set in round319: Average loss: 0.0362, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033375\n",
      "After training\n",
      "\n",
      "Test set in round320: Average loss: 0.0388, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027041\n",
      "After training\n",
      "\n",
      "Test set in round321: Average loss: 0.0392, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.013574\n",
      "After training\n",
      "\n",
      "Test set in round322: Average loss: 0.0365, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029519\n",
      "After training\n",
      "\n",
      "Test set in round323: Average loss: 0.0377, Accuracy: 9876/10020 (98.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.058013\n",
      "After training\n",
      "\n",
      "Test set in round324: Average loss: 0.0379, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029719\n",
      "After training\n",
      "\n",
      "Test set in round325: Average loss: 0.0385, Accuracy: 9864/10020 (98.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037331\n",
      "After training\n",
      "\n",
      "Test set in round326: Average loss: 0.0375, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.078959\n",
      "After training\n",
      "\n",
      "Test set in round327: Average loss: 0.0384, Accuracy: 9873/10020 (98.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.058444\n",
      "After training\n",
      "\n",
      "Test set in round328: Average loss: 0.0372, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030666\n",
      "After training\n",
      "\n",
      "Test set in round329: Average loss: 0.0375, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051083\n",
      "After training\n",
      "\n",
      "Test set in round330: Average loss: 0.0397, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030374\n",
      "After training\n",
      "\n",
      "Test set in round331: Average loss: 0.0376, Accuracy: 9876/10020 (98.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007724\n",
      "After training\n",
      "\n",
      "Test set in round332: Average loss: 0.0356, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.076405\n",
      "After training\n",
      "\n",
      "Test set in round334: Average loss: 0.0362, Accuracy: 9879/10020 (98.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.072379\n",
      "After training\n",
      "\n",
      "Test set in round335: Average loss: 0.0377, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049160\n",
      "After training\n",
      "\n",
      "Test set in round336: Average loss: 0.0387, Accuracy: 9876/10020 (98.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030437\n",
      "After training\n",
      "\n",
      "Test set in round337: Average loss: 0.0379, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041542\n",
      "After training\n",
      "\n",
      "Test set in round338: Average loss: 0.0363, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.073415\n",
      "After training\n",
      "\n",
      "Test set in round339: Average loss: 0.0371, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039085\n",
      "After training\n",
      "\n",
      "Test set in round340: Average loss: 0.0370, Accuracy: 9876/10020 (98.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024097\n",
      "After training\n",
      "\n",
      "Test set in round341: Average loss: 0.0382, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037159\n",
      "After training\n",
      "\n",
      "Test set in round342: Average loss: 0.0352, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020208\n",
      "After training\n",
      "\n",
      "Test set in round343: Average loss: 0.0374, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.011550\n",
      "After training\n",
      "\n",
      "Test set in round344: Average loss: 0.0370, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.073167\n",
      "After training\n",
      "\n",
      "Test set in round345: Average loss: 0.0380, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.068475\n",
      "After training\n",
      "\n",
      "Test set in round346: Average loss: 0.0367, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029373\n",
      "After training\n",
      "\n",
      "Test set in round347: Average loss: 0.0373, Accuracy: 9876/10020 (98.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023873\n",
      "After training\n",
      "\n",
      "Test set in round348: Average loss: 0.0363, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018441\n",
      "After training\n",
      "\n",
      "Test set in round349: Average loss: 0.0372, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.013788\n",
      "After training\n",
      "\n",
      "Test set in round350: Average loss: 0.0362, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030372\n",
      "After training\n",
      "\n",
      "Test set in round351: Average loss: 0.0368, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023982\n",
      "After training\n",
      "\n",
      "Test set in round352: Average loss: 0.0355, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025794\n",
      "After training\n",
      "\n",
      "Test set in round353: Average loss: 0.0357, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026756\n",
      "After training\n",
      "\n",
      "Test set in round354: Average loss: 0.0375, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039832\n",
      "After training\n",
      "\n",
      "Test set in round355: Average loss: 0.0369, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006633\n",
      "After training\n",
      "\n",
      "Test set in round356: Average loss: 0.0348, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030747\n",
      "After training\n",
      "\n",
      "Test set in round357: Average loss: 0.0348, Accuracy: 9879/10020 (98.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039266\n",
      "After training\n",
      "\n",
      "Test set in round358: Average loss: 0.0371, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021746\n",
      "After training\n",
      "\n",
      "Test set in round359: Average loss: 0.0364, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020735\n",
      "After training\n",
      "\n",
      "Test set in round360: Average loss: 0.0353, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047024\n",
      "After training\n",
      "\n",
      "Test set in round361: Average loss: 0.0341, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.070696\n",
      "After training\n",
      "\n",
      "Test set in round362: Average loss: 0.0375, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008018\n",
      "After training\n",
      "\n",
      "Test set in round363: Average loss: 0.0361, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031955\n",
      "After training\n",
      "\n",
      "Test set in round364: Average loss: 0.0344, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041257\n",
      "After training\n",
      "\n",
      "Test set in round365: Average loss: 0.0342, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.040076\n",
      "After training\n",
      "\n",
      "Test set in round366: Average loss: 0.0363, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031814\n",
      "After training\n",
      "\n",
      "Test set in round367: Average loss: 0.0346, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034377\n",
      "After training\n",
      "\n",
      "Test set in round368: Average loss: 0.0356, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019684\n",
      "After training\n",
      "\n",
      "Test set in round369: Average loss: 0.0353, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.054670\n",
      "After training\n",
      "\n",
      "Test set in round370: Average loss: 0.0369, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.072114\n",
      "After training\n",
      "\n",
      "Test set in round371: Average loss: 0.0345, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022919\n",
      "After training\n",
      "\n",
      "Test set in round372: Average loss: 0.0362, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022275\n",
      "After training\n",
      "\n",
      "Test set in round373: Average loss: 0.0350, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019192\n",
      "After training\n",
      "\n",
      "Test set in round374: Average loss: 0.0354, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.014878\n",
      "After training\n",
      "\n",
      "Test set in round375: Average loss: 0.0345, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028681\n",
      "After training\n",
      "\n",
      "Test set in round376: Average loss: 0.0332, Accuracy: 9903/10020 (98.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039706\n",
      "After training\n",
      "\n",
      "Test set in round377: Average loss: 0.0359, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.071538\n",
      "After training\n",
      "\n",
      "Test set in round378: Average loss: 0.0353, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026859\n",
      "After training\n",
      "\n",
      "Test set in round379: Average loss: 0.0351, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.070202\n",
      "After training\n",
      "\n",
      "Test set in round380: Average loss: 0.0349, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.065827\n",
      "After training\n",
      "\n",
      "Test set in round381: Average loss: 0.0345, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024932\n",
      "After training\n",
      "\n",
      "Test set in round382: Average loss: 0.0339, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037844\n",
      "After training\n",
      "\n",
      "Test set in round383: Average loss: 0.0342, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025751\n",
      "After training\n",
      "\n",
      "Test set in round384: Average loss: 0.0359, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.011299\n",
      "After training\n",
      "\n",
      "Test set in round385: Average loss: 0.0352, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039415\n",
      "After training\n",
      "\n",
      "Test set in round386: Average loss: 0.0328, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024211\n",
      "After training\n",
      "\n",
      "Test set in round387: Average loss: 0.0335, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006907\n",
      "After training\n",
      "\n",
      "Test set in round388: Average loss: 0.0367, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.058373\n",
      "After training\n",
      "\n",
      "Test set in round389: Average loss: 0.0346, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023493\n",
      "After training\n",
      "\n",
      "Test set in round390: Average loss: 0.0339, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029226\n",
      "After training\n",
      "\n",
      "Test set in round391: Average loss: 0.0352, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022336\n",
      "After training\n",
      "\n",
      "Test set in round392: Average loss: 0.0328, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019491\n",
      "After training\n",
      "\n",
      "Test set in round393: Average loss: 0.0357, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.066398\n",
      "After training\n",
      "\n",
      "Test set in round394: Average loss: 0.0345, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010624\n",
      "After training\n",
      "\n",
      "Test set in round395: Average loss: 0.0336, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.065393\n",
      "After training\n",
      "\n",
      "Test set in round396: Average loss: 0.0336, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034677\n",
      "After training\n",
      "\n",
      "Test set in round397: Average loss: 0.0320, Accuracy: 9903/10020 (98.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036131\n",
      "After training\n",
      "\n",
      "Test set in round398: Average loss: 0.0345, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039490\n",
      "After training\n",
      "\n",
      "Test set in round399: Average loss: 0.0325, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.009771\n",
      "After training\n",
      "\n",
      "Test set in round400: Average loss: 0.0340, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028549\n",
      "After training\n",
      "\n",
      "Test set in round401: Average loss: 0.0330, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032163\n",
      "After training\n",
      "\n",
      "Test set in round402: Average loss: 0.0324, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023257\n",
      "After training\n",
      "\n",
      "Test set in round403: Average loss: 0.0320, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032550\n",
      "After training\n",
      "\n",
      "Test set in round404: Average loss: 0.0346, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042101\n",
      "After training\n",
      "\n",
      "Test set in round405: Average loss: 0.0327, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033099\n",
      "After training\n",
      "\n",
      "Test set in round406: Average loss: 0.0329, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012259\n",
      "After training\n",
      "\n",
      "Test set in round407: Average loss: 0.0346, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008178\n",
      "After training\n",
      "\n",
      "Test set in round408: Average loss: 0.0336, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.067620\n",
      "After training\n",
      "\n",
      "Test set in round409: Average loss: 0.0326, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033553\n",
      "After training\n",
      "\n",
      "Test set in round410: Average loss: 0.0341, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023164\n",
      "After training\n",
      "\n",
      "Test set in round411: Average loss: 0.0330, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028734\n",
      "After training\n",
      "\n",
      "Test set in round412: Average loss: 0.0339, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.063107\n",
      "After training\n",
      "\n",
      "Test set in round413: Average loss: 0.0327, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006446\n",
      "After training\n",
      "\n",
      "Test set in round414: Average loss: 0.0318, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.060540\n",
      "After training\n",
      "\n",
      "Test set in round415: Average loss: 0.0339, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021926\n",
      "After training\n",
      "\n",
      "Test set in round416: Average loss: 0.0359, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034318\n",
      "After training\n",
      "\n",
      "Test set in round417: Average loss: 0.0324, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021643\n",
      "After training\n",
      "\n",
      "Test set in round418: Average loss: 0.0316, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021131\n",
      "After training\n",
      "\n",
      "Test set in round419: Average loss: 0.0357, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020578\n",
      "After training\n",
      "\n",
      "Test set in round420: Average loss: 0.0340, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.040529\n",
      "After training\n",
      "\n",
      "Test set in round421: Average loss: 0.0345, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032386\n",
      "After training\n",
      "\n",
      "Test set in round422: Average loss: 0.0331, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032937\n",
      "After training\n",
      "\n",
      "Test set in round423: Average loss: 0.0318, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025400\n",
      "After training\n",
      "\n",
      "Test set in round424: Average loss: 0.0318, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.061841\n",
      "After training\n",
      "\n",
      "Test set in round425: Average loss: 0.0341, Accuracy: 9879/10020 (98.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026780\n",
      "After training\n",
      "\n",
      "Test set in round426: Average loss: 0.0325, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.059377\n",
      "After training\n",
      "\n",
      "Test set in round427: Average loss: 0.0329, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029968\n",
      "After training\n",
      "\n",
      "Test set in round428: Average loss: 0.0312, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.011189\n",
      "After training\n",
      "\n",
      "Test set in round429: Average loss: 0.0321, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.054333\n",
      "After training\n",
      "\n",
      "Test set in round430: Average loss: 0.0336, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044404\n",
      "After training\n",
      "\n",
      "Test set in round431: Average loss: 0.0341, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.054104\n",
      "After training\n",
      "\n",
      "Test set in round432: Average loss: 0.0335, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018115\n",
      "After training\n",
      "\n",
      "Test set in round433: Average loss: 0.0331, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008584\n",
      "After training\n",
      "\n",
      "Test set in round434: Average loss: 0.0314, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025491\n",
      "After training\n",
      "\n",
      "Test set in round435: Average loss: 0.0311, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.045932\n",
      "After training\n",
      "\n",
      "Test set in round436: Average loss: 0.0339, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031049\n",
      "After training\n",
      "\n",
      "Test set in round437: Average loss: 0.0323, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.005640\n",
      "After training\n",
      "\n",
      "Test set in round438: Average loss: 0.0319, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037431\n",
      "After training\n",
      "\n",
      "Test set in round439: Average loss: 0.0315, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.057932\n",
      "After training\n",
      "\n",
      "Test set in round440: Average loss: 0.0317, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032751\n",
      "After training\n",
      "\n",
      "Test set in round441: Average loss: 0.0322, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007073\n",
      "After training\n",
      "\n",
      "Test set in round442: Average loss: 0.0350, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017034\n",
      "After training\n",
      "\n",
      "Test set in round443: Average loss: 0.0328, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022825\n",
      "After training\n",
      "\n",
      "Test set in round444: Average loss: 0.0350, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015627\n",
      "After training\n",
      "\n",
      "Test set in round445: Average loss: 0.0321, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027590\n",
      "After training\n",
      "\n",
      "Test set in round446: Average loss: 0.0348, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006927\n",
      "After training\n",
      "\n",
      "Test set in round447: Average loss: 0.0317, Accuracy: 9901/10020 (98.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026817\n",
      "After training\n",
      "\n",
      "Test set in round448: Average loss: 0.0329, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.058146\n",
      "After training\n",
      "\n",
      "Test set in round449: Average loss: 0.0325, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018144\n",
      "After training\n",
      "\n",
      "Test set in round450: Average loss: 0.0318, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018126\n",
      "After training\n",
      "\n",
      "Test set in round451: Average loss: 0.0321, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024580\n",
      "After training\n",
      "\n",
      "Test set in round452: Average loss: 0.0339, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007797\n",
      "After training\n",
      "\n",
      "Test set in round453: Average loss: 0.0324, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010901\n",
      "After training\n",
      "\n",
      "Test set in round454: Average loss: 0.0349, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007588\n",
      "After training\n",
      "\n",
      "Test set in round455: Average loss: 0.0331, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019976\n",
      "After training\n",
      "\n",
      "Test set in round456: Average loss: 0.0339, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024825\n",
      "After training\n",
      "\n",
      "Test set in round457: Average loss: 0.0318, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018801\n",
      "After training\n",
      "\n",
      "Test set in round458: Average loss: 0.0328, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025123\n",
      "After training\n",
      "\n",
      "Test set in round459: Average loss: 0.0336, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.057434\n",
      "After training\n",
      "\n",
      "Test set in round460: Average loss: 0.0326, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047604\n",
      "After training\n",
      "\n",
      "Test set in round461: Average loss: 0.0322, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039377\n",
      "After training\n",
      "\n",
      "Test set in round462: Average loss: 0.0339, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035092\n",
      "After training\n",
      "\n",
      "Test set in round463: Average loss: 0.0329, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010358\n",
      "After training\n",
      "\n",
      "Test set in round464: Average loss: 0.0314, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021942\n",
      "After training\n",
      "\n",
      "Test set in round465: Average loss: 0.0323, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.056291\n",
      "After training\n",
      "\n",
      "Test set in round466: Average loss: 0.0321, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015877\n",
      "After training\n",
      "\n",
      "Test set in round467: Average loss: 0.0326, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020110\n",
      "After training\n",
      "\n",
      "Test set in round468: Average loss: 0.0309, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053438\n",
      "After training\n",
      "\n",
      "Test set in round469: Average loss: 0.0311, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034254\n",
      "After training\n",
      "\n",
      "Test set in round470: Average loss: 0.0316, Accuracy: 9901/10020 (98.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017148\n",
      "After training\n",
      "\n",
      "Test set in round471: Average loss: 0.0317, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044274\n",
      "After training\n",
      "\n",
      "Test set in round472: Average loss: 0.0326, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036195\n",
      "After training\n",
      "\n",
      "Test set in round473: Average loss: 0.0338, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039109\n",
      "After training\n",
      "\n",
      "Test set in round474: Average loss: 0.0334, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019782\n",
      "After training\n",
      "\n",
      "Test set in round475: Average loss: 0.0297, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018475\n",
      "After training\n",
      "\n",
      "Test set in round476: Average loss: 0.0323, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024414\n",
      "After training\n",
      "\n",
      "Test set in round477: Average loss: 0.0314, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033683\n",
      "After training\n",
      "\n",
      "Test set in round478: Average loss: 0.0302, Accuracy: 9905/10020 (98.85%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007665\n",
      "After training\n",
      "\n",
      "Test set in round479: Average loss: 0.0336, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006565\n",
      "After training\n",
      "\n",
      "Test set in round480: Average loss: 0.0323, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028617\n",
      "After training\n",
      "\n",
      "Test set in round481: Average loss: 0.0305, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047264\n",
      "After training\n",
      "\n",
      "Test set in round482: Average loss: 0.0321, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034155\n",
      "After training\n",
      "\n",
      "Test set in round483: Average loss: 0.0316, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017590\n",
      "After training\n",
      "\n",
      "Test set in round484: Average loss: 0.0309, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020563\n",
      "After training\n",
      "\n",
      "Test set in round485: Average loss: 0.0325, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.005212\n",
      "After training\n",
      "\n",
      "Test set in round486: Average loss: 0.0318, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025326\n",
      "After training\n",
      "\n",
      "Test set in round487: Average loss: 0.0310, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006390\n",
      "After training\n",
      "\n",
      "Test set in round488: Average loss: 0.0325, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006232\n",
      "After training\n",
      "\n",
      "Test set in round489: Average loss: 0.0325, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008478\n",
      "After training\n",
      "\n",
      "Test set in round490: Average loss: 0.0319, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035378\n",
      "After training\n",
      "\n",
      "Test set in round491: Average loss: 0.0309, Accuracy: 9900/10020 (98.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039153\n",
      "After training\n",
      "\n",
      "Test set in round492: Average loss: 0.0337, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018312\n",
      "After training\n",
      "\n",
      "Test set in round493: Average loss: 0.0314, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008233\n",
      "After training\n",
      "\n",
      "Test set in round494: Average loss: 0.0321, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055413\n",
      "After training\n",
      "\n",
      "Test set in round495: Average loss: 0.0333, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018680\n",
      "After training\n",
      "\n",
      "Test set in round496: Average loss: 0.0340, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035989\n",
      "After training\n",
      "\n",
      "Test set in round497: Average loss: 0.0312, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018777\n",
      "After training\n",
      "\n",
      "Test set in round498: Average loss: 0.0319, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027541\n",
      "After training\n",
      "\n",
      "Test set in round499: Average loss: 0.0296, Accuracy: 9905/10020 (98.85%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008775\n",
      "After training\n",
      "\n",
      "Test set in round500: Average loss: 0.0308, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015656\n",
      "After training\n",
      "\n",
      "Test set in round501: Average loss: 0.0314, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006296\n",
      "After training\n",
      "\n",
      "Test set in round502: Average loss: 0.0323, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021961\n",
      "After training\n",
      "\n",
      "Test set in round503: Average loss: 0.0332, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025416\n",
      "After training\n",
      "\n",
      "Test set in round504: Average loss: 0.0300, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.057075\n",
      "After training\n",
      "\n",
      "Test set in round505: Average loss: 0.0314, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019430\n",
      "After training\n",
      "\n",
      "Test set in round506: Average loss: 0.0298, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018669\n",
      "After training\n",
      "\n",
      "Test set in round507: Average loss: 0.0309, Accuracy: 9901/10020 (98.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029073\n",
      "After training\n",
      "\n",
      "Test set in round508: Average loss: 0.0311, Accuracy: 9904/10020 (98.84%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025360\n",
      "After training\n",
      "\n",
      "Test set in round509: Average loss: 0.0319, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020719\n",
      "After training\n",
      "\n",
      "Test set in round510: Average loss: 0.0316, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025906\n",
      "After training\n",
      "\n",
      "Test set in round511: Average loss: 0.0294, Accuracy: 9907/10020 (98.87%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019374\n",
      "After training\n",
      "\n",
      "Test set in round512: Average loss: 0.0310, Accuracy: 9900/10020 (98.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.052140\n",
      "After training\n",
      "\n",
      "Test set in round513: Average loss: 0.0310, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020519\n",
      "After training\n",
      "\n",
      "Test set in round514: Average loss: 0.0342, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020263\n",
      "After training\n",
      "\n",
      "Test set in round515: Average loss: 0.0328, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007782\n",
      "After training\n",
      "\n",
      "Test set in round516: Average loss: 0.0302, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016633\n",
      "After training\n",
      "\n",
      "Test set in round517: Average loss: 0.0301, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032955\n",
      "After training\n",
      "\n",
      "Test set in round518: Average loss: 0.0292, Accuracy: 9904/10020 (98.84%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028059\n",
      "After training\n",
      "\n",
      "Test set in round519: Average loss: 0.0294, Accuracy: 9907/10020 (98.87%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020704\n",
      "After training\n",
      "\n",
      "Test set in round520: Average loss: 0.0324, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029113\n",
      "After training\n",
      "\n",
      "Test set in round521: Average loss: 0.0307, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015592\n",
      "After training\n",
      "\n",
      "Test set in round522: Average loss: 0.0327, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019509\n",
      "After training\n",
      "\n",
      "Test set in round523: Average loss: 0.0324, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.005421\n",
      "After training\n",
      "\n",
      "Test set in round524: Average loss: 0.0308, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.011949\n",
      "After training\n",
      "\n",
      "Test set in round525: Average loss: 0.0312, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.057943\n",
      "After training\n",
      "\n",
      "Test set in round526: Average loss: 0.0308, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.050856\n",
      "After training\n",
      "\n",
      "Test set in round527: Average loss: 0.0306, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026380\n",
      "After training\n",
      "\n",
      "Test set in round528: Average loss: 0.0322, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016278\n",
      "After training\n",
      "\n",
      "Test set in round529: Average loss: 0.0317, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015155\n",
      "After training\n",
      "\n",
      "Test set in round530: Average loss: 0.0311, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.005796\n",
      "After training\n",
      "\n",
      "Test set in round531: Average loss: 0.0299, Accuracy: 9905/10020 (98.85%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004892\n",
      "After training\n",
      "\n",
      "Test set in round532: Average loss: 0.0310, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015106\n",
      "After training\n",
      "\n",
      "Test set in round533: Average loss: 0.0300, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006893\n",
      "After training\n",
      "\n",
      "Test set in round534: Average loss: 0.0304, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.013965\n",
      "After training\n",
      "\n",
      "Test set in round535: Average loss: 0.0306, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.005008\n",
      "After training\n",
      "\n",
      "Test set in round536: Average loss: 0.0291, Accuracy: 9903/10020 (98.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019916\n",
      "After training\n",
      "\n",
      "Test set in round537: Average loss: 0.0301, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.014128\n",
      "After training\n",
      "\n",
      "Test set in round538: Average loss: 0.0310, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.013589\n",
      "After training\n",
      "\n",
      "Test set in round539: Average loss: 0.0306, Accuracy: 9901/10020 (98.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006381\n",
      "After training\n",
      "\n",
      "Test set in round540: Average loss: 0.0304, Accuracy: 9900/10020 (98.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004898\n",
      "After training\n",
      "\n",
      "Test set in round541: Average loss: 0.0297, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012946\n",
      "After training\n",
      "\n",
      "Test set in round542: Average loss: 0.0300, Accuracy: 9903/10020 (98.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053386\n",
      "After training\n",
      "\n",
      "Test set in round543: Average loss: 0.0305, Accuracy: 9901/10020 (98.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004516\n",
      "After training\n",
      "\n",
      "Test set in round544: Average loss: 0.0303, Accuracy: 9900/10020 (98.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018068\n",
      "After training\n",
      "\n",
      "Test set in round545: Average loss: 0.0320, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017581\n",
      "After training\n",
      "\n",
      "Test set in round546: Average loss: 0.0317, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006619\n",
      "After training\n",
      "\n",
      "Test set in round547: Average loss: 0.0296, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006045\n",
      "After training\n",
      "\n",
      "Test set in round548: Average loss: 0.0303, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.054676\n",
      "After training\n",
      "\n",
      "Test set in round549: Average loss: 0.0301, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023116\n",
      "After training\n",
      "\n",
      "Test set in round550: Average loss: 0.0291, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.013557\n",
      "After training\n",
      "\n",
      "Test set in round551: Average loss: 0.0303, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026027\n",
      "After training\n",
      "\n",
      "Test set in round552: Average loss: 0.0305, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027739\n",
      "After training\n",
      "\n",
      "Test set in round553: Average loss: 0.0301, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027763\n",
      "After training\n",
      "\n",
      "Test set in round554: Average loss: 0.0283, Accuracy: 9906/10020 (98.86%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016623\n",
      "After training\n",
      "\n",
      "Test set in round555: Average loss: 0.0290, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020067\n",
      "After training\n",
      "\n",
      "Test set in round556: Average loss: 0.0288, Accuracy: 9905/10020 (98.85%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012425\n",
      "After training\n",
      "\n",
      "Test set in round557: Average loss: 0.0288, Accuracy: 9901/10020 (98.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.013512\n",
      "After training\n",
      "\n",
      "Test set in round558: Average loss: 0.0298, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.011796\n",
      "After training\n",
      "\n",
      "Test set in round559: Average loss: 0.0313, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029042\n",
      "After training\n",
      "\n",
      "Test set in round560: Average loss: 0.0294, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030231\n",
      "After training\n",
      "\n",
      "Test set in round561: Average loss: 0.0305, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015209\n",
      "After training\n",
      "\n",
      "Test set in round562: Average loss: 0.0306, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.005140\n",
      "After training\n",
      "\n",
      "Test set in round563: Average loss: 0.0307, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007325\n",
      "After training\n",
      "\n",
      "Test set in round564: Average loss: 0.0301, Accuracy: 9900/10020 (98.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022563\n",
      "After training\n",
      "\n",
      "Test set in round565: Average loss: 0.0299, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053849\n",
      "After training\n",
      "\n",
      "Test set in round566: Average loss: 0.0299, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023481\n",
      "After training\n",
      "\n",
      "Test set in round567: Average loss: 0.0317, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004921\n",
      "After training\n",
      "\n",
      "Test set in round568: Average loss: 0.0290, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012775\n",
      "After training\n",
      "\n",
      "Test set in round569: Average loss: 0.0286, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.054070\n",
      "After training\n",
      "\n",
      "Test set in round570: Average loss: 0.0297, Accuracy: 9903/10020 (98.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018505\n",
      "After training\n",
      "\n",
      "Test set in round571: Average loss: 0.0311, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004177\n",
      "After training\n",
      "\n",
      "Test set in round572: Average loss: 0.0309, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015923\n",
      "After training\n",
      "\n",
      "Test set in round573: Average loss: 0.0298, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004089\n",
      "After training\n",
      "\n",
      "Test set in round574: Average loss: 0.0294, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017108\n",
      "After training\n",
      "\n",
      "Test set in round575: Average loss: 0.0314, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026716\n",
      "After training\n",
      "\n",
      "Test set in round576: Average loss: 0.0288, Accuracy: 9904/10020 (98.84%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020328\n",
      "After training\n",
      "\n",
      "Test set in round577: Average loss: 0.0288, Accuracy: 9903/10020 (98.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017383\n",
      "After training\n",
      "\n",
      "Test set in round578: Average loss: 0.0315, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010446\n",
      "After training\n",
      "\n",
      "Test set in round579: Average loss: 0.0294, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020390\n",
      "After training\n",
      "\n",
      "Test set in round580: Average loss: 0.0316, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027994\n",
      "After training\n",
      "\n",
      "Test set in round581: Average loss: 0.0306, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037349\n",
      "After training\n",
      "\n",
      "Test set in round582: Average loss: 0.0302, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028206\n",
      "After training\n",
      "\n",
      "Test set in round583: Average loss: 0.0283, Accuracy: 9910/10020 (98.90%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.013639\n",
      "After training\n",
      "\n",
      "Test set in round584: Average loss: 0.0315, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025335\n",
      "After training\n",
      "\n",
      "Test set in round585: Average loss: 0.0293, Accuracy: 9905/10020 (98.85%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022145\n",
      "After training\n",
      "\n",
      "Test set in round586: Average loss: 0.0293, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025738\n",
      "After training\n",
      "\n",
      "Test set in round587: Average loss: 0.0287, Accuracy: 9906/10020 (98.86%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029886\n",
      "After training\n",
      "\n",
      "Test set in round588: Average loss: 0.0302, Accuracy: 9903/10020 (98.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004574\n",
      "After training\n",
      "\n",
      "Test set in round589: Average loss: 0.0286, Accuracy: 9907/10020 (98.87%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022314\n",
      "After training\n",
      "\n",
      "Test set in round590: Average loss: 0.0292, Accuracy: 9908/10020 (98.88%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030254\n",
      "After training\n",
      "\n",
      "Test set in round591: Average loss: 0.0286, Accuracy: 9907/10020 (98.87%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012436\n",
      "After training\n",
      "\n",
      "Test set in round592: Average loss: 0.0299, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051939\n",
      "After training\n",
      "\n",
      "Test set in round593: Average loss: 0.0300, Accuracy: 9900/10020 (98.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024224\n",
      "After training\n",
      "\n",
      "Test set in round594: Average loss: 0.0313, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.014545\n",
      "After training\n",
      "\n",
      "Test set in round595: Average loss: 0.0298, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024031\n",
      "After training\n",
      "\n",
      "Test set in round596: Average loss: 0.0300, Accuracy: 9903/10020 (98.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018527\n",
      "After training\n",
      "\n",
      "Test set in round597: Average loss: 0.0305, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007168\n",
      "After training\n",
      "\n",
      "Test set in round598: Average loss: 0.0295, Accuracy: 9901/10020 (98.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017329\n",
      "After training\n",
      "\n",
      "Test set in round599: Average loss: 0.0293, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029409\n",
      "After training\n",
      "\n",
      "Test set in round600: Average loss: 0.0293, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017297\n",
      "After training\n",
      "\n",
      "Test set in round601: Average loss: 0.0296, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012051\n",
      "After training\n",
      "\n",
      "Test set in round602: Average loss: 0.0289, Accuracy: 9903/10020 (98.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.005640\n",
      "After training\n",
      "\n",
      "Test set in round603: Average loss: 0.0294, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030055\n",
      "After training\n",
      "\n",
      "Test set in round604: Average loss: 0.0320, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019414\n",
      "After training\n",
      "\n",
      "Test set in round605: Average loss: 0.0313, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016350\n",
      "After training\n",
      "\n",
      "Test set in round606: Average loss: 0.0295, Accuracy: 9901/10020 (98.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017523\n",
      "After training\n",
      "\n",
      "Test set in round607: Average loss: 0.0314, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021227\n",
      "After training\n",
      "\n",
      "Test set in round608: Average loss: 0.0295, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007165\n",
      "After training\n",
      "\n",
      "Test set in round609: Average loss: 0.0294, Accuracy: 9904/10020 (98.84%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012102\n",
      "After training\n",
      "\n",
      "Test set in round610: Average loss: 0.0289, Accuracy: 9905/10020 (98.85%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053116\n",
      "After training\n",
      "\n",
      "Test set in round611: Average loss: 0.0287, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.013267\n",
      "After training\n",
      "\n",
      "Test set in round612: Average loss: 0.0291, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015189\n",
      "After training\n",
      "\n",
      "Test set in round613: Average loss: 0.0296, Accuracy: 9901/10020 (98.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.005432\n",
      "After training\n",
      "\n",
      "Test set in round614: Average loss: 0.0308, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022238\n",
      "After training\n",
      "\n",
      "Test set in round615: Average loss: 0.0299, Accuracy: 9906/10020 (98.86%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010616\n",
      "After training\n",
      "\n",
      "Test set in round616: Average loss: 0.0299, Accuracy: 9909/10020 (98.89%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.005271\n",
      "After training\n",
      "\n",
      "Test set in round617: Average loss: 0.0285, Accuracy: 9908/10020 (98.88%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012374\n",
      "After training\n",
      "\n",
      "Test set in round618: Average loss: 0.0299, Accuracy: 9904/10020 (98.84%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019538\n",
      "After training\n",
      "\n",
      "Test set in round619: Average loss: 0.0295, Accuracy: 9907/10020 (98.87%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004364\n",
      "After training\n",
      "\n",
      "Test set in round620: Average loss: 0.0286, Accuracy: 9906/10020 (98.86%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015351\n",
      "After training\n",
      "\n",
      "Test set in round621: Average loss: 0.0297, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028793\n",
      "After training\n",
      "\n",
      "Test set in round622: Average loss: 0.0294, Accuracy: 9911/10020 (98.91%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004808\n",
      "After training\n",
      "\n",
      "Test set in round623: Average loss: 0.0288, Accuracy: 9903/10020 (98.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021705\n",
      "After training\n",
      "\n",
      "Test set in round624: Average loss: 0.0310, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017407\n",
      "After training\n",
      "\n",
      "Test set in round625: Average loss: 0.0286, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049733\n",
      "After training\n",
      "\n",
      "Test set in round626: Average loss: 0.0296, Accuracy: 9900/10020 (98.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017634\n",
      "After training\n",
      "\n",
      "Test set in round627: Average loss: 0.0277, Accuracy: 9910/10020 (98.90%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.011478\n",
      "After training\n",
      "\n",
      "Test set in round628: Average loss: 0.0287, Accuracy: 9904/10020 (98.84%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021622\n",
      "After training\n",
      "\n",
      "Test set in round629: Average loss: 0.0288, Accuracy: 9905/10020 (98.85%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046391\n",
      "After training\n",
      "\n",
      "Test set in round630: Average loss: 0.0293, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020158\n",
      "After training\n",
      "\n",
      "Test set in round631: Average loss: 0.0290, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015794\n",
      "After training\n",
      "\n",
      "Test set in round632: Average loss: 0.0291, Accuracy: 9900/10020 (98.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023342\n",
      "After training\n",
      "\n",
      "Test set in round633: Average loss: 0.0279, Accuracy: 9906/10020 (98.86%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.014538\n",
      "After training\n",
      "\n",
      "Test set in round634: Average loss: 0.0287, Accuracy: 9906/10020 (98.86%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.013713\n",
      "After training\n",
      "\n",
      "Test set in round635: Average loss: 0.0295, Accuracy: 9903/10020 (98.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.009692\n",
      "After training\n",
      "\n",
      "Test set in round636: Average loss: 0.0300, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004689\n",
      "After training\n",
      "\n",
      "Test set in round637: Average loss: 0.0296, Accuracy: 9900/10020 (98.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018745\n",
      "After training\n",
      "\n",
      "Test set in round638: Average loss: 0.0296, Accuracy: 9903/10020 (98.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025925\n",
      "After training\n",
      "\n",
      "Test set in round639: Average loss: 0.0290, Accuracy: 9905/10020 (98.85%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004565\n",
      "After training\n",
      "\n",
      "Test set in round640: Average loss: 0.0296, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.011049\n",
      "After training\n",
      "\n",
      "Test set in round641: Average loss: 0.0290, Accuracy: 9907/10020 (98.87%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016649\n",
      "After training\n",
      "\n",
      "Test set in round642: Average loss: 0.0292, Accuracy: 9901/10020 (98.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012245\n",
      "After training\n",
      "\n",
      "Test set in round643: Average loss: 0.0278, Accuracy: 9907/10020 (98.87%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.011738\n",
      "After training\n",
      "\n",
      "Test set in round644: Average loss: 0.0289, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020740\n",
      "After training\n",
      "\n",
      "Test set in round645: Average loss: 0.0290, Accuracy: 9903/10020 (98.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004379\n",
      "After training\n",
      "\n",
      "Test set in round646: Average loss: 0.0293, Accuracy: 9903/10020 (98.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018583\n",
      "After training\n",
      "\n",
      "Test set in round647: Average loss: 0.0290, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022709\n",
      "After training\n",
      "\n",
      "Test set in round648: Average loss: 0.0281, Accuracy: 9909/10020 (98.89%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004435\n",
      "After training\n",
      "\n",
      "Test set in round649: Average loss: 0.0280, Accuracy: 9903/10020 (98.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020275\n",
      "After training\n",
      "\n",
      "Test set in round650: Average loss: 0.0283, Accuracy: 9903/10020 (98.83%)\n",
      "\n",
      "CPU times: user 2h 45min 47s, sys: 8min 26s, total: 2h 54min 14s\n",
      "Wall time: 2h 53min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
    "logdir = '/root/notebooks/tensorflow/logs/30%DP_3/'\n",
    "writer = SummaryWriter(logdir)\n",
    "\n",
    "model_list = []\n",
    "model_list = model_init(workers, Net().to(device))\n",
    "opt_list = opt_init(model_list)\n",
    "# not finish in train, finish latter\n",
    "pars = [list(model.parameters()) for model in model_list]\n",
    "\n",
    "for r in range(1, args.rounds + 1):\n",
    "    train(args, device, train_loader, opt_list, workers)\n",
    "    print(\"After training\")\n",
    "    test(args, model_list[0], device, test_loader, r)\n",
    "\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
