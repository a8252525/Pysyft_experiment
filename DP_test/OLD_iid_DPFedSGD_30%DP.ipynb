{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "n_train_items = 6000\n",
    "rounds = 650\n",
    "total_client = 100\n",
    "C = 0.1\n",
    "n_workers = int(total_client * C)\n",
    "batch_size = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import syft as sy  # <-- NEW: import the Pysyft library\n",
    "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
    "# simulation functions\n",
    "def connect_to_workers(n_workers):\n",
    "    return [\n",
    "        sy.VirtualWorker(hook, id=f\"worker{i+1}\")\n",
    "        for i in range(n_workers)\n",
    "    ]\n",
    "\n",
    "\n",
    "workers = connect_to_workers(n_workers=n_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = batch_size\n",
    "        self.test_batch_size = 60\n",
    "        self.epochs = epochs\n",
    "        self.rounds = rounds\n",
    "        self.lr = 0.02\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 2\n",
    "        self.save_model = False\n",
    "        self.n_train_items = n_train_items\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
    "#     datasets.MNIST('../data', train=True, download=True,\n",
    "#                    transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),\n",
    "#                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                    ]))\n",
    "#     .federate(workers), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "#     batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),\n",
    "#                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                    ])),\n",
    "#     batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../data', train=True, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../data', train=False, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size\n",
    ")\n",
    "\n",
    "    \n",
    "#---\n",
    "\n",
    "# less_train_dataloader = [\n",
    "#         ((data), (target))\n",
    "#         for i, (data, target) in enumerate(train_loader)\n",
    "#         if i < (n_train_items / args.batch_size) * 10\n",
    "#     ]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "# print(len(less_train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy \n",
    "# #mnist_dataset.__getitem__(2)[1]\n",
    "# a = (mnist_dataset.__getitem__(0)[0]).numpy()\n",
    "# a.dtype = 'uint8'\n",
    "# print(a)\n",
    "# Image.fromarray(a[0], mode= 'P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*64, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(workers, Net):\n",
    "    model_list = list()\n",
    "    for worker in workers:\n",
    "        model_list.append(Net)\n",
    "    return model_list\n",
    "def opt_init(model_list):\n",
    "    opt_list = list()\n",
    "    for model  in model_list:\n",
    "        opt_list.append(optim.SGD(model.parameters(), lr=args.lr))\n",
    "    return opt_list\n",
    "def random_sample(train_dataloader):\n",
    "    choice_list = sorted(random.sample(range(100), 10))\n",
    "    count = 0\n",
    "    tmp = []\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        if  i == choice_list[count]:\n",
    "            tmp.append(data)\n",
    "            if count == 9:\n",
    "                pass\n",
    "            else:\n",
    "                count += 1\n",
    "    return tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, device, train_loader, opt_list, workers):\n",
    "    global model_list\n",
    "    ## start training and record the model into model_list\n",
    "    \n",
    "    less_train_dataloader = random_sample(train_loader)\n",
    "    for epoch in range(args.epochs):\n",
    "        for batch_idx, (data, target) in enumerate(less_train_dataloader): # <-- now it is a distributed dataset\n",
    "            model_on_worker = model_list[batch_idx%len(workers)]\n",
    "            model_on_worker.train()\n",
    "            model_on_worker.send(workers[batch_idx%len(workers)]) # <-- NEW: send the model to the right location\n",
    "\n",
    "            data_on_worker = data.send(workers[batch_idx%len(workers)])\n",
    "            target_on_worker = target.send(workers[batch_idx%len(workers)])\n",
    "\n",
    "            data_on_worker, target_on_worker = data_on_worker.to(device), target_on_worker.to(device)\n",
    "\n",
    "            opt_list[batch_idx%len(workers)].zero_grad()\n",
    "\n",
    "            output = model_on_worker(data_on_worker)\n",
    "            loss = F.nll_loss(output, target_on_worker)\n",
    "            loss.backward()\n",
    "\n",
    "            opt_list[batch_idx%len(workers)].step()\n",
    "            model_on_worker.get() # <-- NEW: get the model back\n",
    "\n",
    "            model_list[batch_idx%len(workers)] = model_on_worker #When len(dataloader) is longer than the len(worker) send and get must be modified\n",
    "            #model_list here is full of the model which has trained on the workers, there are all different now.\n",
    "\n",
    "        if epoch % args.log_interval == 0:\n",
    "            loss = loss.get() # <-- NEW: get the loss back\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, n_train_items, n_train_items ,\n",
    "                100. * epoch / args.epochs, loss.item()))\n",
    "\n",
    "\n",
    "    ##Aggregation time\n",
    "    new_model = []\n",
    "    tmp_model = Net().to(device)\n",
    "    with torch.no_grad():\n",
    "        for p in model_list[0].parameters():\n",
    "            new_model.append(0)\n",
    "            \n",
    "        for m in model_list:\n",
    "            for par_idx, par in enumerate(m.parameters()):\n",
    "                #average the model_list\n",
    "                new_model[par_idx] = new_model[par_idx]+par.data\n",
    "                # we get new model in list format and need to set_ to model\n",
    "        \n",
    "        for i in range(3):\n",
    "            for n in new_model:\n",
    "                n.add_(torch.normal(0,1.3*1.5,n.size(),device=device)*args.lr/args.batch_size)\n",
    "        \n",
    "        for worker in range(len(workers)):\n",
    "            for par_idx in range(len(new_model)):\n",
    "                list(model_list[worker].parameters())[par_idx].set_(new_model[par_idx]/len(workers))\n",
    "        #init model with new_model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader, r):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)*(args.test_batch_size)\n",
    "    accuracy = 100. * correct / (len(test_loader)*args.test_batch_size)\n",
    "    #Since the test loader here is a list, we can get the len by * it with batch.size\n",
    "    \n",
    "    \n",
    "    writer.add_scalar('Accuracy', accuracy,r)\n",
    "    writer.add_scalar('Loss', test_loss, r)\n",
    "    print('\\nTest set in round{}: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        r , test_loss, correct, len(test_loader)* (args.test_batch_size),\n",
    "        accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 2.199706\n",
      "After training\n",
      "\n",
      "Test set in round1: Average loss: 2.1855, Accuracy: 4770/10020 (47.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 2.032633\n",
      "After training\n",
      "\n",
      "Test set in round2: Average loss: 2.0029, Accuracy: 6785/10020 (67.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 1.719298\n",
      "After training\n",
      "\n",
      "Test set in round3: Average loss: 1.6631, Accuracy: 7678/10020 (76.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 1.197479\n",
      "After training\n",
      "\n",
      "Test set in round4: Average loss: 1.1929, Accuracy: 8256/10020 (82.40%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.835263\n",
      "After training\n",
      "\n",
      "Test set in round5: Average loss: 0.8442, Accuracy: 8227/10020 (82.11%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.594527\n",
      "After training\n",
      "\n",
      "Test set in round6: Average loss: 0.6743, Accuracy: 8301/10020 (82.84%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.497758\n",
      "After training\n",
      "\n",
      "Test set in round7: Average loss: 0.6276, Accuracy: 8109/10020 (80.93%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.511209\n",
      "After training\n",
      "\n",
      "Test set in round8: Average loss: 0.4869, Accuracy: 8715/10020 (86.98%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.427523\n",
      "After training\n",
      "\n",
      "Test set in round9: Average loss: 0.4512, Accuracy: 8805/10020 (87.87%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.283354\n",
      "After training\n",
      "\n",
      "Test set in round10: Average loss: 0.3991, Accuracy: 8895/10020 (88.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.354896\n",
      "After training\n",
      "\n",
      "Test set in round11: Average loss: 0.3722, Accuracy: 8978/10020 (89.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.341957\n",
      "After training\n",
      "\n",
      "Test set in round12: Average loss: 0.3471, Accuracy: 9038/10020 (90.20%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.332224\n",
      "After training\n",
      "\n",
      "Test set in round13: Average loss: 0.3346, Accuracy: 9059/10020 (90.41%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.392796\n",
      "After training\n",
      "\n",
      "Test set in round14: Average loss: 0.3783, Accuracy: 8874/10020 (88.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.349506\n",
      "After training\n",
      "\n",
      "Test set in round15: Average loss: 0.3112, Accuracy: 9120/10020 (91.02%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.341483\n",
      "After training\n",
      "\n",
      "Test set in round16: Average loss: 0.2857, Accuracy: 9212/10020 (91.94%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.263127\n",
      "After training\n",
      "\n",
      "Test set in round17: Average loss: 0.2796, Accuracy: 9212/10020 (91.94%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.301471\n",
      "After training\n",
      "\n",
      "Test set in round18: Average loss: 0.2781, Accuracy: 9194/10020 (91.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.138831\n",
      "After training\n",
      "\n",
      "Test set in round19: Average loss: 0.2609, Accuracy: 9256/10020 (92.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.137518\n",
      "After training\n",
      "\n",
      "Test set in round20: Average loss: 0.2535, Accuracy: 9258/10020 (92.40%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.295820\n",
      "After training\n",
      "\n",
      "Test set in round21: Average loss: 0.2545, Accuracy: 9261/10020 (92.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.238195\n",
      "After training\n",
      "\n",
      "Test set in round22: Average loss: 0.2520, Accuracy: 9286/10020 (92.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.296183\n",
      "After training\n",
      "\n",
      "Test set in round23: Average loss: 0.2519, Accuracy: 9221/10020 (92.03%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.114362\n",
      "After training\n",
      "\n",
      "Test set in round24: Average loss: 0.2276, Accuracy: 9337/10020 (93.18%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.188436\n",
      "After training\n",
      "\n",
      "Test set in round25: Average loss: 0.2168, Accuracy: 9378/10020 (93.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.124137\n",
      "After training\n",
      "\n",
      "Test set in round26: Average loss: 0.2090, Accuracy: 9398/10020 (93.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.180287\n",
      "After training\n",
      "\n",
      "Test set in round27: Average loss: 0.2040, Accuracy: 9401/10020 (93.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.223029\n",
      "After training\n",
      "\n",
      "Test set in round28: Average loss: 0.1973, Accuracy: 9443/10020 (94.24%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.221159\n",
      "After training\n",
      "\n",
      "Test set in round29: Average loss: 0.1948, Accuracy: 9445/10020 (94.26%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.196910\n",
      "After training\n",
      "\n",
      "Test set in round30: Average loss: 0.1931, Accuracy: 9475/10020 (94.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.216982\n",
      "After training\n",
      "\n",
      "Test set in round31: Average loss: 0.2071, Accuracy: 9386/10020 (93.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.162467\n",
      "After training\n",
      "\n",
      "Test set in round32: Average loss: 0.1855, Accuracy: 9457/10020 (94.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.199867\n",
      "After training\n",
      "\n",
      "Test set in round33: Average loss: 0.1857, Accuracy: 9457/10020 (94.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.246327\n",
      "After training\n",
      "\n",
      "Test set in round34: Average loss: 0.2039, Accuracy: 9386/10020 (93.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.158540\n",
      "After training\n",
      "\n",
      "Test set in round35: Average loss: 0.1748, Accuracy: 9492/10020 (94.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.078020\n",
      "After training\n",
      "\n",
      "Test set in round36: Average loss: 0.1707, Accuracy: 9522/10020 (95.03%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.197667\n",
      "After training\n",
      "\n",
      "Test set in round37: Average loss: 0.1884, Accuracy: 9443/10020 (94.24%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.163317\n",
      "After training\n",
      "\n",
      "Test set in round38: Average loss: 0.1659, Accuracy: 9518/10020 (94.99%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.189132\n",
      "After training\n",
      "\n",
      "Test set in round39: Average loss: 0.1646, Accuracy: 9536/10020 (95.17%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.173071\n",
      "After training\n",
      "\n",
      "Test set in round40: Average loss: 0.1572, Accuracy: 9539/10020 (95.20%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.194355\n",
      "After training\n",
      "\n",
      "Test set in round41: Average loss: 0.1594, Accuracy: 9539/10020 (95.20%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.193252\n",
      "After training\n",
      "\n",
      "Test set in round42: Average loss: 0.1523, Accuracy: 9559/10020 (95.40%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.147395\n",
      "After training\n",
      "\n",
      "Test set in round43: Average loss: 0.1451, Accuracy: 9588/10020 (95.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.103046\n",
      "After training\n",
      "\n",
      "Test set in round44: Average loss: 0.1424, Accuracy: 9589/10020 (95.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.134674\n",
      "After training\n",
      "\n",
      "Test set in round45: Average loss: 0.1504, Accuracy: 9586/10020 (95.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.144879\n",
      "After training\n",
      "\n",
      "Test set in round46: Average loss: 0.1495, Accuracy: 9574/10020 (95.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.134622\n",
      "After training\n",
      "\n",
      "Test set in round47: Average loss: 0.1432, Accuracy: 9602/10020 (95.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.083785\n",
      "After training\n",
      "\n",
      "Test set in round48: Average loss: 0.1334, Accuracy: 9613/10020 (95.94%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.078972\n",
      "After training\n",
      "\n",
      "Test set in round49: Average loss: 0.1326, Accuracy: 9614/10020 (95.95%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.134676\n",
      "After training\n",
      "\n",
      "Test set in round50: Average loss: 0.1315, Accuracy: 9618/10020 (95.99%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.073979\n",
      "After training\n",
      "\n",
      "Test set in round51: Average loss: 0.1284, Accuracy: 9629/10020 (96.10%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.159086\n",
      "After training\n",
      "\n",
      "Test set in round52: Average loss: 0.1304, Accuracy: 9613/10020 (95.94%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.122295\n",
      "After training\n",
      "\n",
      "Test set in round53: Average loss: 0.1230, Accuracy: 9643/10020 (96.24%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.176463\n",
      "After training\n",
      "\n",
      "Test set in round54: Average loss: 0.1304, Accuracy: 9606/10020 (95.87%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.106318\n",
      "After training\n",
      "\n",
      "Test set in round55: Average loss: 0.1242, Accuracy: 9659/10020 (96.40%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.072653\n",
      "After training\n",
      "\n",
      "Test set in round56: Average loss: 0.1202, Accuracy: 9644/10020 (96.25%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.160121\n",
      "After training\n",
      "\n",
      "Test set in round57: Average loss: 0.1231, Accuracy: 9634/10020 (96.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.115469\n",
      "After training\n",
      "\n",
      "Test set in round58: Average loss: 0.1169, Accuracy: 9672/10020 (96.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.155059\n",
      "After training\n",
      "\n",
      "Test set in round59: Average loss: 0.1188, Accuracy: 9645/10020 (96.26%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.133125\n",
      "After training\n",
      "\n",
      "Test set in round60: Average loss: 0.1160, Accuracy: 9672/10020 (96.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.151419\n",
      "After training\n",
      "\n",
      "Test set in round61: Average loss: 0.1160, Accuracy: 9650/10020 (96.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.043689\n",
      "After training\n",
      "\n",
      "Test set in round62: Average loss: 0.1117, Accuracy: 9678/10020 (96.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.137522\n",
      "After training\n",
      "\n",
      "Test set in round63: Average loss: 0.1084, Accuracy: 9692/10020 (96.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042033\n",
      "After training\n",
      "\n",
      "Test set in round64: Average loss: 0.1080, Accuracy: 9676/10020 (96.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.091844\n",
      "After training\n",
      "\n",
      "Test set in round65: Average loss: 0.1087, Accuracy: 9675/10020 (96.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.099683\n",
      "After training\n",
      "\n",
      "Test set in round66: Average loss: 0.1144, Accuracy: 9658/10020 (96.39%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.103233\n",
      "After training\n",
      "\n",
      "Test set in round67: Average loss: 0.1056, Accuracy: 9701/10020 (96.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.063393\n",
      "After training\n",
      "\n",
      "Test set in round68: Average loss: 0.1036, Accuracy: 9690/10020 (96.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.142103\n",
      "After training\n",
      "\n",
      "Test set in round69: Average loss: 0.1030, Accuracy: 9694/10020 (96.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.115892\n",
      "After training\n",
      "\n",
      "Test set in round70: Average loss: 0.1060, Accuracy: 9678/10020 (96.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.108948\n",
      "After training\n",
      "\n",
      "Test set in round71: Average loss: 0.1077, Accuracy: 9678/10020 (96.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.124052\n",
      "After training\n",
      "\n",
      "Test set in round72: Average loss: 0.0980, Accuracy: 9723/10020 (97.04%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.143461\n",
      "After training\n",
      "\n",
      "Test set in round73: Average loss: 0.1022, Accuracy: 9705/10020 (96.86%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.057972\n",
      "After training\n",
      "\n",
      "Test set in round74: Average loss: 0.0980, Accuracy: 9712/10020 (96.93%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.100444\n",
      "After training\n",
      "\n",
      "Test set in round75: Average loss: 0.0961, Accuracy: 9728/10020 (97.09%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035010\n",
      "After training\n",
      "\n",
      "Test set in round76: Average loss: 0.0970, Accuracy: 9708/10020 (96.89%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.103708\n",
      "After training\n",
      "\n",
      "Test set in round77: Average loss: 0.0938, Accuracy: 9721/10020 (97.02%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.082110\n",
      "After training\n",
      "\n",
      "Test set in round78: Average loss: 0.0935, Accuracy: 9720/10020 (97.01%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051936\n",
      "After training\n",
      "\n",
      "Test set in round79: Average loss: 0.0923, Accuracy: 9722/10020 (97.03%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.103336\n",
      "After training\n",
      "\n",
      "Test set in round80: Average loss: 0.0911, Accuracy: 9738/10020 (97.19%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.132683\n",
      "After training\n",
      "\n",
      "Test set in round81: Average loss: 0.0988, Accuracy: 9722/10020 (97.03%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.144429\n",
      "After training\n",
      "\n",
      "Test set in round82: Average loss: 0.0898, Accuracy: 9741/10020 (97.22%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.078421\n",
      "After training\n",
      "\n",
      "Test set in round83: Average loss: 0.0881, Accuracy: 9751/10020 (97.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.117411\n",
      "After training\n",
      "\n",
      "Test set in round84: Average loss: 0.0872, Accuracy: 9752/10020 (97.33%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.079162\n",
      "After training\n",
      "\n",
      "Test set in round85: Average loss: 0.0930, Accuracy: 9736/10020 (97.17%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.085997\n",
      "After training\n",
      "\n",
      "Test set in round86: Average loss: 0.0866, Accuracy: 9745/10020 (97.26%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.136551\n",
      "After training\n",
      "\n",
      "Test set in round87: Average loss: 0.0879, Accuracy: 9746/10020 (97.27%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.072373\n",
      "After training\n",
      "\n",
      "Test set in round88: Average loss: 0.0853, Accuracy: 9759/10020 (97.40%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.142555\n",
      "After training\n",
      "\n",
      "Test set in round89: Average loss: 0.0840, Accuracy: 9759/10020 (97.40%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.074918\n",
      "After training\n",
      "\n",
      "Test set in round90: Average loss: 0.0853, Accuracy: 9736/10020 (97.17%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.090087\n",
      "After training\n",
      "\n",
      "Test set in round91: Average loss: 0.0822, Accuracy: 9766/10020 (97.47%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.079534\n",
      "After training\n",
      "\n",
      "Test set in round92: Average loss: 0.0835, Accuracy: 9749/10020 (97.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.129255\n",
      "After training\n",
      "\n",
      "Test set in round93: Average loss: 0.0833, Accuracy: 9756/10020 (97.37%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.111649\n",
      "After training\n",
      "\n",
      "Test set in round94: Average loss: 0.0799, Accuracy: 9763/10020 (97.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.123208\n",
      "After training\n",
      "\n",
      "Test set in round95: Average loss: 0.0821, Accuracy: 9757/10020 (97.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046234\n",
      "After training\n",
      "\n",
      "Test set in round96: Average loss: 0.0823, Accuracy: 9759/10020 (97.40%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.133002\n",
      "After training\n",
      "\n",
      "Test set in round97: Average loss: 0.0817, Accuracy: 9754/10020 (97.35%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.065934\n",
      "After training\n",
      "\n",
      "Test set in round98: Average loss: 0.0832, Accuracy: 9750/10020 (97.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.091556\n",
      "After training\n",
      "\n",
      "Test set in round99: Average loss: 0.0778, Accuracy: 9762/10020 (97.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.072144\n",
      "After training\n",
      "\n",
      "Test set in round100: Average loss: 0.0774, Accuracy: 9762/10020 (97.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.069183\n",
      "After training\n",
      "\n",
      "Test set in round101: Average loss: 0.0760, Accuracy: 9772/10020 (97.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.075789\n",
      "After training\n",
      "\n",
      "Test set in round102: Average loss: 0.0745, Accuracy: 9777/10020 (97.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.072384\n",
      "After training\n",
      "\n",
      "Test set in round103: Average loss: 0.0755, Accuracy: 9773/10020 (97.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.078946\n",
      "After training\n",
      "\n",
      "Test set in round104: Average loss: 0.0760, Accuracy: 9760/10020 (97.41%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.116521\n",
      "After training\n",
      "\n",
      "Test set in round105: Average loss: 0.0842, Accuracy: 9735/10020 (97.16%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.100594\n",
      "After training\n",
      "\n",
      "Test set in round106: Average loss: 0.0741, Accuracy: 9785/10020 (97.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.084161\n",
      "After training\n",
      "\n",
      "Test set in round107: Average loss: 0.0754, Accuracy: 9765/10020 (97.46%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046686\n",
      "After training\n",
      "\n",
      "Test set in round108: Average loss: 0.0731, Accuracy: 9783/10020 (97.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.072233\n",
      "After training\n",
      "\n",
      "Test set in round109: Average loss: 0.0723, Accuracy: 9789/10020 (97.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.045721\n",
      "After training\n",
      "\n",
      "Test set in round110: Average loss: 0.0712, Accuracy: 9784/10020 (97.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.099958\n",
      "After training\n",
      "\n",
      "Test set in round111: Average loss: 0.0747, Accuracy: 9777/10020 (97.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.070592\n",
      "After training\n",
      "\n",
      "Test set in round112: Average loss: 0.0726, Accuracy: 9784/10020 (97.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023432\n",
      "After training\n",
      "\n",
      "Test set in round113: Average loss: 0.0722, Accuracy: 9769/10020 (97.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.074336\n",
      "After training\n",
      "\n",
      "Test set in round114: Average loss: 0.0711, Accuracy: 9790/10020 (97.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.082669\n",
      "After training\n",
      "\n",
      "Test set in round115: Average loss: 0.0707, Accuracy: 9783/10020 (97.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.119870\n",
      "After training\n",
      "\n",
      "Test set in round116: Average loss: 0.0713, Accuracy: 9775/10020 (97.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.119151\n",
      "After training\n",
      "\n",
      "Test set in round117: Average loss: 0.0693, Accuracy: 9788/10020 (97.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.079485\n",
      "After training\n",
      "\n",
      "Test set in round118: Average loss: 0.0693, Accuracy: 9807/10020 (97.87%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.064192\n",
      "After training\n",
      "\n",
      "Test set in round119: Average loss: 0.0709, Accuracy: 9788/10020 (97.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.059067\n",
      "After training\n",
      "\n",
      "Test set in round120: Average loss: 0.0687, Accuracy: 9799/10020 (97.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.069304\n",
      "After training\n",
      "\n",
      "Test set in round121: Average loss: 0.0688, Accuracy: 9780/10020 (97.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035771\n",
      "After training\n",
      "\n",
      "Test set in round122: Average loss: 0.0711, Accuracy: 9773/10020 (97.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.066213\n",
      "After training\n",
      "\n",
      "Test set in round123: Average loss: 0.0690, Accuracy: 9784/10020 (97.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.072356\n",
      "After training\n",
      "\n",
      "Test set in round124: Average loss: 0.0689, Accuracy: 9789/10020 (97.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.057135\n",
      "After training\n",
      "\n",
      "Test set in round125: Average loss: 0.0723, Accuracy: 9778/10020 (97.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.084486\n",
      "After training\n",
      "\n",
      "Test set in round126: Average loss: 0.0681, Accuracy: 9800/10020 (97.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.063904\n",
      "After training\n",
      "\n",
      "Test set in round127: Average loss: 0.0686, Accuracy: 9777/10020 (97.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.064994\n",
      "After training\n",
      "\n",
      "Test set in round128: Average loss: 0.0666, Accuracy: 9799/10020 (97.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.065390\n",
      "After training\n",
      "\n",
      "Test set in round129: Average loss: 0.0648, Accuracy: 9793/10020 (97.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055195\n",
      "After training\n",
      "\n",
      "Test set in round130: Average loss: 0.0644, Accuracy: 9802/10020 (97.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.090014\n",
      "After training\n",
      "\n",
      "Test set in round131: Average loss: 0.0670, Accuracy: 9799/10020 (97.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.087732\n",
      "After training\n",
      "\n",
      "Test set in round132: Average loss: 0.0630, Accuracy: 9812/10020 (97.92%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.073648\n",
      "After training\n",
      "\n",
      "Test set in round133: Average loss: 0.0640, Accuracy: 9799/10020 (97.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.058450\n",
      "After training\n",
      "\n",
      "Test set in round134: Average loss: 0.0640, Accuracy: 9804/10020 (97.84%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.079499\n",
      "After training\n",
      "\n",
      "Test set in round135: Average loss: 0.0629, Accuracy: 9816/10020 (97.96%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.076448\n",
      "After training\n",
      "\n",
      "Test set in round136: Average loss: 0.0642, Accuracy: 9795/10020 (97.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.063186\n",
      "After training\n",
      "\n",
      "Test set in round137: Average loss: 0.0634, Accuracy: 9803/10020 (97.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044379\n",
      "After training\n",
      "\n",
      "Test set in round138: Average loss: 0.0668, Accuracy: 9792/10020 (97.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.091671\n",
      "After training\n",
      "\n",
      "Test set in round139: Average loss: 0.0694, Accuracy: 9792/10020 (97.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031211\n",
      "After training\n",
      "\n",
      "Test set in round140: Average loss: 0.0633, Accuracy: 9801/10020 (97.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026175\n",
      "After training\n",
      "\n",
      "Test set in round141: Average loss: 0.0642, Accuracy: 9792/10020 (97.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.119155\n",
      "After training\n",
      "\n",
      "Test set in round142: Average loss: 0.0627, Accuracy: 9805/10020 (97.85%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.104901\n",
      "After training\n",
      "\n",
      "Test set in round143: Average loss: 0.0610, Accuracy: 9808/10020 (97.88%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053114\n",
      "After training\n",
      "\n",
      "Test set in round144: Average loss: 0.0601, Accuracy: 9811/10020 (97.91%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.063512\n",
      "After training\n",
      "\n",
      "Test set in round145: Average loss: 0.0599, Accuracy: 9807/10020 (97.87%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.068294\n",
      "After training\n",
      "\n",
      "Test set in round146: Average loss: 0.0596, Accuracy: 9819/10020 (97.99%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015963\n",
      "After training\n",
      "\n",
      "Test set in round147: Average loss: 0.0611, Accuracy: 9800/10020 (97.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.065726\n",
      "After training\n",
      "\n",
      "Test set in round148: Average loss: 0.0593, Accuracy: 9814/10020 (97.94%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.112562\n",
      "After training\n",
      "\n",
      "Test set in round149: Average loss: 0.0603, Accuracy: 9811/10020 (97.91%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025778\n",
      "After training\n",
      "\n",
      "Test set in round150: Average loss: 0.0606, Accuracy: 9804/10020 (97.84%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.054902\n",
      "After training\n",
      "\n",
      "Test set in round151: Average loss: 0.0621, Accuracy: 9812/10020 (97.92%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.112056\n",
      "After training\n",
      "\n",
      "Test set in round152: Average loss: 0.0574, Accuracy: 9823/10020 (98.03%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051743\n",
      "After training\n",
      "\n",
      "Test set in round153: Average loss: 0.0597, Accuracy: 9819/10020 (97.99%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.064297\n",
      "After training\n",
      "\n",
      "Test set in round154: Average loss: 0.0571, Accuracy: 9824/10020 (98.04%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.061026\n",
      "After training\n",
      "\n",
      "Test set in round155: Average loss: 0.0589, Accuracy: 9816/10020 (97.96%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.066807\n",
      "After training\n",
      "\n",
      "Test set in round156: Average loss: 0.0596, Accuracy: 9817/10020 (97.97%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030357\n",
      "After training\n",
      "\n",
      "Test set in round157: Average loss: 0.0588, Accuracy: 9812/10020 (97.92%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049843\n",
      "After training\n",
      "\n",
      "Test set in round158: Average loss: 0.0552, Accuracy: 9824/10020 (98.04%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049211\n",
      "After training\n",
      "\n",
      "Test set in round159: Average loss: 0.0553, Accuracy: 9834/10020 (98.14%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.081941\n",
      "After training\n",
      "\n",
      "Test set in round160: Average loss: 0.0596, Accuracy: 9811/10020 (97.91%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.064769\n",
      "After training\n",
      "\n",
      "Test set in round161: Average loss: 0.0565, Accuracy: 9827/10020 (98.07%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049972\n",
      "After training\n",
      "\n",
      "Test set in round162: Average loss: 0.0587, Accuracy: 9820/10020 (98.00%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.045156\n",
      "After training\n",
      "\n",
      "Test set in round163: Average loss: 0.0553, Accuracy: 9830/10020 (98.10%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.060686\n",
      "After training\n",
      "\n",
      "Test set in round164: Average loss: 0.0549, Accuracy: 9826/10020 (98.06%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.101824\n",
      "After training\n",
      "\n",
      "Test set in round165: Average loss: 0.0551, Accuracy: 9821/10020 (98.01%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.070942\n",
      "After training\n",
      "\n",
      "Test set in round166: Average loss: 0.0548, Accuracy: 9824/10020 (98.04%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055805\n",
      "After training\n",
      "\n",
      "Test set in round167: Average loss: 0.0562, Accuracy: 9827/10020 (98.07%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.063394\n",
      "After training\n",
      "\n",
      "Test set in round168: Average loss: 0.0583, Accuracy: 9817/10020 (97.97%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.058011\n",
      "After training\n",
      "\n",
      "Test set in round169: Average loss: 0.0572, Accuracy: 9816/10020 (97.96%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.054280\n",
      "After training\n",
      "\n",
      "Test set in round170: Average loss: 0.0540, Accuracy: 9824/10020 (98.04%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.062305\n",
      "After training\n",
      "\n",
      "Test set in round171: Average loss: 0.0549, Accuracy: 9828/10020 (98.08%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.117817\n",
      "After training\n",
      "\n",
      "Test set in round172: Average loss: 0.0556, Accuracy: 9827/10020 (98.07%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053636\n",
      "After training\n",
      "\n",
      "Test set in round173: Average loss: 0.0523, Accuracy: 9835/10020 (98.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.045878\n",
      "After training\n",
      "\n",
      "Test set in round174: Average loss: 0.0563, Accuracy: 9824/10020 (98.04%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.048220\n",
      "After training\n",
      "\n",
      "Test set in round175: Average loss: 0.0539, Accuracy: 9829/10020 (98.09%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.101149\n",
      "After training\n",
      "\n",
      "Test set in round176: Average loss: 0.0560, Accuracy: 9824/10020 (98.04%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.057565\n",
      "After training\n",
      "\n",
      "Test set in round177: Average loss: 0.0529, Accuracy: 9834/10020 (98.14%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053220\n",
      "After training\n",
      "\n",
      "Test set in round178: Average loss: 0.0514, Accuracy: 9838/10020 (98.18%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055989\n",
      "After training\n",
      "\n",
      "Test set in round179: Average loss: 0.0516, Accuracy: 9839/10020 (98.19%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025159\n",
      "After training\n",
      "\n",
      "Test set in round180: Average loss: 0.0537, Accuracy: 9825/10020 (98.05%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039262\n",
      "After training\n",
      "\n",
      "Test set in round181: Average loss: 0.0534, Accuracy: 9837/10020 (98.17%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.073087\n",
      "After training\n",
      "\n",
      "Test set in round182: Average loss: 0.0526, Accuracy: 9838/10020 (98.18%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.102682\n",
      "After training\n",
      "\n",
      "Test set in round183: Average loss: 0.0525, Accuracy: 9833/10020 (98.13%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051155\n",
      "After training\n",
      "\n",
      "Test set in round184: Average loss: 0.0505, Accuracy: 9842/10020 (98.22%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024778\n",
      "After training\n",
      "\n",
      "Test set in round185: Average loss: 0.0547, Accuracy: 9824/10020 (98.04%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.052375\n",
      "After training\n",
      "\n",
      "Test set in round186: Average loss: 0.0508, Accuracy: 9838/10020 (98.18%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.097524\n",
      "After training\n",
      "\n",
      "Test set in round187: Average loss: 0.0531, Accuracy: 9830/10020 (98.10%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047270\n",
      "After training\n",
      "\n",
      "Test set in round188: Average loss: 0.0510, Accuracy: 9844/10020 (98.24%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.057758\n",
      "After training\n",
      "\n",
      "Test set in round189: Average loss: 0.0529, Accuracy: 9832/10020 (98.12%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046952\n",
      "After training\n",
      "\n",
      "Test set in round190: Average loss: 0.0514, Accuracy: 9839/10020 (98.19%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.056334\n",
      "After training\n",
      "\n",
      "Test set in round191: Average loss: 0.0491, Accuracy: 9846/10020 (98.26%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032766\n",
      "After training\n",
      "\n",
      "Test set in round192: Average loss: 0.0507, Accuracy: 9850/10020 (98.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017349\n",
      "After training\n",
      "\n",
      "Test set in round193: Average loss: 0.0521, Accuracy: 9835/10020 (98.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.064145\n",
      "After training\n",
      "\n",
      "Test set in round194: Average loss: 0.0508, Accuracy: 9841/10020 (98.21%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.050968\n",
      "After training\n",
      "\n",
      "Test set in round195: Average loss: 0.0497, Accuracy: 9837/10020 (98.17%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.102535\n",
      "After training\n",
      "\n",
      "Test set in round196: Average loss: 0.0500, Accuracy: 9845/10020 (98.25%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.075640\n",
      "After training\n",
      "\n",
      "Test set in round197: Average loss: 0.0540, Accuracy: 9840/10020 (98.20%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.013935\n",
      "After training\n",
      "\n",
      "Test set in round198: Average loss: 0.0487, Accuracy: 9848/10020 (98.28%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.094615\n",
      "After training\n",
      "\n",
      "Test set in round199: Average loss: 0.0506, Accuracy: 9835/10020 (98.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036884\n",
      "After training\n",
      "\n",
      "Test set in round200: Average loss: 0.0500, Accuracy: 9846/10020 (98.26%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.052448\n",
      "After training\n",
      "\n",
      "Test set in round201: Average loss: 0.0485, Accuracy: 9848/10020 (98.28%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018965\n",
      "After training\n",
      "\n",
      "Test set in round202: Average loss: 0.0510, Accuracy: 9840/10020 (98.20%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.054090\n",
      "After training\n",
      "\n",
      "Test set in round203: Average loss: 0.0512, Accuracy: 9840/10020 (98.20%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.093858\n",
      "After training\n",
      "\n",
      "Test set in round204: Average loss: 0.0496, Accuracy: 9840/10020 (98.20%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051986\n",
      "After training\n",
      "\n",
      "Test set in round205: Average loss: 0.0495, Accuracy: 9842/10020 (98.22%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041975\n",
      "After training\n",
      "\n",
      "Test set in round206: Average loss: 0.0489, Accuracy: 9845/10020 (98.25%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055549\n",
      "After training\n",
      "\n",
      "Test set in round207: Average loss: 0.0487, Accuracy: 9839/10020 (98.19%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041704\n",
      "After training\n",
      "\n",
      "Test set in round208: Average loss: 0.0475, Accuracy: 9845/10020 (98.25%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053157\n",
      "After training\n",
      "\n",
      "Test set in round209: Average loss: 0.0481, Accuracy: 9850/10020 (98.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049616\n",
      "After training\n",
      "\n",
      "Test set in round210: Average loss: 0.0473, Accuracy: 9851/10020 (98.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.058548\n",
      "After training\n",
      "\n",
      "Test set in round211: Average loss: 0.0483, Accuracy: 9848/10020 (98.28%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.064122\n",
      "After training\n",
      "\n",
      "Test set in round212: Average loss: 0.0510, Accuracy: 9848/10020 (98.28%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047483\n",
      "After training\n",
      "\n",
      "Test set in round213: Average loss: 0.0487, Accuracy: 9847/10020 (98.27%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044081\n",
      "After training\n",
      "\n",
      "Test set in round214: Average loss: 0.0477, Accuracy: 9850/10020 (98.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039063\n",
      "After training\n",
      "\n",
      "Test set in round215: Average loss: 0.0479, Accuracy: 9852/10020 (98.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.052252\n",
      "After training\n",
      "\n",
      "Test set in round216: Average loss: 0.0464, Accuracy: 9847/10020 (98.27%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022762\n",
      "After training\n",
      "\n",
      "Test set in round217: Average loss: 0.0474, Accuracy: 9849/10020 (98.29%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038613\n",
      "After training\n",
      "\n",
      "Test set in round218: Average loss: 0.0471, Accuracy: 9852/10020 (98.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018570\n",
      "After training\n",
      "\n",
      "Test set in round219: Average loss: 0.0484, Accuracy: 9844/10020 (98.24%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.095771\n",
      "After training\n",
      "\n",
      "Test set in round220: Average loss: 0.0483, Accuracy: 9839/10020 (98.19%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046019\n",
      "After training\n",
      "\n",
      "Test set in round221: Average loss: 0.0460, Accuracy: 9857/10020 (98.37%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033041\n",
      "After training\n",
      "\n",
      "Test set in round222: Average loss: 0.0494, Accuracy: 9847/10020 (98.27%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053453\n",
      "After training\n",
      "\n",
      "Test set in round223: Average loss: 0.0481, Accuracy: 9846/10020 (98.26%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028040\n",
      "After training\n",
      "\n",
      "Test set in round224: Average loss: 0.0469, Accuracy: 9856/10020 (98.36%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.040303\n",
      "After training\n",
      "\n",
      "Test set in round225: Average loss: 0.0480, Accuracy: 9848/10020 (98.28%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021003\n",
      "After training\n",
      "\n",
      "Test set in round226: Average loss: 0.0463, Accuracy: 9845/10020 (98.25%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.040352\n",
      "After training\n",
      "\n",
      "Test set in round227: Average loss: 0.0455, Accuracy: 9854/10020 (98.34%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037409\n",
      "After training\n",
      "\n",
      "Test set in round228: Average loss: 0.0471, Accuracy: 9855/10020 (98.35%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035203\n",
      "After training\n",
      "\n",
      "Test set in round229: Average loss: 0.0456, Accuracy: 9853/10020 (98.33%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019687\n",
      "After training\n",
      "\n",
      "Test set in round230: Average loss: 0.0466, Accuracy: 9847/10020 (98.27%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.040324\n",
      "After training\n",
      "\n",
      "Test set in round231: Average loss: 0.0468, Accuracy: 9850/10020 (98.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012361\n",
      "After training\n",
      "\n",
      "Test set in round232: Average loss: 0.0448, Accuracy: 9851/10020 (98.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028892\n",
      "After training\n",
      "\n",
      "Test set in round233: Average loss: 0.0484, Accuracy: 9851/10020 (98.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.048544\n",
      "After training\n",
      "\n",
      "Test set in round234: Average loss: 0.0451, Accuracy: 9856/10020 (98.36%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.078545\n",
      "After training\n",
      "\n",
      "Test set in round235: Average loss: 0.0453, Accuracy: 9852/10020 (98.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049261\n",
      "After training\n",
      "\n",
      "Test set in round236: Average loss: 0.0463, Accuracy: 9857/10020 (98.37%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018325\n",
      "After training\n",
      "\n",
      "Test set in round237: Average loss: 0.0464, Accuracy: 9850/10020 (98.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.064761\n",
      "After training\n",
      "\n",
      "Test set in round238: Average loss: 0.0505, Accuracy: 9831/10020 (98.11%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012936\n",
      "After training\n",
      "\n",
      "Test set in round239: Average loss: 0.0429, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031492\n",
      "After training\n",
      "\n",
      "Test set in round240: Average loss: 0.0458, Accuracy: 9859/10020 (98.39%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042627\n",
      "After training\n",
      "\n",
      "Test set in round241: Average loss: 0.0433, Accuracy: 9864/10020 (98.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046375\n",
      "After training\n",
      "\n",
      "Test set in round242: Average loss: 0.0457, Accuracy: 9852/10020 (98.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044167\n",
      "After training\n",
      "\n",
      "Test set in round243: Average loss: 0.0434, Accuracy: 9867/10020 (98.47%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039762\n",
      "After training\n",
      "\n",
      "Test set in round244: Average loss: 0.0443, Accuracy: 9857/10020 (98.37%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.040476\n",
      "After training\n",
      "\n",
      "Test set in round245: Average loss: 0.0443, Accuracy: 9859/10020 (98.39%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.091849\n",
      "After training\n",
      "\n",
      "Test set in round246: Average loss: 0.0471, Accuracy: 9849/10020 (98.29%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.089405\n",
      "After training\n",
      "\n",
      "Test set in round247: Average loss: 0.0436, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.059075\n",
      "After training\n",
      "\n",
      "Test set in round248: Average loss: 0.0544, Accuracy: 9817/10020 (97.97%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.089634\n",
      "After training\n",
      "\n",
      "Test set in round249: Average loss: 0.0463, Accuracy: 9848/10020 (98.28%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.048344\n",
      "After training\n",
      "\n",
      "Test set in round250: Average loss: 0.0444, Accuracy: 9857/10020 (98.37%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044645\n",
      "After training\n",
      "\n",
      "Test set in round251: Average loss: 0.0430, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016795\n",
      "After training\n",
      "\n",
      "Test set in round252: Average loss: 0.0456, Accuracy: 9852/10020 (98.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.081377\n",
      "After training\n",
      "\n",
      "Test set in round253: Average loss: 0.0453, Accuracy: 9851/10020 (98.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041977\n",
      "After training\n",
      "\n",
      "Test set in round254: Average loss: 0.0425, Accuracy: 9855/10020 (98.35%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017315\n",
      "After training\n",
      "\n",
      "Test set in round255: Average loss: 0.0438, Accuracy: 9855/10020 (98.35%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028391\n",
      "After training\n",
      "\n",
      "Test set in round256: Average loss: 0.0445, Accuracy: 9852/10020 (98.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010960\n",
      "After training\n",
      "\n",
      "Test set in round257: Average loss: 0.0427, Accuracy: 9866/10020 (98.46%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038947\n",
      "After training\n",
      "\n",
      "Test set in round258: Average loss: 0.0428, Accuracy: 9858/10020 (98.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038418\n",
      "After training\n",
      "\n",
      "Test set in round259: Average loss: 0.0474, Accuracy: 9842/10020 (98.22%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037615\n",
      "After training\n",
      "\n",
      "Test set in round260: Average loss: 0.0434, Accuracy: 9857/10020 (98.37%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044151\n",
      "After training\n",
      "\n",
      "Test set in round261: Average loss: 0.0434, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055681\n",
      "After training\n",
      "\n",
      "Test set in round262: Average loss: 0.0463, Accuracy: 9852/10020 (98.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025994\n",
      "After training\n",
      "\n",
      "Test set in round263: Average loss: 0.0451, Accuracy: 9857/10020 (98.37%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039595\n",
      "After training\n",
      "\n",
      "Test set in round264: Average loss: 0.0408, Accuracy: 9865/10020 (98.45%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031587\n",
      "After training\n",
      "\n",
      "Test set in round265: Average loss: 0.0433, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047672\n",
      "After training\n",
      "\n",
      "Test set in round266: Average loss: 0.0416, Accuracy: 9867/10020 (98.47%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049005\n",
      "After training\n",
      "\n",
      "Test set in round267: Average loss: 0.0438, Accuracy: 9859/10020 (98.39%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008162\n",
      "After training\n",
      "\n",
      "Test set in round268: Average loss: 0.0422, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042762\n",
      "After training\n",
      "\n",
      "Test set in round269: Average loss: 0.0443, Accuracy: 9851/10020 (98.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.072775\n",
      "After training\n",
      "\n",
      "Test set in round270: Average loss: 0.0424, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.086090\n",
      "After training\n",
      "\n",
      "Test set in round271: Average loss: 0.0433, Accuracy: 9851/10020 (98.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.011214\n",
      "After training\n",
      "\n",
      "Test set in round272: Average loss: 0.0413, Accuracy: 9866/10020 (98.46%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.083517\n",
      "After training\n",
      "\n",
      "Test set in round273: Average loss: 0.0415, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.045484\n",
      "After training\n",
      "\n",
      "Test set in round274: Average loss: 0.0411, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.079117\n",
      "After training\n",
      "\n",
      "Test set in round275: Average loss: 0.0432, Accuracy: 9852/10020 (98.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041545\n",
      "After training\n",
      "\n",
      "Test set in round276: Average loss: 0.0418, Accuracy: 9870/10020 (98.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038484\n",
      "After training\n",
      "\n",
      "Test set in round277: Average loss: 0.0424, Accuracy: 9856/10020 (98.36%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044280\n",
      "After training\n",
      "\n",
      "Test set in round278: Average loss: 0.0411, Accuracy: 9865/10020 (98.45%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042806\n",
      "After training\n",
      "\n",
      "Test set in round279: Average loss: 0.0404, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023290\n",
      "After training\n",
      "\n",
      "Test set in round280: Average loss: 0.0421, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053860\n",
      "After training\n",
      "\n",
      "Test set in round281: Average loss: 0.0447, Accuracy: 9858/10020 (98.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.048740\n",
      "After training\n",
      "\n",
      "Test set in round282: Average loss: 0.0404, Accuracy: 9865/10020 (98.45%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.079953\n",
      "After training\n",
      "\n",
      "Test set in round283: Average loss: 0.0433, Accuracy: 9851/10020 (98.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.043119\n",
      "After training\n",
      "\n",
      "Test set in round284: Average loss: 0.0413, Accuracy: 9867/10020 (98.47%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031670\n",
      "After training\n",
      "\n",
      "Test set in round285: Average loss: 0.0415, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008938\n",
      "After training\n",
      "\n",
      "Test set in round286: Average loss: 0.0402, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041436\n",
      "After training\n",
      "\n",
      "Test set in round287: Average loss: 0.0398, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.056369\n",
      "After training\n",
      "\n",
      "Test set in round288: Average loss: 0.0413, Accuracy: 9865/10020 (98.45%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.076682\n",
      "After training\n",
      "\n",
      "Test set in round289: Average loss: 0.0421, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.054234\n",
      "After training\n",
      "\n",
      "Test set in round290: Average loss: 0.0407, Accuracy: 9866/10020 (98.46%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031870\n",
      "After training\n",
      "\n",
      "Test set in round291: Average loss: 0.0411, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.071755\n",
      "After training\n",
      "\n",
      "Test set in round292: Average loss: 0.0406, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042801\n",
      "After training\n",
      "\n",
      "Test set in round293: Average loss: 0.0392, Accuracy: 9865/10020 (98.45%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.040996\n",
      "After training\n",
      "\n",
      "Test set in round294: Average loss: 0.0404, Accuracy: 9873/10020 (98.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.045707\n",
      "After training\n",
      "\n",
      "Test set in round295: Average loss: 0.0415, Accuracy: 9867/10020 (98.47%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046955\n",
      "After training\n",
      "\n",
      "Test set in round296: Average loss: 0.0468, Accuracy: 9844/10020 (98.24%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036996\n",
      "After training\n",
      "\n",
      "Test set in round297: Average loss: 0.0386, Accuracy: 9873/10020 (98.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044519\n",
      "After training\n",
      "\n",
      "Test set in round298: Average loss: 0.0420, Accuracy: 9860/10020 (98.40%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047261\n",
      "After training\n",
      "\n",
      "Test set in round299: Average loss: 0.0423, Accuracy: 9856/10020 (98.36%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017169\n",
      "After training\n",
      "\n",
      "Test set in round300: Average loss: 0.0409, Accuracy: 9866/10020 (98.46%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033428\n",
      "After training\n",
      "\n",
      "Test set in round301: Average loss: 0.0393, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.075793\n",
      "After training\n",
      "\n",
      "Test set in round302: Average loss: 0.0411, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.069135\n",
      "After training\n",
      "\n",
      "Test set in round303: Average loss: 0.0406, Accuracy: 9864/10020 (98.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038361\n",
      "After training\n",
      "\n",
      "Test set in round304: Average loss: 0.0409, Accuracy: 9866/10020 (98.46%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.069862\n",
      "After training\n",
      "\n",
      "Test set in round305: Average loss: 0.0411, Accuracy: 9859/10020 (98.39%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051151\n",
      "After training\n",
      "\n",
      "Test set in round306: Average loss: 0.0409, Accuracy: 9867/10020 (98.47%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.068902\n",
      "After training\n",
      "\n",
      "Test set in round307: Average loss: 0.0396, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026482\n",
      "After training\n",
      "\n",
      "Test set in round308: Average loss: 0.0404, Accuracy: 9866/10020 (98.46%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049053\n",
      "After training\n",
      "\n",
      "Test set in round309: Average loss: 0.0424, Accuracy: 9867/10020 (98.47%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.067396\n",
      "After training\n",
      "\n",
      "Test set in round310: Average loss: 0.0397, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036462\n",
      "After training\n",
      "\n",
      "Test set in round311: Average loss: 0.0390, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038768\n",
      "After training\n",
      "\n",
      "Test set in round312: Average loss: 0.0383, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042055\n",
      "After training\n",
      "\n",
      "Test set in round313: Average loss: 0.0386, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022877\n",
      "After training\n",
      "\n",
      "Test set in round314: Average loss: 0.0407, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037347\n",
      "After training\n",
      "\n",
      "Test set in round315: Average loss: 0.0379, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.065111\n",
      "After training\n",
      "\n",
      "Test set in round316: Average loss: 0.0388, Accuracy: 9879/10020 (98.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.061609\n",
      "After training\n",
      "\n",
      "Test set in round317: Average loss: 0.0398, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015283\n",
      "After training\n",
      "\n",
      "Test set in round318: Average loss: 0.0418, Accuracy: 9861/10020 (98.41%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016553\n",
      "After training\n",
      "\n",
      "Test set in round319: Average loss: 0.0402, Accuracy: 9870/10020 (98.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027128\n",
      "After training\n",
      "\n",
      "Test set in round320: Average loss: 0.0386, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017839\n",
      "After training\n",
      "\n",
      "Test set in round321: Average loss: 0.0377, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008103\n",
      "After training\n",
      "\n",
      "Test set in round322: Average loss: 0.0379, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046176\n",
      "After training\n",
      "\n",
      "Test set in round323: Average loss: 0.0445, Accuracy: 9848/10020 (98.28%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037499\n",
      "After training\n",
      "\n",
      "Test set in round324: Average loss: 0.0395, Accuracy: 9864/10020 (98.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007963\n",
      "After training\n",
      "\n",
      "Test set in round325: Average loss: 0.0378, Accuracy: 9867/10020 (98.47%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.057794\n",
      "After training\n",
      "\n",
      "Test set in round326: Average loss: 0.0424, Accuracy: 9873/10020 (98.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024576\n",
      "After training\n",
      "\n",
      "Test set in round327: Average loss: 0.0381, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034170\n",
      "After training\n",
      "\n",
      "Test set in round328: Average loss: 0.0384, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041595\n",
      "After training\n",
      "\n",
      "Test set in round329: Average loss: 0.0414, Accuracy: 9866/10020 (98.46%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010889\n",
      "After training\n",
      "\n",
      "Test set in round330: Average loss: 0.0420, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028783\n",
      "After training\n",
      "\n",
      "Test set in round331: Average loss: 0.0374, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041441\n",
      "After training\n",
      "\n",
      "Test set in round332: Average loss: 0.0373, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028150\n",
      "After training\n",
      "\n",
      "Test set in round333: Average loss: 0.0371, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035694\n",
      "After training\n",
      "\n",
      "Test set in round334: Average loss: 0.0376, Accuracy: 9876/10020 (98.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006888\n",
      "After training\n",
      "\n",
      "Test set in round335: Average loss: 0.0382, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.057255\n",
      "After training\n",
      "\n",
      "Test set in round336: Average loss: 0.0413, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033156\n",
      "After training\n",
      "\n",
      "Test set in round337: Average loss: 0.0373, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.061174\n",
      "After training\n",
      "\n",
      "Test set in round338: Average loss: 0.0388, Accuracy: 9870/10020 (98.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028642\n",
      "After training\n",
      "\n",
      "Test set in round339: Average loss: 0.0377, Accuracy: 9876/10020 (98.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028565\n",
      "After training\n",
      "\n",
      "Test set in round340: Average loss: 0.0385, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024538\n",
      "After training\n",
      "\n",
      "Test set in round341: Average loss: 0.0426, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022458\n",
      "After training\n",
      "\n",
      "Test set in round342: Average loss: 0.0382, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007303\n",
      "After training\n",
      "\n",
      "Test set in round343: Average loss: 0.0375, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.069183\n",
      "After training\n",
      "\n",
      "Test set in round344: Average loss: 0.0372, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025166\n",
      "After training\n",
      "\n",
      "Test set in round345: Average loss: 0.0388, Accuracy: 9870/10020 (98.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012726\n",
      "After training\n",
      "\n",
      "Test set in round346: Average loss: 0.0364, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029471\n",
      "After training\n",
      "\n",
      "Test set in round347: Average loss: 0.0367, Accuracy: 9876/10020 (98.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038985\n",
      "After training\n",
      "\n",
      "Test set in round348: Average loss: 0.0375, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029641\n",
      "After training\n",
      "\n",
      "Test set in round349: Average loss: 0.0359, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.065510\n",
      "After training\n",
      "\n",
      "Test set in round350: Average loss: 0.0388, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039866\n",
      "After training\n",
      "\n",
      "Test set in round351: Average loss: 0.0373, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.014603\n",
      "After training\n",
      "\n",
      "Test set in round352: Average loss: 0.0356, Accuracy: 9876/10020 (98.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029573\n",
      "After training\n",
      "\n",
      "Test set in round353: Average loss: 0.0365, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039628\n",
      "After training\n",
      "\n",
      "Test set in round354: Average loss: 0.0353, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.052090\n",
      "After training\n",
      "\n",
      "Test set in round355: Average loss: 0.0353, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020780\n",
      "After training\n",
      "\n",
      "Test set in round356: Average loss: 0.0384, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.064536\n",
      "After training\n",
      "\n",
      "Test set in round357: Average loss: 0.0369, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.060954\n",
      "After training\n",
      "\n",
      "Test set in round358: Average loss: 0.0375, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.059993\n",
      "After training\n",
      "\n",
      "Test set in round359: Average loss: 0.0356, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046761\n",
      "After training\n",
      "\n",
      "Test set in round360: Average loss: 0.0379, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.060259\n",
      "After training\n",
      "\n",
      "Test set in round361: Average loss: 0.0354, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032058\n",
      "After training\n",
      "\n",
      "Test set in round362: Average loss: 0.0385, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.057712\n",
      "After training\n",
      "\n",
      "Test set in round363: Average loss: 0.0367, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033046\n",
      "After training\n",
      "\n",
      "Test set in round364: Average loss: 0.0356, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038680\n",
      "After training\n",
      "\n",
      "Test set in round365: Average loss: 0.0368, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031428\n",
      "After training\n",
      "\n",
      "Test set in round366: Average loss: 0.0370, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012368\n",
      "After training\n",
      "\n",
      "Test set in round367: Average loss: 0.0363, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.052407\n",
      "After training\n",
      "\n",
      "Test set in round368: Average loss: 0.0351, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027719\n",
      "After training\n",
      "\n",
      "Test set in round369: Average loss: 0.0355, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027817\n",
      "After training\n",
      "\n",
      "Test set in round370: Average loss: 0.0365, Accuracy: 9873/10020 (98.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029590\n",
      "After training\n",
      "\n",
      "Test set in round371: Average loss: 0.0359, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031600\n",
      "After training\n",
      "\n",
      "Test set in round372: Average loss: 0.0362, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008759\n",
      "After training\n",
      "\n",
      "Test set in round373: Average loss: 0.0359, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030361\n",
      "After training\n",
      "\n",
      "Test set in round374: Average loss: 0.0384, Accuracy: 9873/10020 (98.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.058968\n",
      "After training\n",
      "\n",
      "Test set in round375: Average loss: 0.0363, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029967\n",
      "After training\n",
      "\n",
      "Test set in round376: Average loss: 0.0372, Accuracy: 9870/10020 (98.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018940\n",
      "After training\n",
      "\n",
      "Test set in round377: Average loss: 0.0369, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038464\n",
      "After training\n",
      "\n",
      "Test set in round378: Average loss: 0.0391, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022369\n",
      "After training\n",
      "\n",
      "Test set in round379: Average loss: 0.0359, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031609\n",
      "After training\n",
      "\n",
      "Test set in round380: Average loss: 0.0345, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022508\n",
      "After training\n",
      "\n",
      "Test set in round381: Average loss: 0.0365, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008264\n",
      "After training\n",
      "\n",
      "Test set in round382: Average loss: 0.0357, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007841\n",
      "After training\n",
      "\n",
      "Test set in round383: Average loss: 0.0369, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.058987\n",
      "After training\n",
      "\n",
      "Test set in round384: Average loss: 0.0376, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026471\n",
      "After training\n",
      "\n",
      "Test set in round385: Average loss: 0.0374, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028680\n",
      "After training\n",
      "\n",
      "Test set in round386: Average loss: 0.0351, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.043472\n",
      "After training\n",
      "\n",
      "Test set in round387: Average loss: 0.0384, Accuracy: 9870/10020 (98.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031093\n",
      "After training\n",
      "\n",
      "Test set in round388: Average loss: 0.0351, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.040459\n",
      "After training\n",
      "\n",
      "Test set in round389: Average loss: 0.0362, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010737\n",
      "After training\n",
      "\n",
      "Test set in round390: Average loss: 0.0349, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.059576\n",
      "After training\n",
      "\n",
      "Test set in round391: Average loss: 0.0351, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.013616\n",
      "After training\n",
      "\n",
      "Test set in round392: Average loss: 0.0361, Accuracy: 9879/10020 (98.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023233\n",
      "After training\n",
      "\n",
      "Test set in round393: Average loss: 0.0346, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024681\n",
      "After training\n",
      "\n",
      "Test set in round394: Average loss: 0.0352, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008790\n",
      "After training\n",
      "\n",
      "Test set in round395: Average loss: 0.0364, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026652\n",
      "After training\n",
      "\n",
      "Test set in round396: Average loss: 0.0355, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018580\n",
      "After training\n",
      "\n",
      "Test set in round397: Average loss: 0.0368, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015302\n",
      "After training\n",
      "\n",
      "Test set in round398: Average loss: 0.0360, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024131\n",
      "After training\n",
      "\n",
      "Test set in round399: Average loss: 0.0357, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023439\n",
      "After training\n",
      "\n",
      "Test set in round400: Average loss: 0.0360, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051655\n",
      "After training\n",
      "\n",
      "Test set in round401: Average loss: 0.0388, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028013\n",
      "After training\n",
      "\n",
      "Test set in round402: Average loss: 0.0359, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025316\n",
      "After training\n",
      "\n",
      "Test set in round403: Average loss: 0.0358, Accuracy: 9879/10020 (98.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039547\n",
      "After training\n",
      "\n",
      "Test set in round404: Average loss: 0.0342, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037024\n",
      "After training\n",
      "\n",
      "Test set in round405: Average loss: 0.0399, Accuracy: 9860/10020 (98.40%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.062572\n",
      "After training\n",
      "\n",
      "Test set in round406: Average loss: 0.0345, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024036\n",
      "After training\n",
      "\n",
      "Test set in round407: Average loss: 0.0344, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030125\n",
      "After training\n",
      "\n",
      "Test set in round408: Average loss: 0.0358, Accuracy: 9876/10020 (98.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.057298\n",
      "After training\n",
      "\n",
      "Test set in round409: Average loss: 0.0346, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027800\n",
      "After training\n",
      "\n",
      "Test set in round410: Average loss: 0.0364, Accuracy: 9873/10020 (98.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025867\n",
      "After training\n",
      "\n",
      "Test set in round411: Average loss: 0.0356, Accuracy: 9876/10020 (98.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010180\n",
      "After training\n",
      "\n",
      "Test set in round412: Average loss: 0.0344, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033707\n",
      "After training\n",
      "\n",
      "Test set in round413: Average loss: 0.0360, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.005734\n",
      "After training\n",
      "\n",
      "Test set in round414: Average loss: 0.0351, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055486\n",
      "After training\n",
      "\n",
      "Test set in round415: Average loss: 0.0341, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038454\n",
      "After training\n",
      "\n",
      "Test set in round416: Average loss: 0.0382, Accuracy: 9876/10020 (98.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022647\n",
      "After training\n",
      "\n",
      "Test set in round417: Average loss: 0.0343, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.054719\n",
      "After training\n",
      "\n",
      "Test set in round418: Average loss: 0.0358, Accuracy: 9876/10020 (98.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.005549\n",
      "After training\n",
      "\n",
      "Test set in round419: Average loss: 0.0348, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010338\n",
      "After training\n",
      "\n",
      "Test set in round420: Average loss: 0.0327, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027349\n",
      "After training\n",
      "\n",
      "Test set in round421: Average loss: 0.0350, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030423\n",
      "After training\n",
      "\n",
      "Test set in round422: Average loss: 0.0355, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007920\n",
      "After training\n",
      "\n",
      "Test set in round423: Average loss: 0.0342, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035605\n",
      "After training\n",
      "\n",
      "Test set in round424: Average loss: 0.0338, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019501\n",
      "After training\n",
      "\n",
      "Test set in round425: Average loss: 0.0356, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028146\n",
      "After training\n",
      "\n",
      "Test set in round426: Average loss: 0.0333, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022235\n",
      "After training\n",
      "\n",
      "Test set in round427: Average loss: 0.0334, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030164\n",
      "After training\n",
      "\n",
      "Test set in round428: Average loss: 0.0332, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031077\n",
      "After training\n",
      "\n",
      "Test set in round429: Average loss: 0.0326, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055464\n",
      "After training\n",
      "\n",
      "Test set in round430: Average loss: 0.0342, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017298\n",
      "After training\n",
      "\n",
      "Test set in round431: Average loss: 0.0338, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025157\n",
      "After training\n",
      "\n",
      "Test set in round432: Average loss: 0.0336, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024775\n",
      "After training\n",
      "\n",
      "Test set in round433: Average loss: 0.0324, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031009\n",
      "After training\n",
      "\n",
      "Test set in round434: Average loss: 0.0342, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031656\n",
      "After training\n",
      "\n",
      "Test set in round435: Average loss: 0.0325, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033593\n",
      "After training\n",
      "\n",
      "Test set in round436: Average loss: 0.0346, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.043606\n",
      "After training\n",
      "\n",
      "Test set in round437: Average loss: 0.0346, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031468\n",
      "After training\n",
      "\n",
      "Test set in round438: Average loss: 0.0325, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.009319\n",
      "After training\n",
      "\n",
      "Test set in round439: Average loss: 0.0334, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039519\n",
      "After training\n",
      "\n",
      "Test set in round440: Average loss: 0.0373, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019506\n",
      "After training\n",
      "\n",
      "Test set in round441: Average loss: 0.0339, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017556\n",
      "After training\n",
      "\n",
      "Test set in round442: Average loss: 0.0347, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025025\n",
      "After training\n",
      "\n",
      "Test set in round443: Average loss: 0.0329, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027281\n",
      "After training\n",
      "\n",
      "Test set in round444: Average loss: 0.0343, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025741\n",
      "After training\n",
      "\n",
      "Test set in round445: Average loss: 0.0343, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020056\n",
      "After training\n",
      "\n",
      "Test set in round446: Average loss: 0.0332, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025355\n",
      "After training\n",
      "\n",
      "Test set in round447: Average loss: 0.0350, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.058766\n",
      "After training\n",
      "\n",
      "Test set in round448: Average loss: 0.0334, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008290\n",
      "After training\n",
      "\n",
      "Test set in round449: Average loss: 0.0327, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.052617\n",
      "After training\n",
      "\n",
      "Test set in round450: Average loss: 0.0336, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008103\n",
      "After training\n",
      "\n",
      "Test set in round451: Average loss: 0.0327, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010317\n",
      "After training\n",
      "\n",
      "Test set in round452: Average loss: 0.0316, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041008\n",
      "After training\n",
      "\n",
      "Test set in round453: Average loss: 0.0336, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033305\n",
      "After training\n",
      "\n",
      "Test set in round454: Average loss: 0.0335, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026392\n",
      "After training\n",
      "\n",
      "Test set in round455: Average loss: 0.0341, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032865\n",
      "After training\n",
      "\n",
      "Test set in round456: Average loss: 0.0328, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016335\n",
      "After training\n",
      "\n",
      "Test set in round457: Average loss: 0.0327, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031848\n",
      "After training\n",
      "\n",
      "Test set in round458: Average loss: 0.0366, Accuracy: 9879/10020 (98.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018555\n",
      "After training\n",
      "\n",
      "Test set in round459: Average loss: 0.0334, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025780\n",
      "After training\n",
      "\n",
      "Test set in round460: Average loss: 0.0327, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.057462\n",
      "After training\n",
      "\n",
      "Test set in round461: Average loss: 0.0327, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022274\n",
      "After training\n",
      "\n",
      "Test set in round462: Average loss: 0.0347, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015730\n",
      "After training\n",
      "\n",
      "Test set in round463: Average loss: 0.0338, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008497\n",
      "After training\n",
      "\n",
      "Test set in round464: Average loss: 0.0338, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027971\n",
      "After training\n",
      "\n",
      "Test set in round465: Average loss: 0.0327, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016877\n",
      "After training\n",
      "\n",
      "Test set in round466: Average loss: 0.0347, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022684\n",
      "After training\n",
      "\n",
      "Test set in round467: Average loss: 0.0333, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.054302\n",
      "After training\n",
      "\n",
      "Test set in round468: Average loss: 0.0320, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022100\n",
      "After training\n",
      "\n",
      "Test set in round469: Average loss: 0.0341, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027966\n",
      "After training\n",
      "\n",
      "Test set in round470: Average loss: 0.0330, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018369\n",
      "After training\n",
      "\n",
      "Test set in round471: Average loss: 0.0330, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030728\n",
      "After training\n",
      "\n",
      "Test set in round472: Average loss: 0.0341, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051956\n",
      "After training\n",
      "\n",
      "Test set in round473: Average loss: 0.0334, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051709\n",
      "After training\n",
      "\n",
      "Test set in round474: Average loss: 0.0331, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007185\n",
      "After training\n",
      "\n",
      "Test set in round475: Average loss: 0.0331, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024533\n",
      "After training\n",
      "\n",
      "Test set in round476: Average loss: 0.0335, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029331\n",
      "After training\n",
      "\n",
      "Test set in round477: Average loss: 0.0330, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007735\n",
      "After training\n",
      "\n",
      "Test set in round478: Average loss: 0.0319, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029565\n",
      "After training\n",
      "\n",
      "Test set in round479: Average loss: 0.0315, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032414\n",
      "After training\n",
      "\n",
      "Test set in round480: Average loss: 0.0337, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018715\n",
      "After training\n",
      "\n",
      "Test set in round481: Average loss: 0.0333, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025773\n",
      "After training\n",
      "\n",
      "Test set in round482: Average loss: 0.0318, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.005002\n",
      "After training\n",
      "\n",
      "Test set in round483: Average loss: 0.0319, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029205\n",
      "After training\n",
      "\n",
      "Test set in round484: Average loss: 0.0311, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049389\n",
      "After training\n",
      "\n",
      "Test set in round485: Average loss: 0.0332, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015059\n",
      "After training\n",
      "\n",
      "Test set in round486: Average loss: 0.0330, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008841\n",
      "After training\n",
      "\n",
      "Test set in round487: Average loss: 0.0314, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006134\n",
      "After training\n",
      "\n",
      "Test set in round488: Average loss: 0.0322, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015795\n",
      "After training\n",
      "\n",
      "Test set in round489: Average loss: 0.0334, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025084\n",
      "After training\n",
      "\n",
      "Test set in round490: Average loss: 0.0318, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047067\n",
      "After training\n",
      "\n",
      "Test set in round491: Average loss: 0.0341, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020501\n",
      "After training\n",
      "\n",
      "Test set in round492: Average loss: 0.0332, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025993\n",
      "After training\n",
      "\n",
      "Test set in round493: Average loss: 0.0326, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023395\n",
      "After training\n",
      "\n",
      "Test set in round494: Average loss: 0.0329, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015478\n",
      "After training\n",
      "\n",
      "Test set in round495: Average loss: 0.0337, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047446\n",
      "After training\n",
      "\n",
      "Test set in round496: Average loss: 0.0342, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025799\n",
      "After training\n",
      "\n",
      "Test set in round497: Average loss: 0.0312, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023441\n",
      "After training\n",
      "\n",
      "Test set in round498: Average loss: 0.0351, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007132\n",
      "After training\n",
      "\n",
      "Test set in round499: Average loss: 0.0339, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.050725\n",
      "After training\n",
      "\n",
      "Test set in round500: Average loss: 0.0315, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031908\n",
      "After training\n",
      "\n",
      "Test set in round501: Average loss: 0.0316, Accuracy: 9901/10020 (98.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028588\n",
      "After training\n",
      "\n",
      "Test set in round502: Average loss: 0.0324, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018190\n",
      "After training\n",
      "\n",
      "Test set in round503: Average loss: 0.0324, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024310\n",
      "After training\n",
      "\n",
      "Test set in round504: Average loss: 0.0334, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019934\n",
      "After training\n",
      "\n",
      "Test set in round505: Average loss: 0.0319, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.014032\n",
      "After training\n",
      "\n",
      "Test set in round506: Average loss: 0.0319, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047719\n",
      "After training\n",
      "\n",
      "Test set in round507: Average loss: 0.0322, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006704\n",
      "After training\n",
      "\n",
      "Test set in round508: Average loss: 0.0331, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026520\n",
      "After training\n",
      "\n",
      "Test set in round509: Average loss: 0.0323, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.040275\n",
      "After training\n",
      "\n",
      "Test set in round510: Average loss: 0.0353, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.009052\n",
      "After training\n",
      "\n",
      "Test set in round511: Average loss: 0.0313, Accuracy: 9901/10020 (98.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.013913\n",
      "After training\n",
      "\n",
      "Test set in round512: Average loss: 0.0315, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025889\n",
      "After training\n",
      "\n",
      "Test set in round513: Average loss: 0.0310, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028900\n",
      "After training\n",
      "\n",
      "Test set in round514: Average loss: 0.0312, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051015\n",
      "After training\n",
      "\n",
      "Test set in round515: Average loss: 0.0321, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018274\n",
      "After training\n",
      "\n",
      "Test set in round516: Average loss: 0.0316, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023012\n",
      "After training\n",
      "\n",
      "Test set in round517: Average loss: 0.0313, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018688\n",
      "After training\n",
      "\n",
      "Test set in round518: Average loss: 0.0319, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034728\n",
      "After training\n",
      "\n",
      "Test set in round519: Average loss: 0.0341, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022275\n",
      "After training\n",
      "\n",
      "Test set in round520: Average loss: 0.0300, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017789\n",
      "After training\n",
      "\n",
      "Test set in round521: Average loss: 0.0320, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027797\n",
      "After training\n",
      "\n",
      "Test set in round522: Average loss: 0.0328, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.013918\n",
      "After training\n",
      "\n",
      "Test set in round523: Average loss: 0.0321, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025316\n",
      "After training\n",
      "\n",
      "Test set in round524: Average loss: 0.0316, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.048088\n",
      "After training\n",
      "\n",
      "Test set in round525: Average loss: 0.0316, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025965\n",
      "After training\n",
      "\n",
      "Test set in round526: Average loss: 0.0305, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027426\n",
      "After training\n",
      "\n",
      "Test set in round527: Average loss: 0.0312, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024615\n",
      "After training\n",
      "\n",
      "Test set in round528: Average loss: 0.0302, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026685\n",
      "After training\n",
      "\n",
      "Test set in round529: Average loss: 0.0309, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025542\n",
      "After training\n",
      "\n",
      "Test set in round530: Average loss: 0.0314, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006051\n",
      "After training\n",
      "\n",
      "Test set in round531: Average loss: 0.0326, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029189\n",
      "After training\n",
      "\n",
      "Test set in round532: Average loss: 0.0320, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021561\n",
      "After training\n",
      "\n",
      "Test set in round533: Average loss: 0.0307, Accuracy: 9900/10020 (98.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046725\n",
      "After training\n",
      "\n",
      "Test set in round534: Average loss: 0.0320, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020934\n",
      "After training\n",
      "\n",
      "Test set in round535: Average loss: 0.0300, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.009037\n",
      "After training\n",
      "\n",
      "Test set in round536: Average loss: 0.0302, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020358\n",
      "After training\n",
      "\n",
      "Test set in round537: Average loss: 0.0339, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015036\n",
      "After training\n",
      "\n",
      "Test set in round538: Average loss: 0.0309, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.014645\n",
      "After training\n",
      "\n",
      "Test set in round539: Average loss: 0.0310, Accuracy: 9900/10020 (98.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020192\n",
      "After training\n",
      "\n",
      "Test set in round540: Average loss: 0.0314, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.048917\n",
      "After training\n",
      "\n",
      "Test set in round541: Average loss: 0.0309, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004802\n",
      "After training\n",
      "\n",
      "Test set in round542: Average loss: 0.0307, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023689\n",
      "After training\n",
      "\n",
      "Test set in round543: Average loss: 0.0311, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020764\n",
      "After training\n",
      "\n",
      "Test set in round544: Average loss: 0.0340, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006551\n",
      "After training\n",
      "\n",
      "Test set in round545: Average loss: 0.0316, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017022\n",
      "After training\n",
      "\n",
      "Test set in round546: Average loss: 0.0327, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015206\n",
      "After training\n",
      "\n",
      "Test set in round547: Average loss: 0.0318, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.005483\n",
      "After training\n",
      "\n",
      "Test set in round548: Average loss: 0.0300, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021177\n",
      "After training\n",
      "\n",
      "Test set in round549: Average loss: 0.0313, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015547\n",
      "After training\n",
      "\n",
      "Test set in round550: Average loss: 0.0308, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032294\n",
      "After training\n",
      "\n",
      "Test set in round551: Average loss: 0.0320, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021477\n",
      "After training\n",
      "\n",
      "Test set in round552: Average loss: 0.0301, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018002\n",
      "After training\n",
      "\n",
      "Test set in round553: Average loss: 0.0309, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023644\n",
      "After training\n",
      "\n",
      "Test set in round554: Average loss: 0.0317, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020451\n",
      "After training\n",
      "\n",
      "Test set in round555: Average loss: 0.0302, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020278\n",
      "After training\n",
      "\n",
      "Test set in round556: Average loss: 0.0311, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021512\n",
      "After training\n",
      "\n",
      "Test set in round557: Average loss: 0.0314, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016191\n",
      "After training\n",
      "\n",
      "Test set in round558: Average loss: 0.0315, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027342\n",
      "After training\n",
      "\n",
      "Test set in round559: Average loss: 0.0307, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031404\n",
      "After training\n",
      "\n",
      "Test set in round560: Average loss: 0.0310, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032066\n",
      "After training\n",
      "\n",
      "Test set in round561: Average loss: 0.0302, Accuracy: 9900/10020 (98.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037474\n",
      "After training\n",
      "\n",
      "Test set in round562: Average loss: 0.0327, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016741\n",
      "After training\n",
      "\n",
      "Test set in round563: Average loss: 0.0306, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017878\n",
      "After training\n",
      "\n",
      "Test set in round564: Average loss: 0.0307, Accuracy: 9900/10020 (98.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023640\n",
      "After training\n",
      "\n",
      "Test set in round565: Average loss: 0.0318, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019738\n",
      "After training\n",
      "\n",
      "Test set in round566: Average loss: 0.0304, Accuracy: 9901/10020 (98.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.014707\n",
      "After training\n",
      "\n",
      "Test set in round567: Average loss: 0.0312, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017053\n",
      "After training\n",
      "\n",
      "Test set in round568: Average loss: 0.0310, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004737\n",
      "After training\n",
      "\n",
      "Test set in round569: Average loss: 0.0304, Accuracy: 9901/10020 (98.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.013173\n",
      "After training\n",
      "\n",
      "Test set in round570: Average loss: 0.0303, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015281\n",
      "After training\n",
      "\n",
      "Test set in round571: Average loss: 0.0316, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018908\n",
      "After training\n",
      "\n",
      "Test set in round572: Average loss: 0.0310, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006501\n",
      "After training\n",
      "\n",
      "Test set in round573: Average loss: 0.0302, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019762\n",
      "After training\n",
      "\n",
      "Test set in round574: Average loss: 0.0305, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016596\n",
      "After training\n",
      "\n",
      "Test set in round575: Average loss: 0.0307, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016540\n",
      "After training\n",
      "\n",
      "Test set in round576: Average loss: 0.0312, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015100\n",
      "After training\n",
      "\n",
      "Test set in round577: Average loss: 0.0307, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004205\n",
      "After training\n",
      "\n",
      "Test set in round578: Average loss: 0.0312, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.004313\n",
      "After training\n",
      "\n",
      "Test set in round579: Average loss: 0.0296, Accuracy: 9906/10020 (98.86%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030455\n",
      "After training\n",
      "\n",
      "Test set in round580: Average loss: 0.0336, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039689\n",
      "After training\n",
      "\n",
      "Test set in round581: Average loss: 0.0321, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022069\n",
      "After training\n",
      "\n",
      "Test set in round582: Average loss: 0.0302, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017597\n",
      "After training\n",
      "\n",
      "Test set in round583: Average loss: 0.0293, Accuracy: 9904/10020 (98.84%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018926\n",
      "After training\n",
      "\n",
      "Test set in round584: Average loss: 0.0308, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.003801\n",
      "After training\n",
      "\n",
      "Test set in round585: Average loss: 0.0304, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019552\n",
      "After training\n",
      "\n",
      "Test set in round586: Average loss: 0.0297, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012510\n",
      "After training\n",
      "\n",
      "Test set in round587: Average loss: 0.0313, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018514\n",
      "After training\n",
      "\n",
      "Test set in round588: Average loss: 0.0308, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.011549\n",
      "After training\n",
      "\n",
      "Test set in round589: Average loss: 0.0306, Accuracy: 9900/10020 (98.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010339\n",
      "After training\n",
      "\n",
      "Test set in round590: Average loss: 0.0329, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037831\n",
      "After training\n",
      "\n",
      "Test set in round591: Average loss: 0.0333, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020234\n",
      "After training\n",
      "\n",
      "Test set in round592: Average loss: 0.0306, Accuracy: 9902/10020 (98.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053574\n",
      "After training\n",
      "\n",
      "Test set in round593: Average loss: 0.0320, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015714\n",
      "After training\n",
      "\n",
      "Test set in round594: Average loss: 0.0315, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006039\n",
      "After training\n",
      "\n",
      "Test set in round595: Average loss: 0.0316, Accuracy: 9898/10020 (98.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.005607\n",
      "After training\n",
      "\n",
      "Test set in round596: Average loss: 0.0305, Accuracy: 9907/10020 (98.87%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.014662\n",
      "After training\n",
      "\n",
      "Test set in round597: Average loss: 0.0310, Accuracy: 9895/10020 (98.75%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
    "logdir = '/root/notebooks/tensorflow/logs/30'\n",
    "writer = SummaryWriter(logdir)\n",
    "\n",
    "model_list = []\n",
    "model_list = model_init(workers, Net().to(device))\n",
    "opt_list = opt_init(model_list)\n",
    "# not finish in train, finish latter\n",
    "pars = [list(model.parameters()) for model in model_list]\n",
    "\n",
    "for r in range(1, args.rounds + 1):\n",
    "    train(args, device, train_loader, opt_list, workers)\n",
    "    print(\"After training\")\n",
    "    test(args, model_list[0], device, test_loader, r)\n",
    "\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
