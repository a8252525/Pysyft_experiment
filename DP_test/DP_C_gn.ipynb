{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use centrailzed training to compare with federated learning\n",
    "epochs = 30\n",
    "n_train_items = 12800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "# import torchcsprng as csprng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 250\n",
    "        self.test_batch_size = 64\n",
    "        self.epochs = epochs\n",
    "        self.lr = 0.25\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 30\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "# random_number_generator = csprng.create_random_device_generator(\n",
    "#                 \"/dev/urandom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../data', train=True, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../data', train=False, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size\n",
    ")\n",
    "\n",
    "    \n",
    "#---\n",
    "\n",
    "# train_dataloader = [\n",
    "#         ((data), (target))\n",
    "#         for i, (data, target) in enumerate(train_loader)\n",
    "#         if i < n_train_items / args.batch_size\n",
    "#     ]\n",
    "\n",
    "\n",
    "# test_dataloader = [\n",
    "#         ((data), (target))\n",
    "#         for i, (data, target) in enumerate(test_loader)\n",
    "#         if i < n_train_items / args.batch_size\n",
    "#     ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 8, 2, padding=3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 4, 2)\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x of shape [B, 1, 28, 28]\n",
    "        x = F.relu(self.conv1(x))  # -> [B, 16, 14, 14]\n",
    "        x = F.max_pool2d(x, 2, 1)  # -> [B, 16, 13, 13]\n",
    "        x = F.relu(self.conv2(x))  # -> [B, 32, 5, 5]\n",
    "        x = F.max_pool2d(x, 2, 1)  # -> [B, 32, 4, 4]\n",
    "        x = x.view(-1, 32 * 4 * 4)  # -> [B, 512]\n",
    "        x = F.relu(self.fc1(x))  # -> [B, 32]\n",
    "        x = self.fc2(x)  # -> [B, 10]\n",
    "        return x\n",
    "\n",
    "    def name(self):\n",
    "        return \"SampleConvNet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, device, model, train_dataloader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        data,target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),1.5)\n",
    "        \n",
    "        # adding noise to the gradient\n",
    "        for param in model.parameters():\n",
    "            noise = torch.normal(0,1.3*1.5,param.size(),device=device)*args.lr/args.batch_size\n",
    "            param.grad+=noise\n",
    "        optimizer.step()\n",
    "\n",
    "#           param.add_(torch.from_numpy(np.random.normal(0,1.3*1.5,param.size())*args.lr).to(device))\n",
    "        \n",
    "        \n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * args.batch_size, len(train_dataloader) * args.batch_size,\n",
    "                100. * batch_idx / len(train_dataloader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, device, model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader)*(args.test_batch_size)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader)* (args.test_batch_size),\n",
    "        100. * correct / (len(test_loader)*args.test_batch_size)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.309480\n",
      "Train Epoch: 1 [7500/60000 (12%)]\tLoss: 0.660928\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.351959\n",
      "Train Epoch: 1 [22500/60000 (38%)]\tLoss: 0.301276\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.190583\n",
      "Train Epoch: 1 [37500/60000 (62%)]\tLoss: 0.362098\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.146123\n",
      "Train Epoch: 1 [52500/60000 (88%)]\tLoss: 0.105430\n",
      "\n",
      "Test set: Average loss: 0.0810, Accuracy: 9749/10048 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.093707\n",
      "Train Epoch: 2 [7500/60000 (12%)]\tLoss: 0.082293\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.051621\n",
      "Train Epoch: 2 [22500/60000 (38%)]\tLoss: 0.097339\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.068151\n",
      "Train Epoch: 2 [37500/60000 (62%)]\tLoss: 0.165907\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.086043\n",
      "Train Epoch: 2 [52500/60000 (88%)]\tLoss: 0.051643\n",
      "\n",
      "Test set: Average loss: 0.0671, Accuracy: 9778/10048 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.070389\n",
      "Train Epoch: 3 [7500/60000 (12%)]\tLoss: 0.029207\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.018352\n",
      "Train Epoch: 3 [22500/60000 (38%)]\tLoss: 0.077811\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.049090\n",
      "Train Epoch: 3 [37500/60000 (62%)]\tLoss: 0.052901\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.053226\n",
      "Train Epoch: 3 [52500/60000 (88%)]\tLoss: 0.026949\n",
      "\n",
      "Test set: Average loss: 0.0464, Accuracy: 9852/10048 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.053827\n",
      "Train Epoch: 4 [7500/60000 (12%)]\tLoss: 0.022855\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.016117\n",
      "Train Epoch: 4 [22500/60000 (38%)]\tLoss: 0.052204\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.039878\n",
      "Train Epoch: 4 [37500/60000 (62%)]\tLoss: 0.036883\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.045708\n",
      "Train Epoch: 4 [52500/60000 (88%)]\tLoss: 0.021465\n",
      "\n",
      "Test set: Average loss: 0.0410, Accuracy: 9873/10048 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.036521\n",
      "Train Epoch: 5 [7500/60000 (12%)]\tLoss: 0.021477\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.011491\n",
      "Train Epoch: 5 [22500/60000 (38%)]\tLoss: 0.045832\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.029299\n",
      "Train Epoch: 5 [37500/60000 (62%)]\tLoss: 0.037174\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.042926\n",
      "Train Epoch: 5 [52500/60000 (88%)]\tLoss: 0.017944\n",
      "\n",
      "Test set: Average loss: 0.0417, Accuracy: 9875/10048 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.027002\n",
      "Train Epoch: 6 [7500/60000 (12%)]\tLoss: 0.016810\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 0.011963\n",
      "Train Epoch: 6 [22500/60000 (38%)]\tLoss: 0.038046\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.025555\n",
      "Train Epoch: 6 [37500/60000 (62%)]\tLoss: 0.028488\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 0.035581\n",
      "Train Epoch: 6 [52500/60000 (88%)]\tLoss: 0.015296\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 9878/10048 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.021686\n",
      "Train Epoch: 7 [7500/60000 (12%)]\tLoss: 0.014632\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 0.016987\n",
      "Train Epoch: 7 [22500/60000 (38%)]\tLoss: 0.038263\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.028692\n",
      "Train Epoch: 7 [37500/60000 (62%)]\tLoss: 0.032995\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 0.029196\n",
      "Train Epoch: 7 [52500/60000 (88%)]\tLoss: 0.012579\n",
      "\n",
      "Test set: Average loss: 0.0430, Accuracy: 9870/10048 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.022832\n",
      "Train Epoch: 8 [7500/60000 (12%)]\tLoss: 0.014743\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 0.006511\n",
      "Train Epoch: 8 [22500/60000 (38%)]\tLoss: 0.028286\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.028787\n",
      "Train Epoch: 8 [37500/60000 (62%)]\tLoss: 0.031066\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 0.023049\n",
      "Train Epoch: 8 [52500/60000 (88%)]\tLoss: 0.011539\n",
      "\n",
      "Test set: Average loss: 0.0451, Accuracy: 9873/10048 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.020619\n",
      "Train Epoch: 9 [7500/60000 (12%)]\tLoss: 0.008527\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 0.004364\n",
      "Train Epoch: 9 [22500/60000 (38%)]\tLoss: 0.026615\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.025203\n",
      "Train Epoch: 9 [37500/60000 (62%)]\tLoss: 0.025790\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 0.029886\n",
      "Train Epoch: 9 [52500/60000 (88%)]\tLoss: 0.010591\n",
      "\n",
      "Test set: Average loss: 0.0420, Accuracy: 9884/10048 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.018624\n",
      "Train Epoch: 10 [7500/60000 (12%)]\tLoss: 0.010064\n",
      "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 0.004866\n",
      "Train Epoch: 10 [22500/60000 (38%)]\tLoss: 0.015527\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.023354\n",
      "Train Epoch: 10 [37500/60000 (62%)]\tLoss: 0.015406\n",
      "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 0.011287\n",
      "Train Epoch: 10 [52500/60000 (88%)]\tLoss: 0.004748\n",
      "\n",
      "Test set: Average loss: 0.0466, Accuracy: 9880/10048 (98%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.020213\n",
      "Train Epoch: 11 [7500/60000 (12%)]\tLoss: 0.008153\n",
      "Train Epoch: 11 [15000/60000 (25%)]\tLoss: 0.006090\n",
      "Train Epoch: 11 [22500/60000 (38%)]\tLoss: 0.031107\n",
      "Train Epoch: 11 [30000/60000 (50%)]\tLoss: 0.020291\n",
      "Train Epoch: 11 [37500/60000 (62%)]\tLoss: 0.010685\n",
      "Train Epoch: 11 [45000/60000 (75%)]\tLoss: 0.005273\n",
      "Train Epoch: 11 [52500/60000 (88%)]\tLoss: 0.008698\n",
      "\n",
      "Test set: Average loss: 0.0448, Accuracy: 9887/10048 (98%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.010132\n",
      "Train Epoch: 12 [7500/60000 (12%)]\tLoss: 0.003556\n",
      "Train Epoch: 12 [15000/60000 (25%)]\tLoss: 0.007205\n",
      "Train Epoch: 12 [22500/60000 (38%)]\tLoss: 0.009894\n",
      "Train Epoch: 12 [30000/60000 (50%)]\tLoss: 0.017173\n",
      "Train Epoch: 12 [37500/60000 (62%)]\tLoss: 0.017067\n",
      "Train Epoch: 12 [45000/60000 (75%)]\tLoss: 0.008401\n",
      "Train Epoch: 12 [52500/60000 (88%)]\tLoss: 0.013943\n",
      "\n",
      "Test set: Average loss: 0.0605, Accuracy: 9849/10048 (98%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.017565\n",
      "Train Epoch: 13 [7500/60000 (12%)]\tLoss: 0.002531\n",
      "Train Epoch: 13 [15000/60000 (25%)]\tLoss: 0.020633\n",
      "Train Epoch: 13 [22500/60000 (38%)]\tLoss: 0.029110\n",
      "Train Epoch: 13 [30000/60000 (50%)]\tLoss: 0.009604\n",
      "Train Epoch: 13 [37500/60000 (62%)]\tLoss: 0.007574\n",
      "Train Epoch: 13 [45000/60000 (75%)]\tLoss: 0.011161\n",
      "Train Epoch: 13 [52500/60000 (88%)]\tLoss: 0.008625\n",
      "\n",
      "Test set: Average loss: 0.0511, Accuracy: 9876/10048 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.007686\n",
      "Train Epoch: 14 [7500/60000 (12%)]\tLoss: 0.001334\n",
      "Train Epoch: 14 [15000/60000 (25%)]\tLoss: 0.008282\n",
      "Train Epoch: 14 [22500/60000 (38%)]\tLoss: 0.015060\n",
      "Train Epoch: 14 [30000/60000 (50%)]\tLoss: 0.010071\n",
      "Train Epoch: 14 [37500/60000 (62%)]\tLoss: 0.006795\n",
      "Train Epoch: 14 [45000/60000 (75%)]\tLoss: 0.007378\n",
      "Train Epoch: 14 [52500/60000 (88%)]\tLoss: 0.006364\n",
      "\n",
      "Test set: Average loss: 0.0518, Accuracy: 9858/10048 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.011741\n",
      "Train Epoch: 15 [7500/60000 (12%)]\tLoss: 0.007048\n",
      "Train Epoch: 15 [15000/60000 (25%)]\tLoss: 0.004413\n",
      "Train Epoch: 15 [22500/60000 (38%)]\tLoss: 0.007500\n",
      "Train Epoch: 15 [30000/60000 (50%)]\tLoss: 0.003237\n",
      "Train Epoch: 15 [37500/60000 (62%)]\tLoss: 0.007501\n",
      "Train Epoch: 15 [45000/60000 (75%)]\tLoss: 0.007008\n",
      "Train Epoch: 15 [52500/60000 (88%)]\tLoss: 0.006835\n",
      "\n",
      "Test set: Average loss: 0.0515, Accuracy: 9881/10048 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.015644\n",
      "Train Epoch: 16 [7500/60000 (12%)]\tLoss: 0.003279\n",
      "Train Epoch: 16 [15000/60000 (25%)]\tLoss: 0.001315\n",
      "Train Epoch: 16 [22500/60000 (38%)]\tLoss: 0.014618\n",
      "Train Epoch: 16 [30000/60000 (50%)]\tLoss: 0.002563\n",
      "Train Epoch: 16 [37500/60000 (62%)]\tLoss: 0.005352\n",
      "Train Epoch: 16 [45000/60000 (75%)]\tLoss: 0.006090\n",
      "Train Epoch: 16 [52500/60000 (88%)]\tLoss: 0.004900\n",
      "\n",
      "Test set: Average loss: 0.0509, Accuracy: 9882/10048 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.007616\n",
      "Train Epoch: 17 [7500/60000 (12%)]\tLoss: 0.003670\n",
      "Train Epoch: 17 [15000/60000 (25%)]\tLoss: 0.008153\n",
      "Train Epoch: 17 [22500/60000 (38%)]\tLoss: 0.021331\n",
      "Train Epoch: 17 [30000/60000 (50%)]\tLoss: 0.006062\n",
      "Train Epoch: 17 [37500/60000 (62%)]\tLoss: 0.004877\n",
      "Train Epoch: 17 [45000/60000 (75%)]\tLoss: 0.009446\n",
      "Train Epoch: 17 [52500/60000 (88%)]\tLoss: 0.002611\n",
      "\n",
      "Test set: Average loss: 0.0530, Accuracy: 9872/10048 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.002837\n",
      "Train Epoch: 18 [7500/60000 (12%)]\tLoss: 0.002160\n",
      "Train Epoch: 18 [15000/60000 (25%)]\tLoss: 0.001507\n",
      "Train Epoch: 18 [22500/60000 (38%)]\tLoss: 0.001433\n",
      "Train Epoch: 18 [30000/60000 (50%)]\tLoss: 0.003376\n",
      "Train Epoch: 18 [37500/60000 (62%)]\tLoss: 0.002298\n",
      "Train Epoch: 18 [45000/60000 (75%)]\tLoss: 0.014654\n",
      "Train Epoch: 18 [52500/60000 (88%)]\tLoss: 0.001955\n",
      "\n",
      "Test set: Average loss: 0.0615, Accuracy: 9864/10048 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.007468\n",
      "Train Epoch: 19 [7500/60000 (12%)]\tLoss: 0.001356\n",
      "Train Epoch: 19 [15000/60000 (25%)]\tLoss: 0.002398\n",
      "Train Epoch: 19 [22500/60000 (38%)]\tLoss: 0.005756\n",
      "Train Epoch: 19 [30000/60000 (50%)]\tLoss: 0.003405\n",
      "Train Epoch: 19 [37500/60000 (62%)]\tLoss: 0.041687\n",
      "Train Epoch: 19 [45000/60000 (75%)]\tLoss: 0.007743\n",
      "Train Epoch: 19 [52500/60000 (88%)]\tLoss: 0.028207\n",
      "\n",
      "Test set: Average loss: 0.0633, Accuracy: 9854/10048 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.004686\n",
      "Train Epoch: 20 [7500/60000 (12%)]\tLoss: 0.008645\n",
      "Train Epoch: 20 [15000/60000 (25%)]\tLoss: 0.001040\n",
      "Train Epoch: 20 [22500/60000 (38%)]\tLoss: 0.004457\n",
      "Train Epoch: 20 [30000/60000 (50%)]\tLoss: 0.019590\n",
      "Train Epoch: 20 [37500/60000 (62%)]\tLoss: 0.006356\n",
      "Train Epoch: 20 [45000/60000 (75%)]\tLoss: 0.003227\n",
      "Train Epoch: 20 [52500/60000 (88%)]\tLoss: 0.002781\n",
      "\n",
      "Test set: Average loss: 0.0490, Accuracy: 9889/10048 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.015356\n",
      "Train Epoch: 21 [7500/60000 (12%)]\tLoss: 0.001011\n",
      "Train Epoch: 21 [15000/60000 (25%)]\tLoss: 0.001372\n",
      "Train Epoch: 21 [22500/60000 (38%)]\tLoss: 0.008421\n",
      "Train Epoch: 21 [30000/60000 (50%)]\tLoss: 0.016486\n",
      "Train Epoch: 21 [37500/60000 (62%)]\tLoss: 0.006467\n",
      "Train Epoch: 21 [45000/60000 (75%)]\tLoss: 0.002753\n",
      "Train Epoch: 21 [52500/60000 (88%)]\tLoss: 0.002650\n",
      "\n",
      "Test set: Average loss: 0.0544, Accuracy: 9884/10048 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.005510\n",
      "Train Epoch: 22 [7500/60000 (12%)]\tLoss: 0.020660\n",
      "Train Epoch: 22 [15000/60000 (25%)]\tLoss: 0.017001\n",
      "Train Epoch: 22 [22500/60000 (38%)]\tLoss: 0.001161\n",
      "Train Epoch: 22 [30000/60000 (50%)]\tLoss: 0.000846\n",
      "Train Epoch: 22 [37500/60000 (62%)]\tLoss: 0.046009\n",
      "Train Epoch: 22 [45000/60000 (75%)]\tLoss: 0.002528\n",
      "Train Epoch: 22 [52500/60000 (88%)]\tLoss: 0.000631\n",
      "\n",
      "Test set: Average loss: 0.0593, Accuracy: 9872/10048 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.000345\n",
      "Train Epoch: 23 [7500/60000 (12%)]\tLoss: 0.001506\n",
      "Train Epoch: 23 [15000/60000 (25%)]\tLoss: 0.001581\n",
      "Train Epoch: 23 [22500/60000 (38%)]\tLoss: 0.009846\n",
      "Train Epoch: 23 [30000/60000 (50%)]\tLoss: 0.019229\n",
      "Train Epoch: 23 [37500/60000 (62%)]\tLoss: 0.001723\n",
      "Train Epoch: 23 [45000/60000 (75%)]\tLoss: 0.005655\n",
      "Train Epoch: 23 [52500/60000 (88%)]\tLoss: 0.000626\n",
      "\n",
      "Test set: Average loss: 0.0597, Accuracy: 9876/10048 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.001558\n",
      "Train Epoch: 24 [7500/60000 (12%)]\tLoss: 0.002958\n",
      "Train Epoch: 24 [15000/60000 (25%)]\tLoss: 0.000323\n",
      "Train Epoch: 24 [22500/60000 (38%)]\tLoss: 0.004806\n",
      "Train Epoch: 24 [30000/60000 (50%)]\tLoss: 0.000843\n",
      "Train Epoch: 24 [37500/60000 (62%)]\tLoss: 0.001862\n",
      "Train Epoch: 24 [45000/60000 (75%)]\tLoss: 0.003789\n",
      "Train Epoch: 24 [52500/60000 (88%)]\tLoss: 0.002317\n",
      "\n",
      "Test set: Average loss: 0.0568, Accuracy: 9884/10048 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.003119\n",
      "Train Epoch: 25 [7500/60000 (12%)]\tLoss: 0.000308\n",
      "Train Epoch: 25 [15000/60000 (25%)]\tLoss: 0.011791\n",
      "Train Epoch: 25 [22500/60000 (38%)]\tLoss: 0.011922\n",
      "Train Epoch: 25 [30000/60000 (50%)]\tLoss: 0.006290\n",
      "Train Epoch: 25 [37500/60000 (62%)]\tLoss: 0.002939\n",
      "Train Epoch: 25 [45000/60000 (75%)]\tLoss: 0.006099\n",
      "Train Epoch: 25 [52500/60000 (88%)]\tLoss: 0.005370\n",
      "\n",
      "Test set: Average loss: 0.0651, Accuracy: 9876/10048 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.002814\n",
      "Train Epoch: 26 [7500/60000 (12%)]\tLoss: 0.001591\n",
      "Train Epoch: 26 [15000/60000 (25%)]\tLoss: 0.000461\n",
      "Train Epoch: 26 [22500/60000 (38%)]\tLoss: 0.009129\n",
      "Train Epoch: 26 [30000/60000 (50%)]\tLoss: 0.005645\n",
      "Train Epoch: 26 [37500/60000 (62%)]\tLoss: 0.002453\n",
      "Train Epoch: 26 [45000/60000 (75%)]\tLoss: 0.001151\n",
      "Train Epoch: 26 [52500/60000 (88%)]\tLoss: 0.000804\n",
      "\n",
      "Test set: Average loss: 0.0605, Accuracy: 9888/10048 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.003440\n",
      "Train Epoch: 27 [7500/60000 (12%)]\tLoss: 0.023993\n",
      "Train Epoch: 27 [15000/60000 (25%)]\tLoss: 0.001260\n",
      "Train Epoch: 27 [22500/60000 (38%)]\tLoss: 0.003702\n",
      "Train Epoch: 27 [30000/60000 (50%)]\tLoss: 0.000019\n",
      "Train Epoch: 27 [37500/60000 (62%)]\tLoss: 0.000468\n",
      "Train Epoch: 27 [45000/60000 (75%)]\tLoss: 0.000243\n",
      "Train Epoch: 27 [52500/60000 (88%)]\tLoss: 0.001330\n",
      "\n",
      "Test set: Average loss: 0.0590, Accuracy: 9890/10048 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.001403\n",
      "Train Epoch: 28 [7500/60000 (12%)]\tLoss: 0.001409\n",
      "Train Epoch: 28 [15000/60000 (25%)]\tLoss: 0.000836\n",
      "Train Epoch: 28 [22500/60000 (38%)]\tLoss: 0.008346\n",
      "Train Epoch: 28 [30000/60000 (50%)]\tLoss: 0.001368\n",
      "Train Epoch: 28 [37500/60000 (62%)]\tLoss: 0.000186\n",
      "Train Epoch: 28 [45000/60000 (75%)]\tLoss: 0.006906\n",
      "Train Epoch: 28 [52500/60000 (88%)]\tLoss: 0.000505\n",
      "\n",
      "Test set: Average loss: 0.0722, Accuracy: 9886/10048 (98%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.003728\n",
      "Train Epoch: 29 [7500/60000 (12%)]\tLoss: 0.003337\n",
      "Train Epoch: 29 [15000/60000 (25%)]\tLoss: 0.002422\n",
      "Train Epoch: 29 [22500/60000 (38%)]\tLoss: 0.000680\n",
      "Train Epoch: 29 [30000/60000 (50%)]\tLoss: 0.001544\n",
      "Train Epoch: 29 [37500/60000 (62%)]\tLoss: 0.000067\n",
      "Train Epoch: 29 [45000/60000 (75%)]\tLoss: 0.001306\n",
      "Train Epoch: 29 [52500/60000 (88%)]\tLoss: 0.000493\n",
      "\n",
      "Test set: Average loss: 0.0622, Accuracy: 9888/10048 (98%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.003291\n",
      "Train Epoch: 30 [7500/60000 (12%)]\tLoss: 0.002675\n",
      "Train Epoch: 30 [15000/60000 (25%)]\tLoss: 0.000131\n",
      "Train Epoch: 30 [22500/60000 (38%)]\tLoss: 0.003397\n",
      "Train Epoch: 30 [30000/60000 (50%)]\tLoss: 0.000619\n",
      "Train Epoch: 30 [37500/60000 (62%)]\tLoss: 0.000398\n",
      "Train Epoch: 30 [45000/60000 (75%)]\tLoss: 0.000816\n",
      "Train Epoch: 30 [52500/60000 (88%)]\tLoss: 0.001622\n",
      "\n",
      "Test set: Average loss: 0.0635, Accuracy: 9882/10048 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "model = Net().to(device)\n",
    "optimizer =  optim.SGD(model.parameters(), lr=args.lr)\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, device, model, train_dataloader, optimizer, epoch)\n",
    "    test(args, device, model, test_loader)\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
