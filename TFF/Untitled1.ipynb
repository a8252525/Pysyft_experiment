{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:63: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    }
   ],
   "source": [
    "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f0000_14',\n",
       " 'f0001_41',\n",
       " 'f0005_26',\n",
       " 'f0006_12',\n",
       " 'f0008_45',\n",
       " 'f0011_13',\n",
       " 'f0014_19',\n",
       " 'f0016_39',\n",
       " 'f0017_07',\n",
       " 'f0022_10']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emnist_train.client_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('label', TensorSpec(shape=(), dtype=tf.int32, name=None)),\n",
       "             ('pixels',\n",
       "              TensorSpec(shape=(28, 28), dtype=tf.float32, name=None))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emnist_train.element_type_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_dataset = emnist_train.create_tf_dataset_for_client(\n",
    "    emnist_train.client_ids[0])\n",
    "\n",
    "example_element = next(iter(example_dataset))\n",
    "\n",
    "example_element['label'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(example_element['pixels'].numpy(), cmap='gray', aspect='equal')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 20\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER = 100\n",
    "PREFETCH_BUFFER=10\n",
    "\n",
    "def preprocess(dataset):\n",
    "\n",
    "  def batch_format_fn(element):\n",
    "    \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
    "    return collections.OrderedDict(\n",
    "        x=tf.reshape(element['pixels'], [-1, 784]),\n",
    "        y=tf.reshape(element['label'], [-1, 1]))\n",
    "\n",
    "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
    "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('x', array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "                     [1., 1., 1., ..., 1., 1., 1.],\n",
       "                     [1., 1., 1., ..., 1., 1., 1.],\n",
       "                     ...,\n",
       "                     [1., 1., 1., ..., 1., 1., 1.],\n",
       "                     [1., 1., 1., ..., 1., 1., 1.],\n",
       "                     [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)),\n",
       "             ('y', array([[9],\n",
       "                     [2],\n",
       "                     [1],\n",
       "                     [5],\n",
       "                     [8],\n",
       "                     [2],\n",
       "                     [8],\n",
       "                     [9],\n",
       "                     [6],\n",
       "                     [7],\n",
       "                     [4],\n",
       "                     [3],\n",
       "                     [1],\n",
       "                     [9],\n",
       "                     [5],\n",
       "                     [2],\n",
       "                     [1],\n",
       "                     [2],\n",
       "                     [6],\n",
       "                     [9],\n",
       "                     [1],\n",
       "                     [3],\n",
       "                     [1],\n",
       "                     [2],\n",
       "                     [4],\n",
       "                     [1],\n",
       "                     [6],\n",
       "                     [6],\n",
       "                     [9],\n",
       "                     [7],\n",
       "                     [2],\n",
       "                     [1],\n",
       "                     [8],\n",
       "                     [2],\n",
       "                     [1],\n",
       "                     [4],\n",
       "                     [0],\n",
       "                     [6],\n",
       "                     [0],\n",
       "                     [7],\n",
       "                     [7],\n",
       "                     [3],\n",
       "                     [4],\n",
       "                     [0],\n",
       "                     [2],\n",
       "                     [6],\n",
       "                     [4],\n",
       "                     [7],\n",
       "                     [9],\n",
       "                     [4],\n",
       "                     [2],\n",
       "                     [0],\n",
       "                     [3],\n",
       "                     [0],\n",
       "                     [5],\n",
       "                     [9],\n",
       "                     [8],\n",
       "                     [4],\n",
       "                     [6],\n",
       "                     [7],\n",
       "                     [1],\n",
       "                     [4],\n",
       "                     [8],\n",
       "                     [1]], dtype=int32))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_example_dataset = preprocess(example_dataset)\n",
    "\n",
    "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
    "                                     next(iter(preprocessed_example_dataset)))\n",
    "\n",
    "sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_federated_data(client_data, client_ids):\n",
    "  return [\n",
    "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
    "      for x in client_ids\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_federated.python.simulation.hdf5_client_data.HDF5ClientData"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(emnist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of client datasets: 20\n",
      "First dataset: <PrefetchDataset shapes: OrderedDict([(x, (None, 784)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>\n",
      "OrderedDict([('x', <tf.Tensor: shape=(64, 784), dtype=float32, numpy=\n",
      "array([[1., 1., 1., ..., 1., 1., 1.],\n",
      "       [1., 1., 1., ..., 1., 1., 1.],\n",
      "       [1., 1., 1., ..., 1., 1., 1.],\n",
      "       ...,\n",
      "       [1., 1., 1., ..., 1., 1., 1.],\n",
      "       [1., 1., 1., ..., 1., 1., 1.],\n",
      "       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)>), ('y', <tf.Tensor: shape=(64, 1), dtype=int32, numpy=\n",
      "array([[0],\n",
      "       [8],\n",
      "       [2],\n",
      "       [7],\n",
      "       [0],\n",
      "       [8],\n",
      "       [8],\n",
      "       [3],\n",
      "       [0],\n",
      "       [9],\n",
      "       [3],\n",
      "       [2],\n",
      "       [7],\n",
      "       [1],\n",
      "       [5],\n",
      "       [2],\n",
      "       [0],\n",
      "       [5],\n",
      "       [1],\n",
      "       [5],\n",
      "       [4],\n",
      "       [0],\n",
      "       [3],\n",
      "       [3],\n",
      "       [6],\n",
      "       [7],\n",
      "       [7],\n",
      "       [0],\n",
      "       [9],\n",
      "       [9],\n",
      "       [6],\n",
      "       [2],\n",
      "       [2],\n",
      "       [8],\n",
      "       [0],\n",
      "       [1],\n",
      "       [9],\n",
      "       [9],\n",
      "       [7],\n",
      "       [0],\n",
      "       [3],\n",
      "       [4],\n",
      "       [5],\n",
      "       [2],\n",
      "       [2],\n",
      "       [7],\n",
      "       [7],\n",
      "       [3],\n",
      "       [1],\n",
      "       [1],\n",
      "       [4],\n",
      "       [2],\n",
      "       [0],\n",
      "       [9],\n",
      "       [7],\n",
      "       [6],\n",
      "       [3],\n",
      "       [3],\n",
      "       [9],\n",
      "       [1],\n",
      "       [5],\n",
      "       [6],\n",
      "       [6],\n",
      "       [9]], dtype=int32)>)])\n",
      "Second dataset: <PrefetchDataset shapes: OrderedDict([(x, (None, 784)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>\n"
     ]
    }
   ],
   "source": [
    "sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]\n",
    "\n",
    "federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
    "\n",
    "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
    "print('First dataset: {d}'.format(d=federated_train_data[0]))\n",
    "print('Second dataset: {d}'.format(d=federated_train_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0000_14def create_keras_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Input(shape=(784,)),\n",
    "      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
    "      tf.keras.layers.Softmax(),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "  # We _must_ create a new model here, and _not_ capture it from an external\n",
    "  # scope. TFF will call this within different graph contexts.\n",
    "  keras_model = create_keras_model()\n",
    "  return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=preprocessed_example_dataset.element_spec,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'( -> <model=<trainable=<float32[784,10],float32[10]>,non_trainable=<>>,optimizer_state=<int64>,delta_aggregate_state=<>,model_broadcast_state=<>>@SERVER)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(iterative_process.initialize.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  1, metrics=<sparse_categorical_accuracy=0.12839506566524506,loss=2.9675543308258057>\n"
     ]
    }
   ],
   "source": [
    "state, metrics = iterative_process.next(state, federated_train_data)\n",
    "print('round  1, metrics={}'.format(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  2, metrics=<sparse_categorical_accuracy=0.1415637880563736,loss=2.8178536891937256>\n",
      "round  3, metrics=<sparse_categorical_accuracy=0.16769547760486603,loss=2.8049938678741455>\n",
      "round  4, metrics=<sparse_categorical_accuracy=0.17139917612075806,loss=2.6759519577026367>\n",
      "round  5, metrics=<sparse_categorical_accuracy=0.19279836118221283,loss=2.642240047454834>\n",
      "round  6, metrics=<sparse_categorical_accuracy=0.19382716715335846,loss=2.4981446266174316>\n",
      "round  7, metrics=<sparse_categorical_accuracy=0.24444444477558136,loss=2.360257148742676>\n",
      "round  8, metrics=<sparse_categorical_accuracy=0.26358023285865784,loss=2.2955877780914307>\n",
      "round  9, metrics=<sparse_categorical_accuracy=0.29135802388191223,loss=2.176128387451172>\n",
      "round 10, metrics=<sparse_categorical_accuracy=0.3002057671546936,loss=2.1810338497161865>\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 11\n",
    "for round_num in range(2, NUM_ROUNDS):\n",
    "  state, metrics = iterative_process.next(state, federated_train_data)\n",
    "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
