{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FATAL Flags parsing error: Unknown command line flag 'f'\n",
      "Pass --helpshort or --helpfull to see help on flags.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2018, The TensorFlow Federated Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"Example showing how to run a multi-machine simulation.\n",
    "\n",
    "In order to run this example, you must have a running instance of the\n",
    "Executor Service, either locally or on Kubernetes.\n",
    "\n",
    "The model trains EMNIST for a small number of rounds, but uses a RemoteExecutor\n",
    "to distribute the work to the ExecutorService.\n",
    "\"\"\"\n",
    "\n",
    "import collections\n",
    "import warnings\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import grpc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string('host', None, 'The host to connect to.')\n",
    "flags.mark_flag_as_required('host')\n",
    "flags.DEFINE_string('port', '8000', 'The port to connect to.')\n",
    "flags.DEFINE_integer('n_clients', 10, 'Number of clients.')\n",
    "flags.DEFINE_integer('n_rounds', 3, 'Number of rounds.')\n",
    "\n",
    "\n",
    "def preprocess(dataset):\n",
    "\n",
    "  def element_fn(element):\n",
    "    return collections.OrderedDict([\n",
    "        ('x', tf.reshape(element['pixels'], [-1])),\n",
    "        ('y', tf.reshape(element['label'], [1])),\n",
    "    ])\n",
    "\n",
    "  return dataset.repeat(NUM_EPOCHS).map(element_fn).batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "def make_federated_data(client_data, client_ids):\n",
    "  return [\n",
    "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
    "      for x in client_ids\n",
    "  ]\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "\n",
    "def make_remote_executor(inferred_cardinalities):\n",
    "  \"\"\"Make remote executor.\"\"\"\n",
    "\n",
    "  def create_worker_stack_on(ex):\n",
    "    return tff.framework.ReferenceResolvingExecutor(\n",
    "        tff.framework.ThreadDelegatingExecutor(ex))\n",
    "\n",
    "  client_ex = []\n",
    "  num_clients = inferred_cardinalities.get(tff.CLIENTS, None)\n",
    "  if num_clients:\n",
    "    print('Inferred that there are {} clients'.format(num_clients))\n",
    "  else:\n",
    "    print('No CLIENTS placement provided')\n",
    "\n",
    "  for _ in range(num_clients or 0):\n",
    "    channel = grpc.insecure_channel('{}:{}'.format(FLAGS.host, FLAGS.port))\n",
    "    client_ex.append(\n",
    "        create_worker_stack_on(\n",
    "            tff.framework.RemoteExecutor(channel, rpc_mode='STREAMING')))\n",
    "\n",
    "  federated_ex = tff.framework.FederatingExecutor({\n",
    "      None: create_worker_stack_on(tff.framework.EagerTFExecutor()),\n",
    "      tff.SERVER: create_worker_stack_on(tff.framework.EagerTFExecutor()),\n",
    "      tff.CLIENTS: client_ex,\n",
    "  })\n",
    "\n",
    "  return tff.framework.ReferenceResolvingExecutor(federated_ex)\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "  if len(argv) > 1:\n",
    "    raise app.UsageError('Too many command-line arguments.')\n",
    "\n",
    "  warnings.simplefilter('ignore')\n",
    "\n",
    "  np.random.seed(0)\n",
    "\n",
    "  emnist_train, _ = tff.simulation.datasets.emnist.load_data()\n",
    "\n",
    "  sample_clients = emnist_train.client_ids[0:FLAGS.n_clients]\n",
    "\n",
    "  federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
    "\n",
    "  example_dataset = emnist_train.create_tf_dataset_for_client(\n",
    "      emnist_train.client_ids[0])\n",
    "\n",
    "  preprocessed_example_dataset = preprocess(example_dataset)\n",
    "  input_spec = preprocessed_example_dataset.element_spec\n",
    "\n",
    "  def model_fn():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(784,)),\n",
    "        tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
    "        tf.keras.layers.Softmax(),\n",
    "    ])\n",
    "    return tff.learning.from_keras_model(\n",
    "        model,\n",
    "        input_spec=input_spec,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "  iterative_process = tff.learning.build_federated_averaging_process(\n",
    "      model_fn,\n",
    "      client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02))\n",
    "\n",
    "  # Set the default executor to be a RemoteExecutor\n",
    "  tff.framework.set_default_executor(\n",
    "      tff.framework.create_executor_factory(make_remote_executor))\n",
    "\n",
    "  state = iterative_process.initialize()\n",
    "\n",
    "  state, metrics = iterative_process.next(state, federated_train_data)\n",
    "  print('round  1, metrics={}'.format(metrics))\n",
    "\n",
    "  for round_num in range(2, FLAGS.n_rounds + 1):\n",
    "    state, metrics = iterative_process.next(state, federated_train_data)\n",
    "    print('round {:2d}, metrics={}'.format(round_num, metrics))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  app.run(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
