{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "# TODO(b/148678573,b/148685415): must use the ReferenceExecutor because it\n",
    "# supports unbounded references and tff.sequence_* intrinsics.\n",
    "tff.framework.set_default_executor(tff.test.ReferenceExecutor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(dtype('uint8'), (60000, 28, 28)), (dtype('uint8'), (60000,))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x.dtype, x.shape) for x in mnist_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES_PER_USER = 600\n",
    "B = 10\n",
    "BATCH_SIZE = NUM_EXAMPLES_PER_USER//B\n",
    "EPOCHS = 20\n",
    "\n",
    "def get_data_for_digit(source, digit):\n",
    "  output_sequence = []\n",
    "  all_samples = [i for i, d in enumerate(source[1]) if d == digit]\n",
    "  for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_USER), BATCH_SIZE):\n",
    "    batch_samples = all_samples[i:i + BATCH_SIZE]\n",
    "    output_sequence.append({\n",
    "        'x':\n",
    "            np.array([source[0][i].flatten() / 255.0 for i in batch_samples],\n",
    "                     dtype=np.float32),\n",
    "        'y':\n",
    "            np.array([source[1][i] for i in batch_samples], dtype=np.int32)\n",
    "    })\n",
    "  return output_sequence\n",
    "\n",
    "\n",
    "federated_train_data = [get_data_for_digit(mnist_train, d) for d in range(10)] * EPOCHS\n",
    "\n",
    "federated_test_data = [get_data_for_digit(mnist_test, d) for d in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "Epochs : 20\n"
     ]
    }
   ],
   "source": [
    "print(len(federated_train_data[5][-1]['y']))\n",
    "print(federated_train_data[5][-1]['y'])\n",
    "print('Epochs : {}'.format(len(federated_train_data)//10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(federated_train_data[5][-1]['x'][-1].reshape(28, 28), cmap='gray')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<x=float32[?,784],y=int32[?]>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SPEC = collections.OrderedDict(\n",
    "    x=tf.TensorSpec(shape=[None, 784], dtype=tf.float32),\n",
    "    y=tf.TensorSpec(shape=[None], dtype=tf.int32))\n",
    "BATCH_TYPE = tff.to_type(BATCH_SPEC)\n",
    "\n",
    "str(BATCH_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<weights=float32[784,10],bias=float32[10]>\n"
     ]
    }
   ],
   "source": [
    "MODEL_SPEC = collections.OrderedDict(\n",
    "    weights=tf.TensorSpec(shape=[784, 10], dtype=tf.float32),\n",
    "    bias=tf.TensorSpec(shape=[10], dtype=tf.float32))\n",
    "MODEL_TYPE = tff.to_type(MODEL_SPEC)\n",
    "\n",
    "print(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: `forward_pass` is defined separately from `batch_loss` so that it can \n",
    "# be later called from within another tf.function. Necessary because a\n",
    "# @tf.function  decorated method cannot invoke a @tff.tf_computation.\n",
    "\n",
    "@tf.function\n",
    "def forward_pass(model, batch):\n",
    "  predicted_y = tf.nn.softmax(\n",
    "      tf.matmul(batch['x'], model['weights']) + model['bias'])\n",
    "  return -tf.reduce_mean(\n",
    "      tf.reduce_sum(\n",
    "          tf.one_hot(batch['y'], 10) * tf.math.log(predicted_y), axis=[1]))\n",
    "\n",
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "def batch_loss(model, batch):\n",
    "  return forward_pass(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<<weights=float32[784,10],bias=float32[10]>,<x=float32[?,784],y=int32[?]>> -> float32)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(batch_loss.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3025854"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_model = collections.OrderedDict(\n",
    "    weights=np.zeros([784, 10], dtype=np.float32),\n",
    "    bias=np.zeros([10], dtype=np.float32))\n",
    "\n",
    "sample_batch = federated_train_data[5][-1]\n",
    "\n",
    "batch_loss(initial_model, sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
    "def batch_train(initial_model, batch, learning_rate):\n",
    "  # Define a group of model variables and set them to `initial_model`. Must\n",
    "  # be defined outside the @tf.function.\n",
    "  model_vars = collections.OrderedDict([\n",
    "      (name, tf.Variable(name=name, initial_value=value))\n",
    "      for name, value in initial_model.items()\n",
    "  ])\n",
    "  optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "  @tf.function\n",
    "  def _train_on_batch(model_vars, batch):\n",
    "    # Perform one step of gradient descent using loss from `batch_loss`.\n",
    "    with tf.GradientTape() as tape:\n",
    "      loss = forward_pass(model_vars, batch)\n",
    "    grads = tape.gradient(loss, model_vars)\n",
    "    optimizer.apply_gradients(\n",
    "        zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)))\n",
    "    return model_vars\n",
    "\n",
    "  return _train_on_batch(model_vars, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<<weights=float32[784,10],bias=float32[10]>,<x=float32[?,784],y=int32[?]>,float32> -> <weights=float32[784,10],bias=float32[10]>)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(batch_train.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initial_model\n",
    "losses = []\n",
    "for _ in range(5):\n",
    "  model = batch_train(model, sample_batch, 0.1)\n",
    "  losses.append(batch_loss(model, sample_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.27275327, 0.15478344, 0.110576674, 0.08657645, 0.07133835]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
    "\n",
    "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
    "def local_train(initial_model, learning_rate, all_batches):\n",
    "\n",
    "  # Mapping function to apply to each batch.\n",
    "  @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "  def batch_fn(model, batch):\n",
    "    return batch_train(model, batch, learning_rate)\n",
    "\n",
    "  return tff.sequence_reduce(all_batches, initial_model, batch_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<<weights=float32[784,10],bias=float32[10]>,float32,<x=float32[?,784],y=int32[?]>*> -> <weights=float32[784,10],bias=float32[10]>)'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(local_train.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "locally_trained_model = local_train(initial_model, 0.1, federated_train_data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
    "def local_eval(model, all_batches):\n",
    "  # TODO(b/120157713): Replace with `tff.sequence_average()` once implemented.\n",
    "  return tff.sequence_sum(\n",
    "      tff.sequence_map(\n",
    "          tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),\n",
    "          all_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(<<weights=float32[784,10],bias=float32[10]>,<x=float32[?,784],y=int32[?]>*> -> float32)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(local_eval.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_model loss = 23.025854\n",
      "locally_trained_model loss = 0.41719618\n"
     ]
    }
   ],
   "source": [
    "print('initial_model loss =', local_eval(initial_model,\n",
    "                                         federated_train_data[5]))\n",
    "print('locally_trained_model loss =',\n",
    "      local_eval(locally_trained_model, federated_train_data[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_model loss = 23.025854\n",
      "locally_trained_model loss = 74.082214\n"
     ]
    }
   ],
   "source": [
    "print('initial_model loss =', local_eval(initial_model,\n",
    "                                         federated_train_data[0]))\n",
    "print('locally_trained_model loss =',\n",
    "      local_eval(locally_trained_model, federated_train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER)\n",
    "CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
    "def federated_eval(model, data):\n",
    "  return tff.federated_mean(\n",
    "      tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_model loss = 23.025873\n",
      "locally_trained_model loss = 54.106598\n"
     ]
    }
   ],
   "source": [
    "print('initial_model loss =', federated_eval(initial_model,\n",
    "                                             federated_train_data))\n",
    "print('locally_trained_model loss =',\n",
    "      federated_eval(locally_trained_model, federated_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER)\n",
    "\n",
    "\n",
    "@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE,\n",
    "                           CLIENT_DATA_TYPE)\n",
    "def federated_train(model, learning_rate, data):\n",
    "  return tff.federated_mean(\n",
    "      tff.federated_map(local_train, [\n",
    "          tff.federated_broadcast(model),\n",
    "          tff.federated_broadcast(learning_rate), data\n",
    "      ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0, loss=21.579282760620117\n",
      "round 1, loss=20.319385528564453\n",
      "round 2, loss=19.213903427124023\n",
      "round 3, loss=18.239704132080078\n",
      "round 4, loss=17.378320693969727\n"
     ]
    }
   ],
   "source": [
    "model = initial_model\n",
    "learning_rate = 0.1\n",
    "for round_num in range(5):\n",
    "  model = federated_train(model, learning_rate, federated_train_data)\n",
    "  learning_rate = learning_rate * 0.9\n",
    "  loss = federated_eval(model, federated_train_data)\n",
    "  print('round {}, loss={}'.format(round_num, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_model test loss = 23.025852\n",
      "trained_model test loss = 17.832167\n"
     ]
    }
   ],
   "source": [
    "print('initial_model test loss =',\n",
    "      federated_eval(initial_model, federated_test_data))\n",
    "print('trained_model test loss =', federated_eval(model, federated_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
