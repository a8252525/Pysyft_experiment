{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "n_train_items = 6000\n",
    "rounds = 650\n",
    "total_client = 100\n",
    "C = 0.1\n",
    "n_workers = int(total_client * C)\n",
    "batch_size = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "import syft as sy  # <-- NEW: import the Pysyft library\n",
    "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
    "# simulation functions\n",
    "def connect_to_workers(n_workers):\n",
    "    return [\n",
    "        sy.VirtualWorker(hook, id=f\"worker{i+1}\")\n",
    "        for i in range(n_workers)\n",
    "    ]\n",
    "\n",
    "\n",
    "workers = connect_to_workers(n_workers=n_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = batch_size\n",
    "        self.test_batch_size = 60\n",
    "        self.epochs = epochs\n",
    "        self.rounds = rounds\n",
    "        self.lr = 0.02\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 2\n",
    "        self.save_model = False\n",
    "        self.n_train_items = n_train_items\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
    "#     datasets.MNIST('../data', train=True, download=True,\n",
    "#                    transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),\n",
    "#                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                    ]))\n",
    "#     .federate(workers), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "#     batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),\n",
    "#                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                    ])),\n",
    "#     batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size\n",
    ")\n",
    "\n",
    "    \n",
    "#---\n",
    "\n",
    "# less_train_dataloader = [\n",
    "#         ((data), (target))\n",
    "#         for i, (data, target) in enumerate(train_loader)\n",
    "#         if i < (n_train_items / args.batch_size) * 10\n",
    "#     ]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "# print(len(less_train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy \n",
    "# #mnist_dataset.__getitem__(2)[1]\n",
    "# a = (mnist_dataset.__getitem__(0)[0]).numpy()\n",
    "# a.dtype = 'uint8'\n",
    "# print(a)\n",
    "# Image.fromarray(a[0], mode= 'P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*64, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(workers, Net):\n",
    "    model_list = list()\n",
    "    for worker in workers:\n",
    "        model_list.append(Net)\n",
    "    return model_list\n",
    "def opt_init(model_list):\n",
    "    opt_list = list()\n",
    "    for model  in model_list:\n",
    "        opt_list.append(optim.SGD(model.parameters(), lr=args.lr))\n",
    "    return opt_list\n",
    "def random_sample(train_dataloader):\n",
    "    choice_list = sorted(random.sample(range(100), 10))\n",
    "    count = 0\n",
    "    tmp = []\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        if  i == choice_list[count]:\n",
    "            tmp.append(data)\n",
    "            if count == 9:\n",
    "                pass\n",
    "            else:\n",
    "                count += 1\n",
    "    return tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, device, train_loader, opt_list, workers):\n",
    "    global model_list\n",
    "    ## start training and record the model into model_list\n",
    "    \n",
    "    less_train_dataloader = random_sample(train_loader)\n",
    "    for epoch in range(args.epochs):\n",
    "        for batch_idx, (data, target) in enumerate(less_train_dataloader): # <-- now it is a distributed dataset\n",
    "            model_on_worker = model_list[batch_idx%len(workers)]\n",
    "            model_on_worker.train()\n",
    "            model_on_worker.send(workers[batch_idx%len(workers)]) # <-- NEW: send the model to the right location\n",
    "\n",
    "            data_on_worker = data.send(workers[batch_idx%len(workers)])\n",
    "            target_on_worker = target.send(workers[batch_idx%len(workers)])\n",
    "\n",
    "            data_on_worker, target_on_worker = data_on_worker.to(device), target_on_worker.to(device)\n",
    "\n",
    "            opt_list[batch_idx%len(workers)].zero_grad()\n",
    "\n",
    "            output = model_on_worker(data_on_worker)\n",
    "            loss = F.nll_loss(output, target_on_worker)\n",
    "            loss.backward()\n",
    "\n",
    "            opt_list[batch_idx%len(workers)].step()\n",
    "            model_on_worker.get() # <-- NEW: get the model back\n",
    "\n",
    "            model_list[batch_idx%len(workers)] = model_on_worker #When len(dataloader) is longer than the len(worker) send and get must be modified\n",
    "            #model_list here is full of the model which has trained on the workers, there are all different now.\n",
    "\n",
    "        if epoch % args.log_interval == 0:\n",
    "            loss = loss.get() # <-- NEW: get the loss back\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, n_train_items, n_train_items ,\n",
    "                100. * epoch / args.epochs, loss.item()))\n",
    "\n",
    "\n",
    "    ##Aggregation time\n",
    "    new_model = []\n",
    "    tmp_model = Net().to(device)\n",
    "    with torch.no_grad():\n",
    "        for p in model_list[0].parameters():\n",
    "            new_model.append(0)\n",
    "            \n",
    "        for m in model_list:\n",
    "            for par_idx, par in enumerate(m.parameters()):\n",
    "                #average the model_list\n",
    "                new_model[par_idx] = new_model[par_idx]+par.data\n",
    "                # we get new model in list format and need to set_ to model\n",
    "        for worker in range(len(workers)):\n",
    "            for par_idx in range(len(new_model)):\n",
    "                list(model_list[worker].parameters())[par_idx].set_(new_model[par_idx]/len(workers))\n",
    "        #init model with new_model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader, r):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)*(args.test_batch_size)\n",
    "    accuracy = 100. * correct / (len(test_loader)*args.test_batch_size)\n",
    "    #Since the test loader here is a list, we can get the len by * it with batch.size\n",
    "    \n",
    "    \n",
    "    writer.add_scalar('Accuracy', accuracy,r)\n",
    "    writer.add_scalar('Loss', test_loss, r)\n",
    "    print('\\nTest set in round{}: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        r , test_loss, correct, len(test_loader)* (args.test_batch_size),\n",
    "        accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 2.187603\n",
      "After training\n",
      "\n",
      "Test set in round1: Average loss: 2.1699, Accuracy: 5336/10020 (53.25%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 2.006526\n",
      "After training\n",
      "\n",
      "Test set in round2: Average loss: 1.9868, Accuracy: 6575/10020 (65.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 1.662865\n",
      "After training\n",
      "\n",
      "Test set in round3: Average loss: 1.6673, Accuracy: 7582/10020 (75.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 1.277740\n",
      "After training\n",
      "\n",
      "Test set in round4: Average loss: 1.2257, Accuracy: 7745/10020 (77.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.972842\n",
      "After training\n",
      "\n",
      "Test set in round5: Average loss: 0.9083, Accuracy: 7494/10020 (74.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.724724\n",
      "After training\n",
      "\n",
      "Test set in round6: Average loss: 0.7031, Accuracy: 8172/10020 (81.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.811098\n",
      "After training\n",
      "\n",
      "Test set in round7: Average loss: 0.7053, Accuracy: 7676/10020 (76.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.524643\n",
      "After training\n",
      "\n",
      "Test set in round8: Average loss: 0.5411, Accuracy: 8407/10020 (83.90%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.416509\n",
      "After training\n",
      "\n",
      "Test set in round9: Average loss: 0.4634, Accuracy: 8759/10020 (87.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.415444\n",
      "After training\n",
      "\n",
      "Test set in round10: Average loss: 0.5148, Accuracy: 8278/10020 (82.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.378433\n",
      "After training\n",
      "\n",
      "Test set in round11: Average loss: 0.4024, Accuracy: 8836/10020 (88.18%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.438315\n",
      "After training\n",
      "\n",
      "Test set in round12: Average loss: 0.3789, Accuracy: 8952/10020 (89.34%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.343554\n",
      "After training\n",
      "\n",
      "Test set in round13: Average loss: 0.4185, Accuracy: 8670/10020 (86.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.303109\n",
      "After training\n",
      "\n",
      "Test set in round14: Average loss: 0.3391, Accuracy: 9007/10020 (89.89%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.304067\n",
      "After training\n",
      "\n",
      "Test set in round15: Average loss: 0.3835, Accuracy: 8708/10020 (86.91%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.368985\n",
      "After training\n",
      "\n",
      "Test set in round16: Average loss: 0.3172, Accuracy: 9062/10020 (90.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.313231\n",
      "After training\n",
      "\n",
      "Test set in round17: Average loss: 0.3284, Accuracy: 9028/10020 (90.10%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.262256\n",
      "After training\n",
      "\n",
      "Test set in round18: Average loss: 0.3057, Accuracy: 9056/10020 (90.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.290786\n",
      "After training\n",
      "\n",
      "Test set in round19: Average loss: 0.2954, Accuracy: 9146/10020 (91.28%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.372518\n",
      "After training\n",
      "\n",
      "Test set in round20: Average loss: 0.2977, Accuracy: 9076/10020 (90.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.362975\n",
      "After training\n",
      "\n",
      "Test set in round21: Average loss: 0.2884, Accuracy: 9115/10020 (90.97%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.172087\n",
      "After training\n",
      "\n",
      "Test set in round22: Average loss: 0.2638, Accuracy: 9213/10020 (91.95%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.279908\n",
      "After training\n",
      "\n",
      "Test set in round23: Average loss: 0.2582, Accuracy: 9232/10020 (92.14%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.231399\n",
      "After training\n",
      "\n",
      "Test set in round24: Average loss: 0.2614, Accuracy: 9172/10020 (91.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.144707\n",
      "After training\n",
      "\n",
      "Test set in round25: Average loss: 0.2332, Accuracy: 9314/10020 (92.95%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.228207\n",
      "After training\n",
      "\n",
      "Test set in round26: Average loss: 0.2346, Accuracy: 9333/10020 (93.14%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.110784\n",
      "After training\n",
      "\n",
      "Test set in round27: Average loss: 0.2249, Accuracy: 9351/10020 (93.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.235385\n",
      "After training\n",
      "\n",
      "Test set in round28: Average loss: 0.2195, Accuracy: 9369/10020 (93.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.301160\n",
      "After training\n",
      "\n",
      "Test set in round29: Average loss: 0.2321, Accuracy: 9336/10020 (93.17%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.188125\n",
      "After training\n",
      "\n",
      "Test set in round30: Average loss: 0.2158, Accuracy: 9352/10020 (93.33%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.238495\n",
      "After training\n",
      "\n",
      "Test set in round31: Average loss: 0.2206, Accuracy: 9318/10020 (92.99%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.101700\n",
      "After training\n",
      "\n",
      "Test set in round32: Average loss: 0.2031, Accuracy: 9402/10020 (93.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.203324\n",
      "After training\n",
      "\n",
      "Test set in round33: Average loss: 0.2070, Accuracy: 9395/10020 (93.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.195102\n",
      "After training\n",
      "\n",
      "Test set in round34: Average loss: 0.1900, Accuracy: 9455/10020 (94.36%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.231028\n",
      "After training\n",
      "\n",
      "Test set in round35: Average loss: 0.1988, Accuracy: 9402/10020 (93.83%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.155438\n",
      "After training\n",
      "\n",
      "Test set in round36: Average loss: 0.1857, Accuracy: 9478/10020 (94.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.179821\n",
      "After training\n",
      "\n",
      "Test set in round37: Average loss: 0.1829, Accuracy: 9453/10020 (94.34%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.159949\n",
      "After training\n",
      "\n",
      "Test set in round38: Average loss: 0.1809, Accuracy: 9463/10020 (94.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.159746\n",
      "After training\n",
      "\n",
      "Test set in round39: Average loss: 0.1724, Accuracy: 9485/10020 (94.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.142125\n",
      "After training\n",
      "\n",
      "Test set in round40: Average loss: 0.1719, Accuracy: 9507/10020 (94.88%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.176714\n",
      "After training\n",
      "\n",
      "Test set in round41: Average loss: 0.1738, Accuracy: 9498/10020 (94.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.149040\n",
      "After training\n",
      "\n",
      "Test set in round42: Average loss: 0.1630, Accuracy: 9518/10020 (94.99%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.156382\n",
      "After training\n",
      "\n",
      "Test set in round43: Average loss: 0.1606, Accuracy: 9533/10020 (95.14%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.078759\n",
      "After training\n",
      "\n",
      "Test set in round44: Average loss: 0.1585, Accuracy: 9535/10020 (95.16%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.171374\n",
      "After training\n",
      "\n",
      "Test set in round45: Average loss: 0.1574, Accuracy: 9549/10020 (95.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.188344\n",
      "After training\n",
      "\n",
      "Test set in round46: Average loss: 0.1549, Accuracy: 9544/10020 (95.25%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.187432\n",
      "After training\n",
      "\n",
      "Test set in round47: Average loss: 0.1606, Accuracy: 9492/10020 (94.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.197867\n",
      "After training\n",
      "\n",
      "Test set in round48: Average loss: 0.1554, Accuracy: 9542/10020 (95.23%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.129683\n",
      "After training\n",
      "\n",
      "Test set in round49: Average loss: 0.1443, Accuracy: 9572/10020 (95.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.180259\n",
      "After training\n",
      "\n",
      "Test set in round50: Average loss: 0.1530, Accuracy: 9540/10020 (95.21%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.113880\n",
      "After training\n",
      "\n",
      "Test set in round51: Average loss: 0.1404, Accuracy: 9596/10020 (95.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.174476\n",
      "After training\n",
      "\n",
      "Test set in round52: Average loss: 0.1434, Accuracy: 9579/10020 (95.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.201382\n",
      "After training\n",
      "\n",
      "Test set in round53: Average loss: 0.1492, Accuracy: 9536/10020 (95.17%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.059240\n",
      "After training\n",
      "\n",
      "Test set in round54: Average loss: 0.1350, Accuracy: 9599/10020 (95.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.162426\n",
      "After training\n",
      "\n",
      "Test set in round55: Average loss: 0.1302, Accuracy: 9625/10020 (96.06%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.084060\n",
      "After training\n",
      "\n",
      "Test set in round56: Average loss: 0.1303, Accuracy: 9621/10020 (96.02%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.143018\n",
      "After training\n",
      "\n",
      "Test set in round57: Average loss: 0.1284, Accuracy: 9630/10020 (96.11%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.180773\n",
      "After training\n",
      "\n",
      "Test set in round58: Average loss: 0.1337, Accuracy: 9592/10020 (95.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.108459\n",
      "After training\n",
      "\n",
      "Test set in round59: Average loss: 0.1229, Accuracy: 9629/10020 (96.10%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.151504\n",
      "After training\n",
      "\n",
      "Test set in round60: Average loss: 0.1251, Accuracy: 9639/10020 (96.20%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.164160\n",
      "After training\n",
      "\n",
      "Test set in round61: Average loss: 0.1217, Accuracy: 9640/10020 (96.21%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055555\n",
      "After training\n",
      "\n",
      "Test set in round62: Average loss: 0.1205, Accuracy: 9638/10020 (96.19%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.073037\n",
      "After training\n",
      "\n",
      "Test set in round63: Average loss: 0.1172, Accuracy: 9657/10020 (96.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.100398\n",
      "After training\n",
      "\n",
      "Test set in round64: Average loss: 0.1177, Accuracy: 9650/10020 (96.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.098109\n",
      "After training\n",
      "\n",
      "Test set in round65: Average loss: 0.1155, Accuracy: 9659/10020 (96.40%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.096484\n",
      "After training\n",
      "\n",
      "Test set in round66: Average loss: 0.1121, Accuracy: 9669/10020 (96.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.145211\n",
      "After training\n",
      "\n",
      "Test set in round67: Average loss: 0.1146, Accuracy: 9662/10020 (96.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.092553\n",
      "After training\n",
      "\n",
      "Test set in round68: Average loss: 0.1117, Accuracy: 9677/10020 (96.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.095863\n",
      "After training\n",
      "\n",
      "Test set in round69: Average loss: 0.1090, Accuracy: 9687/10020 (96.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.164421\n",
      "After training\n",
      "\n",
      "Test set in round70: Average loss: 0.1111, Accuracy: 9676/10020 (96.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.091611\n",
      "After training\n",
      "\n",
      "Test set in round71: Average loss: 0.1063, Accuracy: 9687/10020 (96.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.130490\n",
      "After training\n",
      "\n",
      "Test set in round72: Average loss: 0.1097, Accuracy: 9662/10020 (96.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.107326\n",
      "After training\n",
      "\n",
      "Test set in round73: Average loss: 0.1070, Accuracy: 9682/10020 (96.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.155817\n",
      "After training\n",
      "\n",
      "Test set in round74: Average loss: 0.1031, Accuracy: 9698/10020 (96.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.104053\n",
      "After training\n",
      "\n",
      "Test set in round75: Average loss: 0.1074, Accuracy: 9686/10020 (96.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.092728\n",
      "After training\n",
      "\n",
      "Test set in round76: Average loss: 0.1004, Accuracy: 9707/10020 (96.88%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.103600\n",
      "After training\n",
      "\n",
      "Test set in round77: Average loss: 0.1004, Accuracy: 9696/10020 (96.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.085182\n",
      "After training\n",
      "\n",
      "Test set in round78: Average loss: 0.0995, Accuracy: 9707/10020 (96.88%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.125761\n",
      "After training\n",
      "\n",
      "Test set in round79: Average loss: 0.1023, Accuracy: 9697/10020 (96.78%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.096917\n",
      "After training\n",
      "\n",
      "Test set in round80: Average loss: 0.0990, Accuracy: 9704/10020 (96.85%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.088521\n",
      "After training\n",
      "\n",
      "Test set in round81: Average loss: 0.0982, Accuracy: 9717/10020 (96.98%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.081836\n",
      "After training\n",
      "\n",
      "Test set in round82: Average loss: 0.0943, Accuracy: 9721/10020 (97.02%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.078754\n",
      "After training\n",
      "\n",
      "Test set in round83: Average loss: 0.0977, Accuracy: 9716/10020 (96.97%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.079473\n",
      "After training\n",
      "\n",
      "Test set in round84: Average loss: 0.0929, Accuracy: 9722/10020 (97.03%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.075931\n",
      "After training\n",
      "\n",
      "Test set in round85: Average loss: 0.0928, Accuracy: 9726/10020 (97.07%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.097116\n",
      "After training\n",
      "\n",
      "Test set in round86: Average loss: 0.0911, Accuracy: 9734/10020 (97.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.137952\n",
      "After training\n",
      "\n",
      "Test set in round87: Average loss: 0.0916, Accuracy: 9742/10020 (97.23%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.073940\n",
      "After training\n",
      "\n",
      "Test set in round88: Average loss: 0.0891, Accuracy: 9737/10020 (97.18%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.074367\n",
      "After training\n",
      "\n",
      "Test set in round89: Average loss: 0.0887, Accuracy: 9736/10020 (97.17%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.084372\n",
      "After training\n",
      "\n",
      "Test set in round90: Average loss: 0.0859, Accuracy: 9755/10020 (97.36%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.054409\n",
      "After training\n",
      "\n",
      "Test set in round91: Average loss: 0.0859, Accuracy: 9753/10020 (97.34%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.084972\n",
      "After training\n",
      "\n",
      "Test set in round92: Average loss: 0.0907, Accuracy: 9739/10020 (97.20%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.068600\n",
      "After training\n",
      "\n",
      "Test set in round93: Average loss: 0.0851, Accuracy: 9756/10020 (97.37%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053676\n",
      "After training\n",
      "\n",
      "Test set in round94: Average loss: 0.0862, Accuracy: 9758/10020 (97.39%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.075033\n",
      "After training\n",
      "\n",
      "Test set in round95: Average loss: 0.0837, Accuracy: 9754/10020 (97.35%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.071264\n",
      "After training\n",
      "\n",
      "Test set in round96: Average loss: 0.0835, Accuracy: 9752/10020 (97.33%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.107232\n",
      "After training\n",
      "\n",
      "Test set in round97: Average loss: 0.0835, Accuracy: 9762/10020 (97.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.129349\n",
      "After training\n",
      "\n",
      "Test set in round98: Average loss: 0.0829, Accuracy: 9765/10020 (97.46%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.116779\n",
      "After training\n",
      "\n",
      "Test set in round99: Average loss: 0.0831, Accuracy: 9759/10020 (97.40%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.067378\n",
      "After training\n",
      "\n",
      "Test set in round100: Average loss: 0.0818, Accuracy: 9761/10020 (97.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.056674\n",
      "After training\n",
      "\n",
      "Test set in round101: Average loss: 0.0815, Accuracy: 9769/10020 (97.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.100340\n",
      "After training\n",
      "\n",
      "Test set in round102: Average loss: 0.0801, Accuracy: 9776/10020 (97.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.067050\n",
      "After training\n",
      "\n",
      "Test set in round103: Average loss: 0.0777, Accuracy: 9782/10020 (97.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.060990\n",
      "After training\n",
      "\n",
      "Test set in round104: Average loss: 0.0790, Accuracy: 9771/10020 (97.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.131924\n",
      "After training\n",
      "\n",
      "Test set in round105: Average loss: 0.0794, Accuracy: 9774/10020 (97.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.063436\n",
      "After training\n",
      "\n",
      "Test set in round106: Average loss: 0.0759, Accuracy: 9786/10020 (97.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.131699\n",
      "After training\n",
      "\n",
      "Test set in round107: Average loss: 0.0780, Accuracy: 9774/10020 (97.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.102239\n",
      "After training\n",
      "\n",
      "Test set in round108: Average loss: 0.0739, Accuracy: 9797/10020 (97.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.090438\n",
      "After training\n",
      "\n",
      "Test set in round109: Average loss: 0.0770, Accuracy: 9780/10020 (97.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.127171\n",
      "After training\n",
      "\n",
      "Test set in round110: Average loss: 0.0771, Accuracy: 9781/10020 (97.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.094499\n",
      "After training\n",
      "\n",
      "Test set in round111: Average loss: 0.0751, Accuracy: 9784/10020 (97.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.056417\n",
      "After training\n",
      "\n",
      "Test set in round112: Average loss: 0.0753, Accuracy: 9777/10020 (97.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.066942\n",
      "After training\n",
      "\n",
      "Test set in round113: Average loss: 0.0788, Accuracy: 9779/10020 (97.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.060190\n",
      "After training\n",
      "\n",
      "Test set in round114: Average loss: 0.0725, Accuracy: 9793/10020 (97.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.077737\n",
      "After training\n",
      "\n",
      "Test set in round115: Average loss: 0.0727, Accuracy: 9792/10020 (97.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.078344\n",
      "After training\n",
      "\n",
      "Test set in round116: Average loss: 0.0734, Accuracy: 9772/10020 (97.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.056329\n",
      "After training\n",
      "\n",
      "Test set in round117: Average loss: 0.0739, Accuracy: 9788/10020 (97.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047983\n",
      "After training\n",
      "\n",
      "Test set in round118: Average loss: 0.0733, Accuracy: 9794/10020 (97.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038051\n",
      "After training\n",
      "\n",
      "Test set in round119: Average loss: 0.0758, Accuracy: 9783/10020 (97.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.111123\n",
      "After training\n",
      "\n",
      "Test set in round120: Average loss: 0.0764, Accuracy: 9784/10020 (97.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.064740\n",
      "After training\n",
      "\n",
      "Test set in round121: Average loss: 0.0738, Accuracy: 9796/10020 (97.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028589\n",
      "After training\n",
      "\n",
      "Test set in round122: Average loss: 0.0685, Accuracy: 9801/10020 (97.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.078618\n",
      "After training\n",
      "\n",
      "Test set in round123: Average loss: 0.0692, Accuracy: 9791/10020 (97.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022277\n",
      "After training\n",
      "\n",
      "Test set in round124: Average loss: 0.0698, Accuracy: 9801/10020 (97.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.083384\n",
      "After training\n",
      "\n",
      "Test set in round125: Average loss: 0.0685, Accuracy: 9806/10020 (97.86%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046359\n",
      "After training\n",
      "\n",
      "Test set in round126: Average loss: 0.0686, Accuracy: 9799/10020 (97.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042405\n",
      "After training\n",
      "\n",
      "Test set in round127: Average loss: 0.0677, Accuracy: 9812/10020 (97.92%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.063778\n",
      "After training\n",
      "\n",
      "Test set in round128: Average loss: 0.0667, Accuracy: 9812/10020 (97.92%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.110690\n",
      "After training\n",
      "\n",
      "Test set in round129: Average loss: 0.0666, Accuracy: 9807/10020 (97.87%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.061980\n",
      "After training\n",
      "\n",
      "Test set in round130: Average loss: 0.0672, Accuracy: 9808/10020 (97.88%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.131747\n",
      "After training\n",
      "\n",
      "Test set in round131: Average loss: 0.0675, Accuracy: 9809/10020 (97.89%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.107329\n",
      "After training\n",
      "\n",
      "Test set in round132: Average loss: 0.0646, Accuracy: 9815/10020 (97.95%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.125838\n",
      "After training\n",
      "\n",
      "Test set in round133: Average loss: 0.0670, Accuracy: 9805/10020 (97.85%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.052716\n",
      "After training\n",
      "\n",
      "Test set in round134: Average loss: 0.0647, Accuracy: 9801/10020 (97.81%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.073362\n",
      "After training\n",
      "\n",
      "Test set in round135: Average loss: 0.0657, Accuracy: 9799/10020 (97.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022311\n",
      "After training\n",
      "\n",
      "Test set in round136: Average loss: 0.0657, Accuracy: 9811/10020 (97.91%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.056719\n",
      "After training\n",
      "\n",
      "Test set in round137: Average loss: 0.0638, Accuracy: 9811/10020 (97.91%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.075626\n",
      "After training\n",
      "\n",
      "Test set in round138: Average loss: 0.0642, Accuracy: 9810/10020 (97.90%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.056307\n",
      "After training\n",
      "\n",
      "Test set in round139: Average loss: 0.0626, Accuracy: 9819/10020 (97.99%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.059170\n",
      "After training\n",
      "\n",
      "Test set in round140: Average loss: 0.0629, Accuracy: 9811/10020 (97.91%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051319\n",
      "After training\n",
      "\n",
      "Test set in round141: Average loss: 0.0621, Accuracy: 9821/10020 (98.01%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.108574\n",
      "After training\n",
      "\n",
      "Test set in round142: Average loss: 0.0625, Accuracy: 9817/10020 (97.97%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039731\n",
      "After training\n",
      "\n",
      "Test set in round143: Average loss: 0.0613, Accuracy: 9819/10020 (97.99%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.052902\n",
      "After training\n",
      "\n",
      "Test set in round144: Average loss: 0.0621, Accuracy: 9804/10020 (97.84%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.076501\n",
      "After training\n",
      "\n",
      "Test set in round145: Average loss: 0.0627, Accuracy: 9796/10020 (97.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.120646\n",
      "After training\n",
      "\n",
      "Test set in round146: Average loss: 0.0641, Accuracy: 9802/10020 (97.82%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055569\n",
      "After training\n",
      "\n",
      "Test set in round147: Average loss: 0.0608, Accuracy: 9821/10020 (98.01%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019821\n",
      "After training\n",
      "\n",
      "Test set in round148: Average loss: 0.0614, Accuracy: 9820/10020 (98.00%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.052371\n",
      "After training\n",
      "\n",
      "Test set in round149: Average loss: 0.0603, Accuracy: 9818/10020 (97.98%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020548\n",
      "After training\n",
      "\n",
      "Test set in round150: Average loss: 0.0604, Accuracy: 9828/10020 (98.08%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.052529\n",
      "After training\n",
      "\n",
      "Test set in round151: Average loss: 0.0620, Accuracy: 9817/10020 (97.97%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.057026\n",
      "After training\n",
      "\n",
      "Test set in round152: Average loss: 0.0590, Accuracy: 9829/10020 (98.09%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053376\n",
      "After training\n",
      "\n",
      "Test set in round153: Average loss: 0.0580, Accuracy: 9831/10020 (98.11%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.048989\n",
      "After training\n",
      "\n",
      "Test set in round154: Average loss: 0.0590, Accuracy: 9820/10020 (98.00%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035219\n",
      "After training\n",
      "\n",
      "Test set in round155: Average loss: 0.0596, Accuracy: 9821/10020 (98.01%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.050742\n",
      "After training\n",
      "\n",
      "Test set in round156: Average loss: 0.0578, Accuracy: 9825/10020 (98.05%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037097\n",
      "After training\n",
      "\n",
      "Test set in round157: Average loss: 0.0580, Accuracy: 9831/10020 (98.11%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.061028\n",
      "After training\n",
      "\n",
      "Test set in round158: Average loss: 0.0579, Accuracy: 9817/10020 (97.97%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028628\n",
      "After training\n",
      "\n",
      "Test set in round159: Average loss: 0.0582, Accuracy: 9827/10020 (98.07%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.090548\n",
      "After training\n",
      "\n",
      "Test set in round160: Average loss: 0.0580, Accuracy: 9827/10020 (98.07%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.079989\n",
      "After training\n",
      "\n",
      "Test set in round161: Average loss: 0.0554, Accuracy: 9816/10020 (97.96%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.089399\n",
      "After training\n",
      "\n",
      "Test set in round162: Average loss: 0.0559, Accuracy: 9830/10020 (98.10%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016915\n",
      "After training\n",
      "\n",
      "Test set in round163: Average loss: 0.0567, Accuracy: 9823/10020 (98.03%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044206\n",
      "After training\n",
      "\n",
      "Test set in round164: Average loss: 0.0552, Accuracy: 9814/10020 (97.94%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051110\n",
      "After training\n",
      "\n",
      "Test set in round165: Average loss: 0.0553, Accuracy: 9821/10020 (98.01%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034771\n",
      "After training\n",
      "\n",
      "Test set in round166: Average loss: 0.0567, Accuracy: 9834/10020 (98.14%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029210\n",
      "After training\n",
      "\n",
      "Test set in round167: Average loss: 0.0567, Accuracy: 9825/10020 (98.05%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047346\n",
      "After training\n",
      "\n",
      "Test set in round168: Average loss: 0.0560, Accuracy: 9831/10020 (98.11%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.084740\n",
      "After training\n",
      "\n",
      "Test set in round169: Average loss: 0.0537, Accuracy: 9832/10020 (98.12%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044041\n",
      "After training\n",
      "\n",
      "Test set in round170: Average loss: 0.0552, Accuracy: 9829/10020 (98.09%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035406\n",
      "After training\n",
      "\n",
      "Test set in round171: Average loss: 0.0541, Accuracy: 9838/10020 (98.18%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.045750\n",
      "After training\n",
      "\n",
      "Test set in round172: Average loss: 0.0553, Accuracy: 9832/10020 (98.12%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047616\n",
      "After training\n",
      "\n",
      "Test set in round173: Average loss: 0.0543, Accuracy: 9827/10020 (98.07%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047717\n",
      "After training\n",
      "\n",
      "Test set in round174: Average loss: 0.0530, Accuracy: 9835/10020 (98.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.063190\n",
      "After training\n",
      "\n",
      "Test set in round175: Average loss: 0.0554, Accuracy: 9835/10020 (98.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019852\n",
      "After training\n",
      "\n",
      "Test set in round176: Average loss: 0.0524, Accuracy: 9837/10020 (98.17%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026379\n",
      "After training\n",
      "\n",
      "Test set in round177: Average loss: 0.0544, Accuracy: 9831/10020 (98.11%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026316\n",
      "After training\n",
      "\n",
      "Test set in round178: Average loss: 0.0534, Accuracy: 9835/10020 (98.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.065073\n",
      "After training\n",
      "\n",
      "Test set in round179: Average loss: 0.0532, Accuracy: 9835/10020 (98.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041784\n",
      "After training\n",
      "\n",
      "Test set in round180: Average loss: 0.0528, Accuracy: 9842/10020 (98.22%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055098\n",
      "After training\n",
      "\n",
      "Test set in round181: Average loss: 0.0522, Accuracy: 9835/10020 (98.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.066149\n",
      "After training\n",
      "\n",
      "Test set in round182: Average loss: 0.0518, Accuracy: 9833/10020 (98.13%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.053988\n",
      "After training\n",
      "\n",
      "Test set in round183: Average loss: 0.0515, Accuracy: 9834/10020 (98.14%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025307\n",
      "After training\n",
      "\n",
      "Test set in round184: Average loss: 0.0514, Accuracy: 9843/10020 (98.23%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.014707\n",
      "After training\n",
      "\n",
      "Test set in round185: Average loss: 0.0528, Accuracy: 9832/10020 (98.12%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.126853\n",
      "After training\n",
      "\n",
      "Test set in round186: Average loss: 0.0516, Accuracy: 9843/10020 (98.23%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034245\n",
      "After training\n",
      "\n",
      "Test set in round187: Average loss: 0.0513, Accuracy: 9840/10020 (98.20%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055408\n",
      "After training\n",
      "\n",
      "Test set in round188: Average loss: 0.0516, Accuracy: 9838/10020 (98.18%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024031\n",
      "After training\n",
      "\n",
      "Test set in round189: Average loss: 0.0516, Accuracy: 9828/10020 (98.08%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037006\n",
      "After training\n",
      "\n",
      "Test set in round190: Average loss: 0.0514, Accuracy: 9842/10020 (98.22%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034335\n",
      "After training\n",
      "\n",
      "Test set in round191: Average loss: 0.0517, Accuracy: 9836/10020 (98.16%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041960\n",
      "After training\n",
      "\n",
      "Test set in round192: Average loss: 0.0503, Accuracy: 9847/10020 (98.27%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023135\n",
      "After training\n",
      "\n",
      "Test set in round193: Average loss: 0.0504, Accuracy: 9836/10020 (98.16%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.069154\n",
      "After training\n",
      "\n",
      "Test set in round194: Average loss: 0.0517, Accuracy: 9838/10020 (98.18%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041320\n",
      "After training\n",
      "\n",
      "Test set in round195: Average loss: 0.0503, Accuracy: 9843/10020 (98.23%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.043807\n",
      "After training\n",
      "\n",
      "Test set in round196: Average loss: 0.0489, Accuracy: 9851/10020 (98.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041435\n",
      "After training\n",
      "\n",
      "Test set in round197: Average loss: 0.0487, Accuracy: 9841/10020 (98.21%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016046\n",
      "After training\n",
      "\n",
      "Test set in round198: Average loss: 0.0483, Accuracy: 9851/10020 (98.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038832\n",
      "After training\n",
      "\n",
      "Test set in round199: Average loss: 0.0489, Accuracy: 9847/10020 (98.27%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044016\n",
      "After training\n",
      "\n",
      "Test set in round200: Average loss: 0.0472, Accuracy: 9850/10020 (98.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.089251\n",
      "After training\n",
      "\n",
      "Test set in round201: Average loss: 0.0542, Accuracy: 9836/10020 (98.16%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.043785\n",
      "After training\n",
      "\n",
      "Test set in round202: Average loss: 0.0485, Accuracy: 9851/10020 (98.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.052387\n",
      "After training\n",
      "\n",
      "Test set in round203: Average loss: 0.0487, Accuracy: 9848/10020 (98.28%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.062016\n",
      "After training\n",
      "\n",
      "Test set in round204: Average loss: 0.0534, Accuracy: 9833/10020 (98.13%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.040346\n",
      "After training\n",
      "\n",
      "Test set in round205: Average loss: 0.0481, Accuracy: 9852/10020 (98.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055242\n",
      "After training\n",
      "\n",
      "Test set in round206: Average loss: 0.0479, Accuracy: 9850/10020 (98.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042381\n",
      "After training\n",
      "\n",
      "Test set in round207: Average loss: 0.0487, Accuracy: 9854/10020 (98.34%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.070029\n",
      "After training\n",
      "\n",
      "Test set in round208: Average loss: 0.0502, Accuracy: 9836/10020 (98.16%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.115553\n",
      "After training\n",
      "\n",
      "Test set in round209: Average loss: 0.0494, Accuracy: 9838/10020 (98.18%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037850\n",
      "After training\n",
      "\n",
      "Test set in round210: Average loss: 0.0476, Accuracy: 9851/10020 (98.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038357\n",
      "After training\n",
      "\n",
      "Test set in round211: Average loss: 0.0471, Accuracy: 9850/10020 (98.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.040509\n",
      "After training\n",
      "\n",
      "Test set in round212: Average loss: 0.0466, Accuracy: 9854/10020 (98.34%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.059908\n",
      "After training\n",
      "\n",
      "Test set in round213: Average loss: 0.0470, Accuracy: 9850/10020 (98.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.058299\n",
      "After training\n",
      "\n",
      "Test set in round214: Average loss: 0.0466, Accuracy: 9847/10020 (98.27%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.114474\n",
      "After training\n",
      "\n",
      "Test set in round215: Average loss: 0.0482, Accuracy: 9844/10020 (98.24%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.101946\n",
      "After training\n",
      "\n",
      "Test set in round216: Average loss: 0.0509, Accuracy: 9832/10020 (98.12%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.094797\n",
      "After training\n",
      "\n",
      "Test set in round217: Average loss: 0.0508, Accuracy: 9835/10020 (98.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.073599\n",
      "After training\n",
      "\n",
      "Test set in round218: Average loss: 0.0572, Accuracy: 9814/10020 (97.94%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.095024\n",
      "After training\n",
      "\n",
      "Test set in round219: Average loss: 0.0490, Accuracy: 9836/10020 (98.16%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.068607\n",
      "After training\n",
      "\n",
      "Test set in round220: Average loss: 0.0500, Accuracy: 9835/10020 (98.15%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.095076\n",
      "After training\n",
      "\n",
      "Test set in round221: Average loss: 0.0466, Accuracy: 9846/10020 (98.26%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.014731\n",
      "After training\n",
      "\n",
      "Test set in round222: Average loss: 0.0480, Accuracy: 9836/10020 (98.16%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.091620\n",
      "After training\n",
      "\n",
      "Test set in round223: Average loss: 0.0453, Accuracy: 9855/10020 (98.35%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.076831\n",
      "After training\n",
      "\n",
      "Test set in round224: Average loss: 0.0450, Accuracy: 9857/10020 (98.37%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.059412\n",
      "After training\n",
      "\n",
      "Test set in round225: Average loss: 0.0477, Accuracy: 9844/10020 (98.24%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016455\n",
      "After training\n",
      "\n",
      "Test set in round226: Average loss: 0.0475, Accuracy: 9837/10020 (98.17%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.060164\n",
      "After training\n",
      "\n",
      "Test set in round227: Average loss: 0.0454, Accuracy: 9855/10020 (98.35%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038205\n",
      "After training\n",
      "\n",
      "Test set in round228: Average loss: 0.0444, Accuracy: 9867/10020 (98.47%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.013429\n",
      "After training\n",
      "\n",
      "Test set in round229: Average loss: 0.0462, Accuracy: 9843/10020 (98.23%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036921\n",
      "After training\n",
      "\n",
      "Test set in round230: Average loss: 0.0450, Accuracy: 9857/10020 (98.37%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028791\n",
      "After training\n",
      "\n",
      "Test set in round231: Average loss: 0.0449, Accuracy: 9849/10020 (98.29%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.092068\n",
      "After training\n",
      "\n",
      "Test set in round232: Average loss: 0.0478, Accuracy: 9836/10020 (98.16%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.087300\n",
      "After training\n",
      "\n",
      "Test set in round233: Average loss: 0.0475, Accuracy: 9838/10020 (98.18%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.014801\n",
      "After training\n",
      "\n",
      "Test set in round234: Average loss: 0.0453, Accuracy: 9856/10020 (98.36%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028132\n",
      "After training\n",
      "\n",
      "Test set in round235: Average loss: 0.0455, Accuracy: 9845/10020 (98.25%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032717\n",
      "After training\n",
      "\n",
      "Test set in round236: Average loss: 0.0459, Accuracy: 9857/10020 (98.37%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015872\n",
      "After training\n",
      "\n",
      "Test set in round237: Average loss: 0.0449, Accuracy: 9852/10020 (98.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010432\n",
      "After training\n",
      "\n",
      "Test set in round238: Average loss: 0.0443, Accuracy: 9850/10020 (98.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027990\n",
      "After training\n",
      "\n",
      "Test set in round239: Average loss: 0.0453, Accuracy: 9850/10020 (98.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039632\n",
      "After training\n",
      "\n",
      "Test set in round240: Average loss: 0.0439, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033166\n",
      "After training\n",
      "\n",
      "Test set in round241: Average loss: 0.0464, Accuracy: 9850/10020 (98.30%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034164\n",
      "After training\n",
      "\n",
      "Test set in round242: Average loss: 0.0425, Accuracy: 9870/10020 (98.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.058629\n",
      "After training\n",
      "\n",
      "Test set in round243: Average loss: 0.0430, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038362\n",
      "After training\n",
      "\n",
      "Test set in round244: Average loss: 0.0437, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024190\n",
      "After training\n",
      "\n",
      "Test set in round245: Average loss: 0.0447, Accuracy: 9856/10020 (98.36%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025817\n",
      "After training\n",
      "\n",
      "Test set in round246: Average loss: 0.0447, Accuracy: 9851/10020 (98.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.044481\n",
      "After training\n",
      "\n",
      "Test set in round247: Average loss: 0.0421, Accuracy: 9864/10020 (98.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037552\n",
      "After training\n",
      "\n",
      "Test set in round248: Average loss: 0.0429, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039142\n",
      "After training\n",
      "\n",
      "Test set in round249: Average loss: 0.0423, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023560\n",
      "After training\n",
      "\n",
      "Test set in round250: Average loss: 0.0438, Accuracy: 9848/10020 (98.28%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036561\n",
      "After training\n",
      "\n",
      "Test set in round251: Average loss: 0.0428, Accuracy: 9858/10020 (98.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032839\n",
      "After training\n",
      "\n",
      "Test set in round252: Average loss: 0.0423, Accuracy: 9867/10020 (98.47%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037800\n",
      "After training\n",
      "\n",
      "Test set in round253: Average loss: 0.0424, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024759\n",
      "After training\n",
      "\n",
      "Test set in round254: Average loss: 0.0435, Accuracy: 9855/10020 (98.35%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037252\n",
      "After training\n",
      "\n",
      "Test set in round255: Average loss: 0.0429, Accuracy: 9858/10020 (98.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.049181\n",
      "After training\n",
      "\n",
      "Test set in round256: Average loss: 0.0434, Accuracy: 9851/10020 (98.31%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.050479\n",
      "After training\n",
      "\n",
      "Test set in round257: Average loss: 0.0429, Accuracy: 9853/10020 (98.33%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017271\n",
      "After training\n",
      "\n",
      "Test set in round258: Average loss: 0.0426, Accuracy: 9860/10020 (98.40%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023721\n",
      "After training\n",
      "\n",
      "Test set in round259: Average loss: 0.0429, Accuracy: 9852/10020 (98.32%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.069657\n",
      "After training\n",
      "\n",
      "Test set in round260: Average loss: 0.0413, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037086\n",
      "After training\n",
      "\n",
      "Test set in round261: Average loss: 0.0411, Accuracy: 9867/10020 (98.47%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030404\n",
      "After training\n",
      "\n",
      "Test set in round262: Average loss: 0.0419, Accuracy: 9865/10020 (98.45%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038008\n",
      "After training\n",
      "\n",
      "Test set in round263: Average loss: 0.0408, Accuracy: 9864/10020 (98.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.009692\n",
      "After training\n",
      "\n",
      "Test set in round264: Average loss: 0.0422, Accuracy: 9858/10020 (98.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.098155\n",
      "After training\n",
      "\n",
      "Test set in round265: Average loss: 0.0426, Accuracy: 9849/10020 (98.29%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.058748\n",
      "After training\n",
      "\n",
      "Test set in round266: Average loss: 0.0433, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030068\n",
      "After training\n",
      "\n",
      "Test set in round267: Average loss: 0.0422, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.092766\n",
      "After training\n",
      "\n",
      "Test set in round268: Average loss: 0.0409, Accuracy: 9864/10020 (98.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.043361\n",
      "After training\n",
      "\n",
      "Test set in round269: Average loss: 0.0403, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033827\n",
      "After training\n",
      "\n",
      "Test set in round270: Average loss: 0.0406, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046343\n",
      "After training\n",
      "\n",
      "Test set in round271: Average loss: 0.0420, Accuracy: 9858/10020 (98.38%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.088490\n",
      "After training\n",
      "\n",
      "Test set in round272: Average loss: 0.0421, Accuracy: 9854/10020 (98.34%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.087046\n",
      "After training\n",
      "\n",
      "Test set in round273: Average loss: 0.0415, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.059927\n",
      "After training\n",
      "\n",
      "Test set in round274: Average loss: 0.0422, Accuracy: 9859/10020 (98.39%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032572\n",
      "After training\n",
      "\n",
      "Test set in round275: Average loss: 0.0414, Accuracy: 9861/10020 (98.41%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.079589\n",
      "After training\n",
      "\n",
      "Test set in round276: Average loss: 0.0414, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024035\n",
      "After training\n",
      "\n",
      "Test set in round277: Average loss: 0.0411, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036423\n",
      "After training\n",
      "\n",
      "Test set in round278: Average loss: 0.0399, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041066\n",
      "After training\n",
      "\n",
      "Test set in round279: Average loss: 0.0427, Accuracy: 9864/10020 (98.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015071\n",
      "After training\n",
      "\n",
      "Test set in round280: Average loss: 0.0411, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.080428\n",
      "After training\n",
      "\n",
      "Test set in round281: Average loss: 0.0424, Accuracy: 9855/10020 (98.35%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022597\n",
      "After training\n",
      "\n",
      "Test set in round282: Average loss: 0.0406, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017761\n",
      "After training\n",
      "\n",
      "Test set in round283: Average loss: 0.0390, Accuracy: 9873/10020 (98.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047744\n",
      "After training\n",
      "\n",
      "Test set in round284: Average loss: 0.0396, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.084256\n",
      "After training\n",
      "\n",
      "Test set in round285: Average loss: 0.0394, Accuracy: 9873/10020 (98.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032744\n",
      "After training\n",
      "\n",
      "Test set in round286: Average loss: 0.0400, Accuracy: 9870/10020 (98.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023327\n",
      "After training\n",
      "\n",
      "Test set in round287: Average loss: 0.0407, Accuracy: 9864/10020 (98.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.063935\n",
      "After training\n",
      "\n",
      "Test set in round288: Average loss: 0.0403, Accuracy: 9864/10020 (98.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.080747\n",
      "After training\n",
      "\n",
      "Test set in round289: Average loss: 0.0403, Accuracy: 9859/10020 (98.39%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021825\n",
      "After training\n",
      "\n",
      "Test set in round290: Average loss: 0.0398, Accuracy: 9864/10020 (98.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.043064\n",
      "After training\n",
      "\n",
      "Test set in round291: Average loss: 0.0402, Accuracy: 9863/10020 (98.43%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.013999\n",
      "After training\n",
      "\n",
      "Test set in round292: Average loss: 0.0399, Accuracy: 9865/10020 (98.45%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047050\n",
      "After training\n",
      "\n",
      "Test set in round293: Average loss: 0.0401, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022959\n",
      "After training\n",
      "\n",
      "Test set in round294: Average loss: 0.0404, Accuracy: 9866/10020 (98.46%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026151\n",
      "After training\n",
      "\n",
      "Test set in round295: Average loss: 0.0388, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.043567\n",
      "After training\n",
      "\n",
      "Test set in round296: Average loss: 0.0411, Accuracy: 9865/10020 (98.45%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032287\n",
      "After training\n",
      "\n",
      "Test set in round297: Average loss: 0.0387, Accuracy: 9864/10020 (98.44%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.077894\n",
      "After training\n",
      "\n",
      "Test set in round298: Average loss: 0.0411, Accuracy: 9859/10020 (98.39%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032363\n",
      "After training\n",
      "\n",
      "Test set in round299: Average loss: 0.0397, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.009058\n",
      "After training\n",
      "\n",
      "Test set in round300: Average loss: 0.0400, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.055834\n",
      "After training\n",
      "\n",
      "Test set in round301: Average loss: 0.0418, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.011825\n",
      "After training\n",
      "\n",
      "Test set in round302: Average loss: 0.0443, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019241\n",
      "After training\n",
      "\n",
      "Test set in round303: Average loss: 0.0384, Accuracy: 9879/10020 (98.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029479\n",
      "After training\n",
      "\n",
      "Test set in round304: Average loss: 0.0394, Accuracy: 9870/10020 (98.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035464\n",
      "After training\n",
      "\n",
      "Test set in round305: Average loss: 0.0396, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.043736\n",
      "After training\n",
      "\n",
      "Test set in round306: Average loss: 0.0389, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.043842\n",
      "After training\n",
      "\n",
      "Test set in round307: Average loss: 0.0370, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017477\n",
      "After training\n",
      "\n",
      "Test set in round308: Average loss: 0.0387, Accuracy: 9873/10020 (98.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027801\n",
      "After training\n",
      "\n",
      "Test set in round309: Average loss: 0.0392, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051654\n",
      "After training\n",
      "\n",
      "Test set in round310: Average loss: 0.0371, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035673\n",
      "After training\n",
      "\n",
      "Test set in round311: Average loss: 0.0378, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036315\n",
      "After training\n",
      "\n",
      "Test set in round312: Average loss: 0.0384, Accuracy: 9873/10020 (98.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038442\n",
      "After training\n",
      "\n",
      "Test set in round313: Average loss: 0.0378, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.048663\n",
      "After training\n",
      "\n",
      "Test set in round314: Average loss: 0.0389, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024946\n",
      "After training\n",
      "\n",
      "Test set in round315: Average loss: 0.0401, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039750\n",
      "After training\n",
      "\n",
      "Test set in round316: Average loss: 0.0388, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028196\n",
      "After training\n",
      "\n",
      "Test set in round317: Average loss: 0.0385, Accuracy: 9874/10020 (98.54%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042625\n",
      "After training\n",
      "\n",
      "Test set in round318: Average loss: 0.0367, Accuracy: 9879/10020 (98.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026198\n",
      "After training\n",
      "\n",
      "Test set in round319: Average loss: 0.0382, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.058222\n",
      "After training\n",
      "\n",
      "Test set in round320: Average loss: 0.0419, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032983\n",
      "After training\n",
      "\n",
      "Test set in round321: Average loss: 0.0361, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028781\n",
      "After training\n",
      "\n",
      "Test set in round322: Average loss: 0.0376, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033151\n",
      "After training\n",
      "\n",
      "Test set in round323: Average loss: 0.0368, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024413\n",
      "After training\n",
      "\n",
      "Test set in round324: Average loss: 0.0385, Accuracy: 9873/10020 (98.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046252\n",
      "After training\n",
      "\n",
      "Test set in round325: Average loss: 0.0368, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.009852\n",
      "After training\n",
      "\n",
      "Test set in round326: Average loss: 0.0371, Accuracy: 9873/10020 (98.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.084174\n",
      "After training\n",
      "\n",
      "Test set in round327: Average loss: 0.0402, Accuracy: 9862/10020 (98.42%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008107\n",
      "After training\n",
      "\n",
      "Test set in round328: Average loss: 0.0367, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.083526\n",
      "After training\n",
      "\n",
      "Test set in round329: Average loss: 0.0381, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.040139\n",
      "After training\n",
      "\n",
      "Test set in round330: Average loss: 0.0375, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.009859\n",
      "After training\n",
      "\n",
      "Test set in round331: Average loss: 0.0362, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034043\n",
      "After training\n",
      "\n",
      "Test set in round332: Average loss: 0.0374, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037609\n",
      "After training\n",
      "\n",
      "Test set in round333: Average loss: 0.0371, Accuracy: 9879/10020 (98.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.011404\n",
      "After training\n",
      "\n",
      "Test set in round334: Average loss: 0.0381, Accuracy: 9868/10020 (98.48%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029556\n",
      "After training\n",
      "\n",
      "Test set in round335: Average loss: 0.0380, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019771\n",
      "After training\n",
      "\n",
      "Test set in round336: Average loss: 0.0384, Accuracy: 9869/10020 (98.49%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.011519\n",
      "After training\n",
      "\n",
      "Test set in round337: Average loss: 0.0377, Accuracy: 9876/10020 (98.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.011314\n",
      "After training\n",
      "\n",
      "Test set in round338: Average loss: 0.0366, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028719\n",
      "After training\n",
      "\n",
      "Test set in round339: Average loss: 0.0368, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.057673\n",
      "After training\n",
      "\n",
      "Test set in round340: Average loss: 0.0375, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.080893\n",
      "After training\n",
      "\n",
      "Test set in round341: Average loss: 0.0370, Accuracy: 9873/10020 (98.53%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032400\n",
      "After training\n",
      "\n",
      "Test set in round342: Average loss: 0.0360, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031067\n",
      "After training\n",
      "\n",
      "Test set in round343: Average loss: 0.0356, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038939\n",
      "After training\n",
      "\n",
      "Test set in round344: Average loss: 0.0409, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028306\n",
      "After training\n",
      "\n",
      "Test set in round345: Average loss: 0.0363, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.074186\n",
      "After training\n",
      "\n",
      "Test set in round346: Average loss: 0.0380, Accuracy: 9866/10020 (98.46%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020961\n",
      "After training\n",
      "\n",
      "Test set in round347: Average loss: 0.0383, Accuracy: 9870/10020 (98.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.070981\n",
      "After training\n",
      "\n",
      "Test set in round348: Average loss: 0.0380, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.042770\n",
      "After training\n",
      "\n",
      "Test set in round349: Average loss: 0.0357, Accuracy: 9879/10020 (98.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024484\n",
      "After training\n",
      "\n",
      "Test set in round350: Average loss: 0.0358, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032260\n",
      "After training\n",
      "\n",
      "Test set in round351: Average loss: 0.0361, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026693\n",
      "After training\n",
      "\n",
      "Test set in round352: Average loss: 0.0365, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010469\n",
      "After training\n",
      "\n",
      "Test set in round353: Average loss: 0.0380, Accuracy: 9865/10020 (98.45%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025095\n",
      "After training\n",
      "\n",
      "Test set in round354: Average loss: 0.0362, Accuracy: 9879/10020 (98.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.009789\n",
      "After training\n",
      "\n",
      "Test set in round355: Average loss: 0.0360, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027685\n",
      "After training\n",
      "\n",
      "Test set in round356: Average loss: 0.0364, Accuracy: 9879/10020 (98.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.072538\n",
      "After training\n",
      "\n",
      "Test set in round357: Average loss: 0.0365, Accuracy: 9876/10020 (98.56%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018621\n",
      "After training\n",
      "\n",
      "Test set in round358: Average loss: 0.0372, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024727\n",
      "After training\n",
      "\n",
      "Test set in round359: Average loss: 0.0363, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038309\n",
      "After training\n",
      "\n",
      "Test set in round360: Average loss: 0.0364, Accuracy: 9877/10020 (98.57%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027868\n",
      "After training\n",
      "\n",
      "Test set in round361: Average loss: 0.0354, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019085\n",
      "After training\n",
      "\n",
      "Test set in round362: Average loss: 0.0384, Accuracy: 9870/10020 (98.50%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024355\n",
      "After training\n",
      "\n",
      "Test set in round363: Average loss: 0.0359, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021625\n",
      "After training\n",
      "\n",
      "Test set in round364: Average loss: 0.0366, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010130\n",
      "After training\n",
      "\n",
      "Test set in round365: Average loss: 0.0373, Accuracy: 9872/10020 (98.52%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036614\n",
      "After training\n",
      "\n",
      "Test set in round366: Average loss: 0.0353, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026873\n",
      "After training\n",
      "\n",
      "Test set in round367: Average loss: 0.0350, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.075871\n",
      "After training\n",
      "\n",
      "Test set in round368: Average loss: 0.0359, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022270\n",
      "After training\n",
      "\n",
      "Test set in round369: Average loss: 0.0343, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025992\n",
      "After training\n",
      "\n",
      "Test set in round370: Average loss: 0.0349, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031423\n",
      "After training\n",
      "\n",
      "Test set in round371: Average loss: 0.0357, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022840\n",
      "After training\n",
      "\n",
      "Test set in round372: Average loss: 0.0352, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029878\n",
      "After training\n",
      "\n",
      "Test set in round373: Average loss: 0.0352, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007343\n",
      "After training\n",
      "\n",
      "Test set in round374: Average loss: 0.0340, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034232\n",
      "After training\n",
      "\n",
      "Test set in round375: Average loss: 0.0346, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.048852\n",
      "After training\n",
      "\n",
      "Test set in round376: Average loss: 0.0367, Accuracy: 9878/10020 (98.58%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012442\n",
      "After training\n",
      "\n",
      "Test set in round377: Average loss: 0.0342, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022244\n",
      "After training\n",
      "\n",
      "Test set in round378: Average loss: 0.0345, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007851\n",
      "After training\n",
      "\n",
      "Test set in round379: Average loss: 0.0356, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029092\n",
      "After training\n",
      "\n",
      "Test set in round380: Average loss: 0.0363, Accuracy: 9871/10020 (98.51%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024695\n",
      "After training\n",
      "\n",
      "Test set in round381: Average loss: 0.0341, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024944\n",
      "After training\n",
      "\n",
      "Test set in round382: Average loss: 0.0338, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026118\n",
      "After training\n",
      "\n",
      "Test set in round383: Average loss: 0.0337, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029785\n",
      "After training\n",
      "\n",
      "Test set in round384: Average loss: 0.0353, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023891\n",
      "After training\n",
      "\n",
      "Test set in round385: Average loss: 0.0349, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041805\n",
      "After training\n",
      "\n",
      "Test set in round386: Average loss: 0.0366, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.047582\n",
      "After training\n",
      "\n",
      "Test set in round387: Average loss: 0.0366, Accuracy: 9875/10020 (98.55%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021586\n",
      "After training\n",
      "\n",
      "Test set in round388: Average loss: 0.0342, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035473\n",
      "After training\n",
      "\n",
      "Test set in round389: Average loss: 0.0335, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.076559\n",
      "After training\n",
      "\n",
      "Test set in round390: Average loss: 0.0341, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.068661\n",
      "After training\n",
      "\n",
      "Test set in round391: Average loss: 0.0351, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022809\n",
      "After training\n",
      "\n",
      "Test set in round392: Average loss: 0.0358, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012066\n",
      "After training\n",
      "\n",
      "Test set in round393: Average loss: 0.0330, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022781\n",
      "After training\n",
      "\n",
      "Test set in round394: Average loss: 0.0328, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038454\n",
      "After training\n",
      "\n",
      "Test set in round395: Average loss: 0.0365, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017461\n",
      "After training\n",
      "\n",
      "Test set in round396: Average loss: 0.0349, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.033434\n",
      "After training\n",
      "\n",
      "Test set in round397: Average loss: 0.0333, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.032405\n",
      "After training\n",
      "\n",
      "Test set in round398: Average loss: 0.0336, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035262\n",
      "After training\n",
      "\n",
      "Test set in round399: Average loss: 0.0329, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036942\n",
      "After training\n",
      "\n",
      "Test set in round400: Average loss: 0.0333, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025953\n",
      "After training\n",
      "\n",
      "Test set in round401: Average loss: 0.0339, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031011\n",
      "After training\n",
      "\n",
      "Test set in round402: Average loss: 0.0344, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025142\n",
      "After training\n",
      "\n",
      "Test set in round403: Average loss: 0.0339, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031784\n",
      "After training\n",
      "\n",
      "Test set in round404: Average loss: 0.0335, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031988\n",
      "After training\n",
      "\n",
      "Test set in round405: Average loss: 0.0333, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.034134\n",
      "After training\n",
      "\n",
      "Test set in round406: Average loss: 0.0376, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022073\n",
      "After training\n",
      "\n",
      "Test set in round407: Average loss: 0.0338, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.075924\n",
      "After training\n",
      "\n",
      "Test set in round408: Average loss: 0.0346, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037206\n",
      "After training\n",
      "\n",
      "Test set in round409: Average loss: 0.0326, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021809\n",
      "After training\n",
      "\n",
      "Test set in round410: Average loss: 0.0343, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023730\n",
      "After training\n",
      "\n",
      "Test set in round411: Average loss: 0.0348, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.070601\n",
      "After training\n",
      "\n",
      "Test set in round412: Average loss: 0.0339, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027649\n",
      "After training\n",
      "\n",
      "Test set in round413: Average loss: 0.0326, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035126\n",
      "After training\n",
      "\n",
      "Test set in round414: Average loss: 0.0325, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022798\n",
      "After training\n",
      "\n",
      "Test set in round415: Average loss: 0.0342, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035633\n",
      "After training\n",
      "\n",
      "Test set in round416: Average loss: 0.0336, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.026627\n",
      "After training\n",
      "\n",
      "Test set in round417: Average loss: 0.0340, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.009553\n",
      "After training\n",
      "\n",
      "Test set in round418: Average loss: 0.0340, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025213\n",
      "After training\n",
      "\n",
      "Test set in round419: Average loss: 0.0347, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.046582\n",
      "After training\n",
      "\n",
      "Test set in round420: Average loss: 0.0345, Accuracy: 9879/10020 (98.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008924\n",
      "After training\n",
      "\n",
      "Test set in round421: Average loss: 0.0331, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024827\n",
      "After training\n",
      "\n",
      "Test set in round422: Average loss: 0.0329, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017674\n",
      "After training\n",
      "\n",
      "Test set in round423: Average loss: 0.0347, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021831\n",
      "After training\n",
      "\n",
      "Test set in round424: Average loss: 0.0338, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029648\n",
      "After training\n",
      "\n",
      "Test set in round425: Average loss: 0.0316, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019068\n",
      "After training\n",
      "\n",
      "Test set in round426: Average loss: 0.0333, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.051837\n",
      "After training\n",
      "\n",
      "Test set in round427: Average loss: 0.0340, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024501\n",
      "After training\n",
      "\n",
      "Test set in round428: Average loss: 0.0331, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019597\n",
      "After training\n",
      "\n",
      "Test set in round429: Average loss: 0.0335, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020514\n",
      "After training\n",
      "\n",
      "Test set in round430: Average loss: 0.0328, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.012005\n",
      "After training\n",
      "\n",
      "Test set in round431: Average loss: 0.0349, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020649\n",
      "After training\n",
      "\n",
      "Test set in round432: Average loss: 0.0330, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.066779\n",
      "After training\n",
      "\n",
      "Test set in round433: Average loss: 0.0332, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016623\n",
      "After training\n",
      "\n",
      "Test set in round434: Average loss: 0.0339, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008453\n",
      "After training\n",
      "\n",
      "Test set in round435: Average loss: 0.0353, Accuracy: 9879/10020 (98.59%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035286\n",
      "After training\n",
      "\n",
      "Test set in round436: Average loss: 0.0349, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.023141\n",
      "After training\n",
      "\n",
      "Test set in round437: Average loss: 0.0314, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019253\n",
      "After training\n",
      "\n",
      "Test set in round438: Average loss: 0.0338, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.067226\n",
      "After training\n",
      "\n",
      "Test set in round439: Average loss: 0.0329, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019379\n",
      "After training\n",
      "\n",
      "Test set in round440: Average loss: 0.0336, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038311\n",
      "After training\n",
      "\n",
      "Test set in round441: Average loss: 0.0326, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021495\n",
      "After training\n",
      "\n",
      "Test set in round442: Average loss: 0.0336, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031837\n",
      "After training\n",
      "\n",
      "Test set in round443: Average loss: 0.0365, Accuracy: 9880/10020 (98.60%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030353\n",
      "After training\n",
      "\n",
      "Test set in round444: Average loss: 0.0327, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019707\n",
      "After training\n",
      "\n",
      "Test set in round445: Average loss: 0.0321, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.065768\n",
      "After training\n",
      "\n",
      "Test set in round446: Average loss: 0.0324, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018322\n",
      "After training\n",
      "\n",
      "Test set in round447: Average loss: 0.0327, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025900\n",
      "After training\n",
      "\n",
      "Test set in round448: Average loss: 0.0317, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029686\n",
      "After training\n",
      "\n",
      "Test set in round449: Average loss: 0.0316, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022388\n",
      "After training\n",
      "\n",
      "Test set in round450: Average loss: 0.0327, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007026\n",
      "After training\n",
      "\n",
      "Test set in round451: Average loss: 0.0332, Accuracy: 9885/10020 (98.65%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021080\n",
      "After training\n",
      "\n",
      "Test set in round452: Average loss: 0.0342, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.065190\n",
      "After training\n",
      "\n",
      "Test set in round453: Average loss: 0.0337, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.037726\n",
      "After training\n",
      "\n",
      "Test set in round454: Average loss: 0.0341, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.064727\n",
      "After training\n",
      "\n",
      "Test set in round455: Average loss: 0.0330, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029204\n",
      "After training\n",
      "\n",
      "Test set in round456: Average loss: 0.0321, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025120\n",
      "After training\n",
      "\n",
      "Test set in round457: Average loss: 0.0327, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.029899\n",
      "After training\n",
      "\n",
      "Test set in round458: Average loss: 0.0317, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.021572\n",
      "After training\n",
      "\n",
      "Test set in round459: Average loss: 0.0322, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.010445\n",
      "After training\n",
      "\n",
      "Test set in round460: Average loss: 0.0318, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007460\n",
      "After training\n",
      "\n",
      "Test set in round461: Average loss: 0.0325, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027120\n",
      "After training\n",
      "\n",
      "Test set in round462: Average loss: 0.0348, Accuracy: 9881/10020 (98.61%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.030531\n",
      "After training\n",
      "\n",
      "Test set in round463: Average loss: 0.0326, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024867\n",
      "After training\n",
      "\n",
      "Test set in round464: Average loss: 0.0319, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008168\n",
      "After training\n",
      "\n",
      "Test set in round465: Average loss: 0.0320, Accuracy: 9888/10020 (98.68%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.035918\n",
      "After training\n",
      "\n",
      "Test set in round466: Average loss: 0.0309, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.027074\n",
      "After training\n",
      "\n",
      "Test set in round467: Average loss: 0.0336, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.062353\n",
      "After training\n",
      "\n",
      "Test set in round468: Average loss: 0.0327, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.038854\n",
      "After training\n",
      "\n",
      "Test set in round469: Average loss: 0.0349, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015711\n",
      "After training\n",
      "\n",
      "Test set in round470: Average loss: 0.0328, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019901\n",
      "After training\n",
      "\n",
      "Test set in round471: Average loss: 0.0327, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.008732\n",
      "After training\n",
      "\n",
      "Test set in round472: Average loss: 0.0336, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.017292\n",
      "After training\n",
      "\n",
      "Test set in round473: Average loss: 0.0321, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.016112\n",
      "After training\n",
      "\n",
      "Test set in round474: Average loss: 0.0341, Accuracy: 9882/10020 (98.62%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025499\n",
      "After training\n",
      "\n",
      "Test set in round475: Average loss: 0.0329, Accuracy: 9886/10020 (98.66%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.015013\n",
      "After training\n",
      "\n",
      "Test set in round476: Average loss: 0.0323, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.039153\n",
      "After training\n",
      "\n",
      "Test set in round477: Average loss: 0.0341, Accuracy: 9883/10020 (98.63%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.060701\n",
      "After training\n",
      "\n",
      "Test set in round478: Average loss: 0.0328, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.041345\n",
      "After training\n",
      "\n",
      "Test set in round479: Average loss: 0.0327, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.007766\n",
      "After training\n",
      "\n",
      "Test set in round480: Average loss: 0.0323, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.014694\n",
      "After training\n",
      "\n",
      "Test set in round481: Average loss: 0.0326, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018541\n",
      "After training\n",
      "\n",
      "Test set in round482: Average loss: 0.0318, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006949\n",
      "After training\n",
      "\n",
      "Test set in round483: Average loss: 0.0322, Accuracy: 9897/10020 (98.77%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.006356\n",
      "After training\n",
      "\n",
      "Test set in round484: Average loss: 0.0317, Accuracy: 9896/10020 (98.76%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.028238\n",
      "After training\n",
      "\n",
      "Test set in round485: Average loss: 0.0318, Accuracy: 9894/10020 (98.74%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.019200\n",
      "After training\n",
      "\n",
      "Test set in round486: Average loss: 0.0316, Accuracy: 9900/10020 (98.80%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020713\n",
      "After training\n",
      "\n",
      "Test set in round487: Average loss: 0.0318, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.062555\n",
      "After training\n",
      "\n",
      "Test set in round488: Average loss: 0.0315, Accuracy: 9899/10020 (98.79%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.020831\n",
      "After training\n",
      "\n",
      "Test set in round489: Average loss: 0.0313, Accuracy: 9887/10020 (98.67%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.024456\n",
      "After training\n",
      "\n",
      "Test set in round490: Average loss: 0.0335, Accuracy: 9892/10020 (98.72%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018469\n",
      "After training\n",
      "\n",
      "Test set in round491: Average loss: 0.0315, Accuracy: 9893/10020 (98.73%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.018656\n",
      "After training\n",
      "\n",
      "Test set in round492: Average loss: 0.0330, Accuracy: 9890/10020 (98.70%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.062053\n",
      "After training\n",
      "\n",
      "Test set in round493: Average loss: 0.0306, Accuracy: 9904/10020 (98.84%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.056190\n",
      "After training\n",
      "\n",
      "Test set in round494: Average loss: 0.0322, Accuracy: 9895/10020 (98.75%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.031459\n",
      "After training\n",
      "\n",
      "Test set in round495: Average loss: 0.0339, Accuracy: 9889/10020 (98.69%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.022522\n",
      "After training\n",
      "\n",
      "Test set in round496: Average loss: 0.0313, Accuracy: 9891/10020 (98.71%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.036166\n",
      "After training\n",
      "\n",
      "Test set in round497: Average loss: 0.0350, Accuracy: 9884/10020 (98.64%)\n",
      "\n",
      "Train Epoch: 0 [6000/6000 (0%)]\tLoss: 0.025377\n",
      "After training\n",
      "\n",
      "Test set in round498: Average loss: 0.0313, Accuracy: 9893/10020 (98.73%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
    "logdir = '/root/notebooks/tensorflow/logs/pysyft_iidFedSGD'\n",
    "writer = SummaryWriter(logdir)\n",
    "\n",
    "model_list = []\n",
    "model_list = model_init(workers, Net().to(device))\n",
    "opt_list = opt_init(model_list)\n",
    "# not finish in train, finish latter\n",
    "pars = [list(model.parameters()) for model in model_list]\n",
    "\n",
    "for r in range(1, args.rounds + 1):\n",
    "    train(args, device, train_loader, opt_list, workers)\n",
    "    print(\"After training\")\n",
    "    test(args, model_list[0], device, test_loader, r)\n",
    "\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
